# Introduction
第一段: 

## BR-MRS 引言部分中文翻译



第一段
(介绍背景)多模态推荐系统通过整合视觉、文本等异质模态信息，已被广泛验证能够提升个性化排序性能。
(大家都关注的一个问题) 模态之间有着丰富而精细的联系, 既包含互补的信息, 又包含冲突的信息. 多模态推荐系统的核心挑战在于怎么在排序目标下自适应地利用模态间关系, 当一个模态不足以刻画用户偏好时, 用另一个模态去互补. 当两个模态冲突时, 排除任务无关的噪声. 
(为什么大家关注这个问题) Case, 图片相似但是文本描述不同(需要用另一个模态信息互补),  文本写的是A配色, 图像写的是B配色. 冲突的用户偏好信息.  

第二段  相关工作
(概述相关工作的技术方向): 为了建模这一问题, 在之前的工作中,一些基于晚融合的工作, 通过两个分支分别建模, 最终融合在一起做推荐,(Motivation是什么,它们为什么觉得这样可以解决上面的问题) 基于自监督学习的多模态推荐方法, 通过对最终的表征进行对比构建自监督信号, 能够排除掉模态间相互冲突的信号, 从而只保留跨模态一致的信息.

第三段 
Despite remarkable progress,

第四段 




## Introduction
多模态推荐系统通过整合视觉,文本等异质模态信息, 为刻画用户偏好提供了更丰富的信息来源,并已在个性化排序任务中被广泛验证能够带来显著的性能提升。然而, 不同模态通常包含不一致的信息, 既有可能互补, 也同时存在冲突的信息, 例如物品的图像通常包含更细粒度的外观,材质和风格信息,而文本描述可能强调功能属性,使用场景, 不一致的信息既在一些关键信息上相互补充,共同塑造用户偏好,也有可能由于营销,展示角度偏差等因素产生冲突甚至引入噪声。因此, 多模态推荐系统的一个核心挑战在于,如何在排序目标下自适应地利用模态间不一致的信息--当单一模态不足以完整刻画用户偏好时,能够有效利用另一模态的补充信息增强排序判别能力; 而当不同模态提供的信息存在冲突时, 则需要抑制与排序任务无关的噪声, 避免其误导推荐决策。 

围绕如何处理模态间的不一致性, 早期的一些研究进行模态独立建模, 依赖Late Fusion策略, 为不同模态分别设计独立的编码和排序分支, 并在最终推荐决策阶段对各模态预测结果进行融合, 通过减少模态间的早期交互，在一定程度上规避了冲突信息的直接传播, 但在一定程度上削弱了跨模态协作带来的判别增益, 使得模型在需要多模态互补才能区分的困难样本上表现受限. 进一步地, 一些方法进行跨模态一致性建模, 通过引入自监督学习机制(对比学习或生成式自监督),抑制跨模态间的不一致性,从而提升多模态联合推荐的鲁棒性. 然而, 这一范式隐含地将模态差异视为噪声, 忽略了潜在的模态间互补的可能性. 近期, 一些方法意识到模态间不一致信息的价值, 尝试通过显式的解耦机制, 如正交约束或模态特异性子空间, 在共享语义空间之外额外学习模态特有信息, 但此类方法的建模多停留于表征空间的几何解耦,缺乏与推荐任务的个性化排序目标相一致的优化约束, 难以确保解耦所获得的模态差异信息具备有效的排序判别力. 

为了系统地分析现有工作的不足, 我们进一步展开实证分析和理论分析, 具体的, 我们发现现有方法在处理跨模态不一致信息的时候, 往往存在两类普遍失效现象: (1) 在某些物品-用户对上, 模型会在推荐和正样本在某个模态空间中高度相似的负样本. 但这些负样本往往在另一模态下具备清晰的判别证据. (2) 在部分用户场景中, 融合后的多模态分支反而弱于某个单模态分支, 出现退化现象, 表明融合表征可能仍然被某个模态的噪声信息稀释。 在理论层面, 我们证明现有方法的缺陷. 






## 4.1 跨模态硬负样本采样

由于直接使用正交约束难以对齐推荐任务中对用户偏好进行个性化排序的目标, 因此, 我们迫切需要一种在服务于个性化排序目标的前提下, 同时又能主动挖掘并利用每个模态特有的判别信息的方法.  具体而言, 我们希望一个模态对某些样本混淆时,另一个模态能够贡献其独特的信息起到判别作用。在这种目标的驱动下,我们重新审视推荐系统中被广泛使用的贝叶斯个性化排序损失, 其中的核心组件负采样策略--已被证明能够有效增强模型的判别能力 ,然而, 以往的负采样方法通常局限在提升整体的负样本辨别质量, 忽略了其挖掘模态独特信息的潜力.  

为此，我们提出跨模态硬负样本采样（CHNS)模块, 采用负采样策略激活模态特有的判别能力, 以提升模型的个性化排序表现。 具体而言, 对于每个正样本对 $(u, i^+) \in \mathcal{O}$, 我们首先随机采样一个候选负样本池 $\mathcal{N}(u) \subseteq \mathcal{I} \setminus \mathcal{O}_u$中,随后, 我们在每个模态下分别识别其最容易产生混淆的负样本: 

$$
\begin{aligned}
j_v(u, i^+) &= \arg\max_{j \in \mathcal{N}(u)} s_v(u, j), \
j_t(u, i^+) &= \arg\max_{j \in \mathcal{N}(u)} s_t(u, j).
\end{aligned}
$$

其中$j_v$ 表示在视觉模态下最难与正样本区分的负样本，而 $j_t$ 表示在文本模态下最具混淆性的负样本。 
接下来, 我们利用一个模态所对应的困难负样本来训练另一模态的排序分支, 从而显式要求该模态贡献其独特信息用于提供判别证据. 相对应的损失函数定义为 
$$
\mathcal{L}*{\mathrm{chns}} = -\sum*{(u,i^+) \in \mathcal{O}} \left[ \log \sigma\left(s_t(u,i^+) - s_t(u, j_v(u,i^+))\right) + \log \sigma\left(s_v(u,i^+) - s_v(u, j_t(u,i^+))\right) \right].
$$
其中，第一项(\sigma\left(s_t(u,i^+) - s_t(u, j_v(u,i^+))\right))表示文本模态需要区分视觉模态所难以区分的负样本；第二项(\sigma\left(s_v(u,i^+) - s_v(u, j_t(u,i^+))\right))则表示视觉模态需要区分文本空间的混淆案例。通过这种跨模态监督的设计，CHNS明确激励各模态发挥自身独特的判别优势，以更好地服务于个性化排序目标。


---

## 4.2 协同感知 BPR 损失

第一段: 问题定位加设计目标, 把为什么要做SynergyBPR讲清楚
句1: 承上启下
句2: 指出传统约束在推荐任务中难以学习到协同信息, 甚至出现融合退化的原因
句3: 提出设计目标和约束: 直观上,融合后的多模态表征应该承载了多模态联合推断的能力,直接优化融合表征不可行,因为协同信息是隐变量, 理论上,协同信息出现的时候应该呈现出排序能力相对于任一单模态的严格优势

第二段: 


在学习到模态独特信息之后, 我们进一步关注如何在推荐任务中建模模态协同信息。 协同信息指只有联合两个模态才能获取的判别线索, 它并不能从任一单模态中单独推断出来, 可能是用户偏好的关键决定因素。 


直观上, 融合后的多模态表征如果捕获了协同信息, 它在排序能力上应该呈现出对于任一单模态的严格优势。反之, 如果融合分支反而弱于单模态分支, 则融合表示可能退化为冗余或被噪声稀释的表征,而无法有效利用跨模态协同线索。  

直接最大化融合表征中的协同信息, 似乎是一种直接的做法, 然而, 协同信息是不可观测的隐变量, 给优化带来了困难。 之前的方法通常会直接在融合表征上施加BPR损失, 期望从端到端的优化中隐式增强模型利用协同信息的能力, 但仍然无法保障 退化问题, 即融合表征的排序性能反而比任一单模态都要更差,而InfoNCE等组件仍然不足以学习协同信息. 因此我们重新审视推荐系统中的BPR组件, 

 

具体而言, 我们对融合表示施加严格的偏好边际约束,使得融合分支相对于单模态拥有更明显的判别优势。 我们设计了称为Synergy-aware BPR的损失函数: 
Lsyn​=−(u,i+,i−)∑​logσ(Δf​−max(Δt​,Δv​)−θ), 
其中xxx . 

通过这种显式的协同约束设计，融合表示能够主动学习跨模态的协同信息，约束模态融合后在个性化排序任务中地超越任一单模态的表现。

---

## 4.3 训练策略

我们将融合BPR损失、跨模态硬负样本采样损失以及协同感知损失整合，形成BR-MRS的统一训练目标：

$$
\mathcal{L} =  \lambda_h \mathcal{L}*{\mathrm{chns}} + \lambda_s \mathcal{L}_{\mathrm{syn}} + \lambda |\Theta|_2^2,
$$

其中，$\mathcal{L}_{\mathrm{BPR}}$为标准融合排序损失，$\lambda_h$和$\lambda_s$分别调控CHNS和协同感知损失的贡献，$\lambda$为正则化系数，$\Theta$表示模型所有的可训练参数。
