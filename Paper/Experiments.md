
RQ1: 性能怎么样? 
(1)Performance上升, 
(2)在合成数据集上, 我们对每种用户类型的鲁棒性更强,而且不同用户偏好的变动下,我们的鲁棒性也更强. 

RQ2: 每个组件是否有用?
(1) Ablation Study ,消融每个组件,性能都会下降
(2) 超参数敏感度, 我们对超参数不敏感 


RQ3: CHNS怎么保障学习到独特信息的?
(1) 我们采样到的确实是单模态难负样本, 定义ground_truth margin, , 我们对比CHNS负样本和随机负样本的margin分布。 证明我们确实学习到了hard negtives



(2)统计同一个样本上视觉和文本分支的margin分布, 我们采样到的确实是单模态难,跨模态可辨的. 
(3) 独特信息, 单独用视觉分支/文本分支做ranking,引入后,CHNS哪个分支提升更明显? 这一点是为了证明,CHNS主要是激活了哪个模态的独特信息. 视觉recall@20从0.087升到了0.1048, 文本recall@20从0.1012升到了0.1105.  对视觉的激活效果特别好. 
(4)Case Study: 在视觉空间里混淆的负样本(图片相似但文本不同),我们帮它区分出来了 

RQ4: Synergy BPR怎么保障学习到协同信息的,并且缓解性能退化的? 
(1) 统计指标: 加入Synergy BPR之后, 多模态融合退化的情况下降了很多. 反而,单模态都推荐错了,多模态融合在一起推荐对了, 这种情形增加了
(2) Case Study: 找两个Case 1️⃣原来两个单模态都无法推荐的, 加上SynergyBPR之后,得分调整了 2️⃣原来两个单模态可以推荐的, 融合后退化的, 我们得到一个新的. 




(1)我们采样每个item的潜在变量, 包括文本独特, 视觉独特, 协同潜变量,冗余潜变量 Z_t, Z_v, Z_s, Z_r 
(2) 模态生成, 线性变换+噪声 M_t, M_v.   
- z_t只能从M_t里面获取
- z_v只能从M_v里面获取
- Z_s需要M_t + M_v联合才能获取 (怎么保证这一点?) 通过lowrank矩阵投影到各个模态,使得单模态只能获得部分为度的内容 
- Z_r从M_t或者M_v都能获取.  



(3) θ_u = [θ_t; θ_v; θ_s; θ_r] 用户偏好向量   score(u, i) = <θ_u, [z_t^i; z_v^i; z_s^i; z_r^i]> 
(4) Top-K采样



