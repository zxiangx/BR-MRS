% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@book{Aho:72,
    author  = {Alfred V. Aho and Jeffrey D. Ullman},
    title   = {The Theory of Parsing, Translation and Compiling},
    year    = "1972",
    volume  = "1",
    publisher = {Prentice-Hall},
    address = {Englewood Cliffs, NJ}
}

@article{zhou2024symbolic,
  title={Symbolic learning enables self-evolving agents},
  author={Zhou, Wangchunshu and Ou, Yixin and Ding, Shengwei and Li, Long and Wu, Jialong and Wang, Tiannan and Chen, Jiamin and Wang, Shuai and Xu, Xiaohua and Zhang, Ningyu and others},
  journal={arXiv preprint arXiv:2406.18532},
  year={2024}
}

@article{liang2024self,
  title={Self-evolving Agents with reflective and memory-augmented abilities},
  author={Liang, Xuechen and Tao, Meiling and Xia, Yinghui and Shi, Tianyu and Wang, Jun and Yang, JingSong},
  journal={arXiv preprint arXiv:2409.00872},
  year={2024}
}

@article{wang2024moa,
  title={Mixture-of-agents enhances large language model capabilities},
  author={Wang, Junlin and Wang, Jue and Athiwaratkun, Ben and Zhang, Ce and Zou, James},
  journal={arXiv preprint arXiv:2406.04692},
  year={2024}
}

@article{chen2024routerdc,
  title={RouterDC: Query-Based Router by Dual Contrastive Learning for Assembling Large Language Models},
  author={Chen, Shuhao and Jiang, Weisen and Lin, Baijiong and Kwok, James T and Zhang, Yu},
  journal={arXiv preprint arXiv:2409.19886},
  year={2024}
}

@article{han2024wildguard,
  title={Wildguard: Open one-stop moderation tools for safety risks, jailbreaks, and refusals of llms},
  author={Han, Seungju and Rao, Kavel and Ettinger, Allyson and Jiang, Liwei and Lin, Bill Yuchen and Lambert, Nathan and Choi, Yejin and Dziri, Nouha},
  journal={arXiv preprint arXiv:2406.18495},
  year={2024}
}


@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    year    = "1983",
    publisher = {American Psychological Association},
    address = {Washington, DC}
}

@article{Chandra:81,
	author = {Ashok K. Chandra and Dexter C. Kozen and Larry J. Stockmeyer},
	year = "1981",
	title = {Alternation},
	journal = {Journal of the Association for Computing Machinery},
	volume = "28",
	number = "1",
	pages = "114--133",
	doi = "10.1145/322234.322243",
}

@inproceedings{andrew2007scalable,
  title={Scalable training of {L1}-regularized log-linear models},
  author={Andrew, Galen and Gao, Jianfeng},
  booktitle={Proceedings of the 24th International Conference on Machine Learning},
  pages={33--40},
  year={2007},
}

@book{Gusfield:97,
    author  = {Dan Gusfield},
    title   = {Algorithms on Strings, Trees and Sequences},
    year    = "1997",
    publisher = {Cambridge University Press},
    address = {Cambridge, UK}
}

@article{rasooli-tetrault-2015,
    author    = {Mohammad Sadegh Rasooli and Joel R. Tetreault},
    title     = {Yara Parser: {A} Fast and Accurate Dependency Parser},
    journal   = {Computing Research Repository},
    volume    = {arXiv:1503.06733},
    year      = {2015},
    url       = {http://arxiv.org/abs/1503.06733},
    note    = {version 2}
}

@article{Ando2005,
	Acmid = {1194905},
	Author = {Ando, Rie Kubota and Zhang, Tong},
	Issn = {1532-4435},
	Issue_Date = {12/1/2005},
	Journal = {Journal of Machine Learning Research},
	Month = dec,
	Numpages = {37},
	Pages = {1817--1853},
	Publisher = {JMLR.org},
	Title = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
	Volume = {6},
	Year = {2005}
}

% Start

% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{li2024gslb,
  title={GSLB: the graph structure learning benchmark},
  author={Li, Zhixun and Sun, Xin and Luo, Yifan and Zhu, Yanqiao and Chen, Dingshuo and Luo, Yingtao and Zhou, Xiangxin and Liu, Qiang and Wu, Shu and Wang, Liang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@INPROCEEDINGS{Tang:12KDDCross,
    AUTHOR = "Jie Tang and Sen Wu and Jimeng Sun and Hang Su",
    TITLE = "Cross-domain Collaboration Recommendation",
    BOOKTITLE = "KDD'2012",
    YEAR = {2012},
}

@inproceedings{sankar2020dysat,
  title={Dysat: Deep neural representation learning on dynamic graphs via self-attention networks},
  author={Sankar, Aravind and Wu, Yanhong and Gou, Liang and Zhang, Wei and Yang, Hao},
  booktitle={Proceedings of the 13th International Conference on Web Search and Data Mining},
  pages={519--527},
  year={2020}
}

@article{wu2022handling,
  title={Handling Distribution Shifts on Graphs: An Invariance Perspective},
  author={Wu, Qitian and Zhang, Hengrui and Yan, Junchi and Wipf, David},
  journal={International Conference on Learning Representations},
  year={2022}
}

@inproceedings{mikolov2013efficient,
  author    = {Tom{\'{a}}s Mikolov and
               Kai Chen and
               Greg Corrado and
               Jeffrey Dean},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Efficient Estimation of Word Representations in Vector Space},
  booktitle = {1st International Conference on Learning Representations},
  year      = {2013}
}

@inproceedings{wu2022discovering,
  author    = {Yingxin Wu and
               Xiang Wang and
               An Zhang and
               Xiangnan He and
               Tat{-}Seng Chua},
  title     = {Discovering Invariant Rationales for Graph Neural Networks},
  booktitle = {The Tenth International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2022}
}

@article{zhu2021shift,
  title={Shift-robust gnns: Overcoming the limitations of localized graph training data},
  author={Zhu, Qi and Ponomareva, Natalia and Han, Jiawei and Perozzi, Bryan},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{gagnon2022woods,
  title={WOODS: Benchmarks for Out-of-Distribution Generalization in Time Series Tasks},
  author={Gagnon-Audet, Jean-Christophe and Ahuja, Kartik and Darvishi-Bayazi, Mohammad-Javad and Dumas, Guillaume and Rish, Irina},
  journal={arXiv preprint arXiv:2203.09978},
  year={2022}
}

@inproceedings{du2021adarnn,
  title={Adarnn: Adaptive learning and forecasting of time series},
  author={Du, Yuntao and Wang, Jindong and Feng, Wenjie and Pan, Sinno and Qin, Tao and Xu, Renjun and Wang, Chongjun},
  booktitle={Proceedings of the 30th ACM International Conference on Information \& Knowledge Management},
  pages={402--411},
  year={2021}
}

@inproceedings{kim2021reversible,
  title={Reversible Instance Normalization for Accurate Time-Series Forecasting against Distribution Shift},
  author={Kim, Taesung and Kim, Jinhee and Tae, Yunwon and Park, Cheonbok and Choi, Jang-Ho and Choo, Jaegul},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@inproceedings{venkateswaran2021environment,
  title={Environment agnostic invariant risk minimization for classification of sequential datasets},
  author={Venkateswaran, Praveen and Muthusamy, Vinod and Isahagian, Vatche and Venkatasubramanian, Nalini},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={1615--1624},
  year={2021}
}

@article{driess2023palm-e,
  title={Palm-e: An embodied multimodal language model},
  author={Driess, Danny and Xia, Fei and Sajjadi, Mehdi SM and Lynch, Corey and Chowdhery, Aakanksha and Wahid, Ayzaan and Tompson, Jonathan and Vuong, Quan and Yu, Tianhe and Huang, Wenlong and others},
  year={2023}
}


@article{huang2024understanding,
  title={Understanding the planning of LLM agents: A survey},
  author={Huang, Xu and Liu, Weiwen and Chen, Xiaolong and Wang, Xingmei and Wang, Hao and Lian, Defu and Wang, Yasheng and Tang, Ruiming and Chen, Enhong},
  journal={arXiv preprint arXiv:2402.02716},
  year={2024}
}

@inproceedings{wang2024executable,
  title={Executable code actions elicit better llm agents},
  author={Wang, Xingyao and Chen, Yangyi and Yuan, Lifan and Zhang, Yizhe and Li, Yunzhu and Peng, Hao and Ji, Heng},
  booktitle={Forty-first International Conference on Machine Learning},
  year={2024}
}



@article{putta2024agentq,
  title={Agent q: Advanced reasoning and learning for autonomous ai agents},
  author={Putta, Pranav and Mills, Edmund and Garg, Naman and Motwani, Sumeet and Finn, Chelsea and Garg, Divyansh and Rafailov, Rafael},
  journal={arXiv preprint arXiv:2408.07199},
  year={2024}
}

@article{masterman2024landscape,
  title={The landscape of emerging ai agent architectures for reasoning, planning, and tool calling: A survey},
  author={Masterman, Tula and Besen, Sandi and Sawtell, Mason and Chao, Alex},
  journal={arXiv preprint arXiv:2404.11584},
  year={2024}
}

@article{lu2021diversify,
  title={DIVERSIFY to Generalize: Learning Generalized Representations for Time Series Classification},
  author={Lu, Wang and Wang, Jindong and Chen, Yiqiang and Sun, Xinwei},
  journal={arXiv preprint},
  year={2021}
}

@article{zhu2024knowagent,
  title={Knowagent: Knowledge-augmented planning for llm-based agents},
  author={Zhu, Yuqi and Qiao, Shuofei and Ou, Yixin and Deng, Shumin and Lyu, Shiwei and Shen, Yue and Liang, Lei and Gu, Jinjie and Chen, Huajun and Zhang, Ningyu},
  journal={arXiv preprint arXiv:2403.03101},
  year={2024}
}

@article{skarding2021foundations,
  title={Foundations and Modeling of Dynamic Networks Using Dynamic Graph Neural Networks: A Survey},
  author={Skarding, Joakim and Gabrys, Bogdan and Musial, Katarzyna},
  journal={IEEE Access},
  pages={79143--79168},
  year={2021}
}

@article{zhu2022learnable,
  title={Learnable Encoder-Decoder Architecture for Dynamic Graph: A Survey},
  author={Zhu, Yuecai and Lyu, Fuyuan and Hu, Chengming and Chen, Xi and Liu, Xue},
  journal={arXiv preprint arXiv:2203.10480},
  year={2022}
}


@article{zhang2024cut,
 Author = {Guibin Zhang and Yanwei Yue and Zhixun Li and Sukwon Yun and Guancheng Wan and Kun Wang and Dawei Cheng and Jeffrey Xu Yu and Tianlong Chen},
Title = {Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems},
Year = {2024},
  journal={arXiv preprint arXiv:2410.02506},
}


@inproceedings{wang2021inductive,
  author    = {Yanbang Wang and
               Yen{-}Yu Chang and
               Yunyu Liu and
               Jure Leskovec and
               Pan Li},
  title     = {Inductive Representation Learning in Temporal Networks via Causal
               Anonymous Walks},
  booktitle = {9th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2021}
}

@article{cong2021dynamic,
  title={Dynamic Graph Representation Learning via Graph Transformer Networks},
  author={Cong, Weilin and Wu, Yanhong and Tian, Yuandong and Gu, Mengting and Xia, Yinglong and Mahdavi, Mehrdad and Chen, Chun-cheng Jason},
  journal={arXiv preprint arXiv:2111.10447},
  year={2021}
}

@article{hong2024data-interpreter,
  title={Data interpreter: An llm agent for data science},
  author={Hong, Sirui and Lin, Yizhang and Liu, Bang and Liu, Bangbang and Wu, Binhao and Zhang, Ceyao and Wei, Chenxing and Li, Danyang and Chen, Jiaqi and Zhang, Jiayi and others},
  journal={arXiv preprint arXiv:2402.18679},
  year={2024}
}

@inproceedings{yang2021discrete,
  title={Discrete-time Temporal Network Embedding via Implicit Hierarchical Learning in Hyperbolic Space},
  author={Yang, Menglin and Zhou, Min and Kalander, Marcus and Huang, Zengfeng and King, Irwin},
  booktitle={Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery \& Data Mining},
  pages={1975--1985},
  year={2021}
}

@inproceedings{sun2021hyperbolic,
  title={Hyperbolic variational graph neural network for modeling dynamic graphs},
  author={Sun, Li and Zhang, Zhongbao and Zhang, Jiawei and Wang, Feiyang and Peng, Hao and Su, Sen and Yu, Philip S},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={5},
  pages={4375--4383},
  year={2021}
}

@inproceedings{xu2020inductive,
  author    = {Da Xu and
               Chuanwei Ruan and
               Evren K{\"{o}}rpeoglu and
               Sushant Kumar and
               Kannan Achan},
  title     = {Inductive representation learning on temporal graphs},
  booktitle = {8th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2020}
}

@article{wang2021tcl,
  title={Tcl: Transformer-based dynamic graph modelling via contrastive learning},
  author={Wang, Lu and Chang, Xiaofu and Li, Shuang and Chu, Yunfei and Li, Hui and Zhang, Wei and He, Xiaofeng and Song, Le and Zhou, Jingren and Yang, Hongxia},
  journal={arXiv preprint arXiv:2105.07944},
  year={2021}
}

@article{rossi2020temporal,
  title={Temporal graph networks for deep learning on dynamic graphs},
  author={Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
  journal={arXiv preprint arXiv:2006.10637},
  year={2020}
}

@article{hajiramezanali2019variational,
  title={Variational graph recurrent neural networks},
  author={Hajiramezanali, Ehsan and Hasanzadeh, Arman and Narayanan, Krishna and Duffield, Nick and Zhou, Mingyuan and Qian, Xiaoning},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{pareja2020evolvegcn,
  title={Evolvegcn: Evolving graph convolutional networks for dynamic graphs},
  author={Pareja, Aldo and Domeniconi, Giacomo and Chen, Jie and Ma, Tengfei and Suzumura, Toyotaro and Kanezashi, Hiroki and Kaler, Tim and Schardl, Tao and Leiserson, Charles},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5363--5370},
  year={2020}
}

@inproceedings{seo2018structured,
  title={Structured sequence modeling with graph convolutional recurrent networks},
  author={Seo, Youngjoo and Defferrard, Micha{\"e}l and Vandergheynst, Pierre and Bresson, Xavier},
  booktitle={International Conference on Neural Information Processing},
  pages={362--373},
  year={2018},
  organization={Springer}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  year={2016}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint},
  year={2019}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations}
}

@inproceedings{krueger2021out,
  title={Out-of-distribution generalization via risk extrapolation (rex)},
  author={Krueger, David and Caballero, Ethan and Jacobsen, Joern-Henrik and Zhang, Amy and Binas, Jonathan and Zhang, Dinghuai and Le Priol, Remi and Courville, Aaron},
  booktitle={International Conference on Machine Learning},
  pages={5815--5826},
  year={2021}
}

@article{cadene2019rubi,
  title={Rubi: Reducing unimodal biases for visual question answering},
  author={Cadene, Remi and Dancette, Corentin and Cord, Matthieu and Parikh, Devi and others},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{aggarwal2014evolutionary,
  title={Evolutionary network analysis: A survey},
  author={Aggarwal, Charu and Subbian, Karthik},
  journal={ACM Computing Surveys (CSUR)},
  volume={47},
  number={1},
  pages={1--36},
  year={2014},
  publisher={ACM New York, NY, USA}
}

@inproceedings{qiu2020temporal,
  title={Temporal network embedding with high-order nonlinear information},
  author={Qiu, Zhenyu and Hu, Wenbin and Wu, Jia and Liu, Weiwei and Du, Bo and Jia, Xiaohua},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={5436--5443},
  year={2020}
}

@inproceedings{huang2020motif,
  title={Motif-Preserving Temporal Network Embedding.},
  author={Huang, Hong and Fang, Zixuan and Wang, Xiao and Miao, Youshan and Jin, Hai},
  booktitle={IJCAI},
  pages={1237--1243},
  year={2020}
}

@inproceedings{zhou2018dynamic,
  title={Dynamic network embedding by modeling triadic closure process},
  author={Zhou, Lekui and Yang, Yang and Ren, Xiang and Wu, Fei and Zhuang, Yueting},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={32},
  number={1},
  year={2018}
}

@inproceedings{trivedi2019dyrep,
  title={Dyrep: Learning representations over dynamic graphs},
  author={Trivedi, Rakshit and Farajtabar, Mehrdad and Biswal, Prasenjeet and Zha, Hongyuan},
  booktitle={International conference on learning representations},
  year={2019}
}

@article{ding2021closer,
  title={A Closer Look at Distribution Shifts and Out-of-Distribution Generalization on Graphs},
  author={Ding, Mucong and Kong, Kezhi and Chen, Jiuhai and Kirchenbauer, John and Goldblum, Micah and Wipf, David and Huang, Furong and Goldstein, Tom},
  year={2021}
}

@article{kovanen2011temporal,
  title={Temporal motifs in time-dependent networks},
  author={Kovanen, Lauri and Karsai, M{\'a}rton and Kaski, Kimmo and Kert{\'e}sz, J{\'a}nos and Saram{\"a}ki, Jari},
  journal={Journal of Statistical Mechanics: Theory and Experiment},
  volume={2011},
  number={11},
  pages={P11005},
  year={2011},
  publisher={IOP Publishing}
}

@article{benson2016higher,
  title={Higher-order organization of complex networks},
  author={Benson, Austin R and Gleich, David F and Leskovec, Jure},
  journal={Science},
  volume={353},
  number={6295},
  pages={163--166},
  year={2016},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{paranjape2017motifs,
  title={Motifs in temporal networks},
  author={Paranjape, Ashwin and Benson, Austin R and Leskovec, Jure},
  booktitle={Proceedings of the tenth ACM international conference on web search and data mining},
  pages={601--610},
  year={2017}
}

@article{zitnik2019evolution,
  title={Evolution of resilience in protein interactomes across the tree of life},
  author={Zitnik, Marinka and Sosi{\v{c}}, Rok and Feldman, Marcus W and Leskovec, Jure},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={10},
  pages={4426--4433},
  year={2019},
  publisher={National Acad Sciences}
}

@book{coleman1994foundations,
  title={Foundations of social theory},
  author={Coleman, James S},
  year={1994},
  publisher={Harvard university press}
}

@article{huang2015triadic,
  title={Triadic closure pattern analysis and prediction in social networks},
  author={Huang, Hong and Tang, Jie and Liu, Lu and Luo, JarDer and Fu, Xiaoming},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={27},
  number={12},
  pages={3374--3389},
  year={2015},
  publisher={IEEE}
}

@article{kovanen2013temporal,
  title={Temporal motifs reveal homophily, gender-specific patterns, and group talk in call sequences},
  author={Kovanen, Lauri and Kaski, Kimmo and Kert{\'e}sz, J{\'a}nos and Saram{\"a}ki, Jari},
  journal={Proceedings of the National Academy of Sciences},
  volume={110},
  number={45},
  pages={18070--18075},
  year={2013},
  publisher={National Acad Sciences}
}

@book{glymour2016causal,
  title={Causal inference in statistics: A primer},
  author={Glymour, Madelyn and Pearl, Judea and Jewell, Nicholas P},
  year={2016},
  publisher={John Wiley \& Sons}
}

@article{pearl2000models,
  title={Models, reasoning and inference},
  author={Pearl, Judea and others},
  journal={Cambridge, UK: CambridgeUniversityPress},
  volume={19},
  pages={2},
  year={2000}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  year={2017}
}

@book{tian2006characterization,
  title={A characterization of interventional distributions in semi-Markovian causal models},
  author={Tian, Jin and Kang, Changsung and Pearl, Judea},
  year={2006},
  publisher={eScholarship, University of California}
}

@article{brown1992survivorship,
  title={Survivorship bias in performance studies},
  author={Brown, Stephen J and Goetzmann, William and Ibbotson, Roger G and Ross, Stephen A},
  journal={The Review of Financial Studies},
  volume={5},
  number={4},
  pages={553--580},
  year={1992},
  publisher={Oxford University Press}
}

@article{berk1983introduction,
  title={An introduction to sample selection bias in sociological data},
  author={Berk, Richard A},
  journal={American sociological review},
  pages={386--398},
  year={1983}
}

@book{simmel1950sociology,
  title={The sociology of georg simmel},
  author={Simmel, Georg},
  volume={92892},
  year={1950},
  publisher={Simon and Schuster}
}

@article{shen2021towards,
  title={Towards out-of-distribution generalization: A survey},
  author={Shen, Zheyan and Liu, Jiashuo and He, Yue and Zhang, Xingxuan and Xu, Renzhe and Yu, Han and Cui, Peng},
  journal={arXiv preprint arXiv:2108.13624},
  year={2021}
}

@article{nascimento2021dynamic,
  title={Dynamic graph in a symbolic data framework: An account of the causal relation using COVID-19 reports and some reflections on the financial world},
  author={Nascimento, Diego C and Pimentel, Bruno A and Souza, Renata MCR and Costa, Lilia and Gon{\c{c}}alves, Sandro and Louzada, Francisco},
  journal={Chaos, Solitons \& Fractals},
  volume={153},
  pages={111440},
  year={2021},
  publisher={Elsevier}
}

@inproceedings{zhang2021dyngraphtrans,
  title={DynGraphTrans: Dynamic Graph Embedding via Modified Universal Transformer Networks for Financial Transaction Data},
  author={Zhang, Shilei and Suzumura, Toyotaro and Zhang, Li},
  booktitle={2021 IEEE International Conference on Smart Data Services (SMDS)},
  pages={184--191},
  year={2021},
  organization={IEEE}
}

@inproceedings{berger2006framework,
  title={A framework for analysis of dynamic social networks},
  author={Berger-Wolf, Tanya Y and Saia, Jared},
  booktitle={Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  pages={523--528},
  year={2006}
}

@inproceedings{greene2010tracking,
  title={Tracking the evolution of communities in dynamic social networks},
  author={Greene, Derek and Doyle, Donal and Cunningham, Padraig},
  booktitle={2010 international conference on advances in social networks analysis and mining},
  pages={176--183},
  year={2010},
  organization={IEEE}
}

@article{peng2021dynamic,
  title={Dynamic graph convolutional network for long-term traffic flow prediction with reinforcement learning},
  author={Peng, Hao and Du, Bowen and Liu, Mingsheng and Liu, Mingzhe and Ji, Shumei and Wang, Senzhang and Zhang, Xu and He, Lifang},
  journal={Information Sciences},
  volume={578},
  pages={401--416},
  year={2021},
  publisher={Elsevier}
}

@article{peng2020spatial,
  title={Spatial temporal incidence dynamic graph neural networks for traffic flow forecasting},
  author={Peng, Hao and Wang, Hongfei and Du, Bowen and Bhuiyan, Md Zakirul Alam and Ma, Hongyuan and Liu, Jianwei and Wang, Lihong and Yang, Zeyu and Du, Linfeng and Wang, Senzhang and others},
  journal={Information Sciences},
  volume={521},
  pages={277--290},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{wang2022causal,
  title={Causal Representation Learning for Out-of-Distribution Recommendation},
  author={Wang, Wenjie and Lin, Xinyu and Feng, Fuli and He, Xiangnan and Lin, Min and Chua, Tat-Seng},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={3562--3571},
  year={2022}
}

@article{jin2021community,
  title={Community detection and co-author recommendation in co-author networks},
  author={Jin, Tian and Wu, Qiong and Ou, Xuan and Yu, Jianjun},
  journal={International Journal of Machine Learning and Cybernetics},
  volume={12},
  number={2},
  pages={597--609},
  year={2021},
  publisher={Springer}
}

@inproceedings{ahuja2020empirical,
  author    = {Kartik Ahuja and
               Jun Wang and
               Amit Dhurandhar and
               Karthikeyan Shanmugam and
               Kush R. Varshney},
  title     = {Empirical or Invariant Risk Minimization? {A} Sample Complexity Perspective},
  booktitle = {9th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2021}
}

@article{huang2020graph,
  title={Graph meta learning via local subgraphs},
  author={Huang, Kexin and Zitnik, Marinka},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5862--5874},
  year={2020}
}

@article{li2022out,
  title={Out-Of-Distribution Generalization on Graphs: A Survey},
  author={Li, Haoyang and Wang, Xin and Zhang, Ziwei and Zhu, Wenwu},
  journal={arXiv preprint},
  year={2022}
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  editor    = {Yoshua Bengio and
               Yann LeCun},
  title     = {Adam: {A} Method for Stochastic Optimization},
  booktitle = {3rd International Conference on Learning Representations},
  year      = {2015},
}

@article{paszke2019pytorch,
  title={Pytorch: An imperative style, high-performance deep learning library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
  journal={Advances in neural information processing systems},
  year={2019}
}

@article{ba2016layer,
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}
}

@inproceedings{Fey/Lenssen/2019,
  title={Fast Graph Representation Learning with {PyTorch Geometric}},
  author={Fey, Matthias and Lenssen, Jan E.},
  booktitle={ICLR Workshop on Representation Learning on Graphs and Manifolds},
  year={2019},
}
@inproceedings{chang2020invariant,
  title={Invariant rationalization},
  author={Chang, Shiyu and Zhang, Yang and Yu, Mo and Jaakkola, Tommi},
  booktitle={International Conference on Machine Learning},
  pages={1448--1458},
  year={2020},
  organization={PMLR}
}

@inproceedings{ahuja2020invariant,
  title={Invariant risk minimization games},
  author={Ahuja, Kartik and Shanmugam, Karthikeyan and Varshney, Kush and Dhurandhar, Amit},
  booktitle={International Conference on Machine Learning},
  pages={145--155},
  year={2020},
  organization={PMLR}
}

@inproceedings{rosenfeld2020risks,
  author    = {Elan Rosenfeld and
               Pradeep Kumar Ravikumar and
               Andrej Risteski},
  title     = {The Risks of Invariant Risk Minimization},
  booktitle = {9th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2021}
}


@inproceedings{mitrovic2020representation,
  author    = {Jovana Mitrovic and
               Brian McWilliams and
               Jacob C. Walker and
               Lars Holger Buesing and
               Charles Blundell},
  title     = {Representation Learning via Invariant Causal Mechanisms},
  booktitle = {9th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2021}
}

@article{barrat2004architecture,
  title={The architecture of complex weighted networks},
  author={Barrat, Alain and Barthelemy, Marc and Pastor-Satorras, Romualdo and Vespignani, Alessandro},
  journal={Proceedings of the national academy of sciences},
  volume={101},
  number={11},
  pages={3747--3752},
  year={2004},
  publisher={National Acad Sciences}
}

@inproceedings{Cho2014LearningPR,
  title={Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation},
  author={Kyunghyun Cho and Bart van Merrienboer and Çaglar G{\"u}lçehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
  booktitle={EMNLP},
  year={2014}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{qin2022graph,
  title={Graph Neural Architecture Search Under Distribution Shifts},
  author={Qin, Yijian and Wang, Xin and Zhang, Ziwei and Xie, Pengtao and Zhu, Wenwu},
  booktitle={International Conference on Machine Learning},
  pages={18083--18095},
  year={2022}
}

@article{li2022ood,
  title={Ood-gnn: Out-of-distribution generalized graph neural network},
  author={Li, Haoyang and Wang, Xin and Zhang, Ziwei and Zhu, Wenwu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zhang2022learning,
  author    = {Zeyang Zhang and
               Ziwei Zhang and
               Xin Wang and
               Wenwu Zhu},
  title     = {Learning to Solve Travelling Salesman Problem with Hardness-Adaptive
               Curriculum},
  booktitle = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence},
  pages     = {9136--9144},
  publisher = {{AAAI} Press},
  year      = {2022},
}

@article{bengio2013representation,
  title={Representation learning: A review and new perspectives},
  author={Bengio, Yoshua and Courville, Aaron and Vincent, Pascal},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={35},
  number={8},
  pages={1798--1828},
  year={2013},
  publisher={IEEE}
}

@article{hsieh2018learning,
  title={Learning to decompose and disentangle representations for video prediction},
  author={Hsieh, Jun-Ting and Liu, Bingbin and Huang, De-An and Fei-Fei, Li F and Niebles, Juan Carlos},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{ma2018disentangled,
  title={Disentangled person image generation},
  author={Ma, Liqian and Sun, Qianru and Georgoulis, Stamatios and Van Gool, Luc and Schiele, Bernt and Fritz, Mario},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={99--108},
  year={2018}
}

@inproceedings{ma2019disentangled,
  title={Disentangled graph convolutional networks},
  author={Ma, Jianxin and Cui, Peng and Kuang, Kun and Wang, Xin and Zhu, Wenwu},
  booktitle={International conference on machine learning},
  pages={4212--4221},
  year={2019},
  organization={PMLR}
}

@article{yang2020factorizable,
  title={Factorizable graph convolutional networks},
  author={Yang, Yiding and Feng, Zunlei and Song, Mingli and Wang, Xinchao},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={20286--20296},
  year={2020}
}

@article{wang2022disentangled,
  title={Disentangled Representation Learning for Recommendation},
  author={Wang, Xin and Chen, Hong and Zhou, Yuwei and Ma, Jianxin and Zhu, Wenwu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2022},
  publisher={IEEE}
}

@article{li2021disentangled,
  title={Disentangled contrastive learning on graphs},
  author={Li, Haoyang and Wang, Xin and Zhang, Ziwei and Yuan, Zehuan and Li, Hang and Zhu, Wenwu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={21872--21884},
  year={2021}
}

@article{li2022disentangled,
  title={Disentangled Graph Contrastive Learning With Independence Promotion},
  author={Li, Haoyang and Zhang, Ziwei and Wang, Xin and Zhu, Wenwu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2022},
  publisher={IEEE}
}

@article{chen2021curriculum,
  title={Curriculum Disentangled Recommendation with Noisy Multi-feedback},
  author={Chen, Hong and Chen, Yudong and Wang, Xin and Xie, Ruobing and Wang, Rui and Xia, Feng and Zhu, Wenwu},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={26924--26936},
  year={2021}
}

@inproceedings{wang2021multimodal,
  title={Multimodal disentangled representation for recommendation},
  author={Wang, Xin and Chen, Hong and Zhu, Wenwu},
  booktitle={2021 IEEE International Conference on Multimedia and Expo (ICME)},
  pages={1--6},
  year={2021}
}

@inproceedings{ma2020disentangled,
  title={Disentangled self-supervision in sequential recommenders},
  author={Ma, Jianxin and Zhou, Chang and Yang, Hongxia and Cui, Peng and Wang, Xin and Zhu, Wenwu},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={483--491},
  year={2020}
}

@article{ma2019learning,
  title={Learning disentangled representations for recommendation},
  author={Ma, Jianxin and Zhou, Chang and Cui, Peng and Yang, Hongxia and Zhu, Wenwu},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{wang2020disenhan,
  title={Disenhan: Disentangled heterogeneous graph attention network for recommendation},
  author={Wang, Yifan and Tang, Suyao and Lei, Yuntong and Song, Weiping and Wang, Sheng and Zhang, Ming},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={1605--1614},
  year={2020}
}

@article{chen2016infogan,
  title={Infogan: Interpretable representation learning by information maximizing generative adversarial nets},
  author={Chen, Xi and Duan, Yan and Houthooft, Rein and Schulman, John and Sutskever, Ilya and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@article{denton2017unsupervised,
  title={Unsupervised learning of disentangled representations from video},
  author={Denton, Emily L and others},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{tran2017disentangled,
  title={Disentangled representation learning gan for pose-invariant face recognition},
  author={Tran, Luan and Yin, Xi and Liu, Xiaoming},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={1415--1424},
  year={2017}
}

@inproceedings{liu2020independence,
  title={Independence promoted graph disentangled networks},
  author={Liu, Yanbei and Wang, Xiao and Wu, Shu and Xiao, Zhitao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={04},
  pages={4916--4923},
  year={2020}
}

@inproceedings{zhang2021disentangled,
  title={Disentangled dynamic graph deep generation},
  author={Zhang, Wenbin and Zhang, Liming and Pfoser, Dieter and Zhao, Liang},
  booktitle={Proceedings of the 2021 SIAM International Conference on Data Mining (SDM)},
  pages={738--746},
  year={2021},
  organization={SIAM}
}

@inproceedings{du2022disentangled,
  author    = {Yuanqi Du and
               Xiaojie Guo and
               Hengning Cao and
               Yanfang Ye and
               Liang Zhao},
  title     = {Disentangled Spatiotemporal Graph Generative Models},
  booktitle = {Thirty-Sixth {AAAI} Conference on Artificial Intelligence},
  pages     = {6541--6549},
  publisher = {{AAAI} Press},
  year      = {2022}
}

@article{chen2022invariance,
  title={Invariance Principle Meets Out-of-Distribution Generalization on Graphs},
  author={Chen, Yongqiang and Zhang, Yonggang and Yang, Han and Ma, Kaili and Xie, Binghui and Liu, Tongliang and Han, Bo and Cheng, James},
  journal={arXiv preprint},
  year={2022}
}

@article{fan2021generalizing,
  title={Generalizing Graph Neural Networks on Out-Of-Distribution Graphs},
  author={Fan, Shaohua and Wang, Xiao and Shi, Chuan and Cui, Peng and Wang, Bai},
  journal={arXiv preprint arXiv:2111.10657},
  year={2021}
}

@inproceedings{chang2020continuous,
  title={Continuous-time dynamic graph learning via neural interaction processes},
  author={Chang, Xiaofu and Liu, Xuqin and Wen, Jianfeng and Li, Shuang and Fang, Yanming and Song, Le and Qi, Yuan},
  booktitle={Proceedings of the 29th ACM International Conference on Information \& Knowledge Management},
  pages={145--154},
  year={2020}
}

@inproceedings{huang2021coupled,
  title={Coupled Graph ODE for Learning Interacting System Dynamics.},
  author={Huang, Zijie and Sun, Yizhou and Wang, Wei},
  booktitle={KDD},
  pages={705--715},
  year={2021}
}

@article{li2021intention,
  title={Intention-aware sequential recommendation with structured intent transition},
  author={Li, Haoyang and Wang, Xin and Zhang, Ziwei and Ma, Jianxin and Cui, Peng and Zhu, Wenwu},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  year={2021},
  publisher={IEEE}
}

@inproceedings{cai2021structural,
  title={Structural temporal graph neural networks for anomaly detection in dynamic graphs},
  author={Cai, Lei and Chen, Zhengzhang and Luo, Chen and Gui, Jiaping and Ni, Jingchao and Li, Ding and Chen, Haifeng},
  booktitle={Proceedings of the 30th ACM international conference on Information \& Knowledge Management},
  pages={3747--3756},
  year={2021}
}

@inproceedings{deng2020dynamic,
  title={Dynamic knowledge graph based multi-event forecasting},
  author={Deng, Songgaojun and Rangwala, Huzefa and Ning, Yue},
  booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={1585--1595},
  year={2020}
}

@inproceedings{yao2021interpretable,
  title={Interpretable clustering on dynamic graphs with recurrent graph neural networks},
  author={Yao, Yuhang and Joe-Wong, Carlee},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={35},
  number={5},
  pages={4608--4616},
  year={2021}
}

@inproceedings{you2019hierarchical,
  title={Hierarchical temporal convolutional networks for dynamic recommender systems},
  author={You, Jiaxuan and Wang, Yichen and Pal, Aditya and Eksombatchai, Pong and Rosenburg, Chuck and Leskovec, Jure},
  booktitle={The world wide web conference},
  pages={2236--2246},
  year={2019}
}

@inproceedings{wang2021tedic,
  title={TEDIC: Neural modeling of behavioral patterns in dynamic social interaction networks},
  author={Wang, Yanbang and Li, Pan and Bai, Chongyang and Leskovec, Jure},
  booktitle={Proceedings of the Web Conference 2021},
  pages={693--705},
  year={2021}
}

@inproceedings{wu2020temp,
  author    = {Jiapeng Wu and
               Meng Cao and
               Jackie Chi Kit Cheung and
               William L. Hamilton},
  editor    = {Bonnie Webber and
               Trevor Cohn and
               Yulan He and
               Yang Liu},
  title     = {TeMP: Temporal Message Passing for Temporal Knowledge Graph Completion},
  booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural
               Language Processing, {EMNLP} 2020, Online, November 16-20, 2020},
  pages     = {5730--5746},
  publisher = {Association for Computational Linguistics},
  year      = {2020}
}

@inproceedings{li2019fates,
  title={Fates of Microscopic Social Ecosystems: Keep Alive or Dead?},
  author={Li, Haoyang and Cui, Peng and Zang, Chengxi and Zhang, Tianyang and Zhu, Wenwu and Lin, Yishi},
  booktitle={Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  pages={668--676},
  year={2019}
}

@inproceedings{yao2022wildtime,
  title={Wild-Time: A Benchmark of in-the-Wild Distribution Shift over Time},
  author={Huaxiu Yao and Caroline Choi and Yoonho Lee and Pang Wei Koh and Chelsea Finn},
  booktitle={Proceedings of the Thirty-sixth Conference on Neural Information Processing Systems Datasets and Benchmarks Track},
  year={2022},
}

@inproceedings{yao2022improving,
  title={Improving Out-of-Distribution Robustness via Selective Augmentation},
  author={Yao, Huaxiu and Wang, Yu and Li, Sai and Zhang, Linjun and Liang, Weixin and Zou, James and Finn, Chelsea},
  booktitle={Proceeding of the Thirty-ninth International Conference on Machine Learning},
  year={2022}
}

@inproceedings{li2022gil,
  title={Learning Invariant Graph Representations for Out-of-Distribution Generalization},
  author={Li, Haoyang and Zhang, Ziwei and Wang, Xin and Zhu, Wenwu},
  booktitle={Thirty-Sixth Conference on Neural Information Processing Systems},
  year={2022}
}

@inproceedings{zhang2022dynamic,
  title={Dynamic graph neural networks under spatio-temporal distribution shift},
  author={Zhang, Zeyang and Wang, Xin and Zhang, Ziwei and Li, Haoyang and Qin, Zhou and Zhu, Wenwu},
  booktitle={Advances in Neural Information Processing Systems},
  year={2022}
}

@article{hu2020open,
  title={Open graph benchmark: Datasets for machine learning on graphs},
  author={Hu, Weihua and Fey, Matthias and Zitnik, Marinka and Dong, Yuxiao and Ren, Hongyu and Liu, Bowen and Catasta, Michele and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={22118--22133},
  year={2020}
}

@INPROCEEDINGS{Tang:08KDD,
    AUTHOR = "Jie Tang and Jing Zhang and Limin Yao and Juanzi Li and Li Zhang and Zhong Su",
    TITLE = "ArnetMiner: Extraction and Mining of Academic Social Networks",
    pages = "990-998",
    YEAR = {2008},
    BOOKTITLE = "KDD'08",
}

@inproceedings{sinha2015overview,
  title={An overview of microsoft academic service (mas) and applications},
  author={Sinha, Arnab and Shen, Zhihong and Song, Yang and Ma, Hao and Eide, Darrin and Hsu, Bo-june Paul and Wang, Kuansan},
  booktitle={Proceedings of the 24th international conference on world wide web},
  pages={243--246},
  year={2015},
  organization={ACM}
}

@article{wang2020microsoft,
  title={Microsoft academic graph: When experts are not enough},
  author={Wang, Kuansan and Shen, Zhihong and Huang, Chiyuan and Wu, Chieh-Han and Dong, Yuxiao and Kanakia, Anshul},
  journal={Quantitative Science Studies},
  volume={1},
  number={1},
  pages={396--413},
  year={2020},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{mikolov2013distributed,
  title={Distributed representations of words and phrases and their compositionality},
  author={Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
  journal={Advances in neural information processing systems},
  volume={26},
  year={2013}
}

@inproceedings{kipf2016semi,
  author    = {Thomas N. Kipf and
               Max Welling},
  title     = {Semi-Supervised Classification with Graph Convolutional Networks},
  booktitle = {5th International Conference on Learning Representations},
  publisher = {OpenReview.net},
  year      = {2017}
}

@inproceedings{velivckovicgraph,
  title={Graph Attention Networks},
  author={Veli{\v{c}}kovi{\'c}, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Li{\`o}, Pietro and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations}
}

@ARTICLE{9847099,
  author={Zhou, Kaiyang and Liu, Ziwei and Qiao, Yu and Xiang, Tao and Loy, Chen Change},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Domain Generalization: A Survey}, 
  year={2023},
  number={4},
  pages={4396-4415},
  doi={10.1109/TPAMI.2022.3195549}}

@ARTICLE{9476906,
  author={Christiansen, Rune and Pfister, Niklas and Jakobsen, Martin Emil and Gnecco, Nicola and Peters, Jonas},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A Causal Framework for Distribution Generalization}, 
  year={2022},
  volume={44},
  number={10},
  pages={6614-6630},
  doi={10.1109/TPAMI.2021.3094760}}

@ARTICLE{9801711,
  author={Peng, Xi and Qiao, Fengchun and Zhao, Long},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Out-of-Domain Generalization From a Single Source: An Uncertainty Quantification Approach}, 
  year={2022},
  volume={},
  number={},
  pages={1-13},
  doi={10.1109/TPAMI.2022.3184598}}

@ARTICLE{9792207,
  author={Ao, Sheng and Guo, Yulan and Hu, Qingyong and Yang, Bo and Markham, Andrew and Chen, Zengping},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={You Only Train Once: Learning General and Distinctive 3D Local Descriptors}, 
  year={2023},
  volume={45},
  number={3},
  pages={3949-3967},
  doi={10.1109/TPAMI.2022.3180341}}

@ARTICLE{9556560,
  author={Yao, Zhiyu and Wang, Yunbo and Wang, Jianmin and Yu, Philip S. and Long, Mingsheng},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={VideoDG: Generalizing Temporal Relations in Videos to Novel Domains}, 
  year={2022},
  volume={44},
  number={11},
  pages={7989-8004},
  doi={10.1109/TPAMI.2021.3116945}}

@ARTICLE{9730006,
  author={Tian, Chris Xing and Li, Haoliang and Xie, Xiaofei and Liu, Yang and Wang, Shiqi},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Neuron Coverage-Guided Domain Generalization}, 
  year={2023},
  volume={45},
  number={1},
  pages={1302-1311},
  doi={10.1109/TPAMI.2022.3157441}}

@ARTICLE{9445225,
  author={Azizzadenesheli, Kamyar},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Importance Weight Estimation and Generalization in Domain Adaptation Under Label Shift}, 
  year={2022},
  volume={44},
  number={10},
  pages={6578-6584},
  doi={10.1109/TPAMI.2021.3086060}}

@inproceedings{bevilacqua2021size,
  title={Size-invariant graph representations for graph classification extrapolations},
  author={Bevilacqua, Beatrice and Zhou, Yangze and Ribeiro, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={837--851},
  year={2021}
}

@inproceedings{han2022g,
  title={G-mixup: Graph data augmentation for graph classification},
  author={Han, Xiaotian and Jiang, Zhimeng and Liu, Ninghao and Hu, Xia},
  booktitle={International Conference on Machine Learning},
  pages={8230--8248},
  year={2022}
}

@ARTICLE{9780235,
  author={Xu, Xinyi and Deng, Cheng and Xie, Yaochen and Ji, Shuiwang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Group Contrastive Self-Supervised Learning on Graphs}, 
  year={2023},
  volume={45},
  number={3},
  pages={3169-3180},
  doi={10.1109/TPAMI.2022.3177295}}


@ARTICLE{9875989,
  author={Yuan, Hao and Yu, Haiyang and Gui, Shurui and Ji, Shuiwang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Explainability in Graph Neural Networks: A Taxonomic Survey}, 
  year={2022},
  volume={},
  number={},
  pages={1-19},
  doi={10.1109/TPAMI.2022.3204236}}

@ARTICLE{9764632,
  author={Xie, Yaochen and Xu, Zhao and Zhang, Jingtun and Wang, Zhengyang and Ji, Shuiwang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Self-Supervised Learning of Graph Neural Networks: A Unified Review}, 
  year={2023},
  volume={45},
  number={2},
  pages={2412-2429},
  doi={10.1109/TPAMI.2022.3170559}}

@ARTICLE{9770382,
  author={Liu, Yixin and Jin, Ming and Pan, Shirui and Zhou, Chuan and Zheng, Yu and Xia, Feng and Yu, Philip},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Graph Self-Supervised Learning: A Survey}, 
  year={2022},
  volume={},
  number={},
  pages={1-1},
  doi={10.1109/TKDE.2022.3172903}}

@ARTICLE{9842366,
  author={Guan, Shanyan and Xu, Jingwei and He, Michelle Zhang and Wang, Yunbo and Ni, Bingbing and Yang, Xiaokang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Out-of-Domain Human Mesh Reconstruction via Dynamic Bilevel Online Adaptation}, 
  year={2023},
  volume={45},
  number={4},
  pages={5070-5086},
  doi={10.1109/TPAMI.2022.3194167}}

@ARTICLE{9154576,
  author={Zhang, Ziyuan and Tran, Luan and Liu, Feng and Liu, Xiaoming},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={On Learning Disentangled Representations for Gait Recognition}, 
  year={2022},
  volume={44},
  number={1},
  pages={345-360},
  doi={10.1109/TPAMI.2020.2998790}}

@ARTICLE{9716806,
  author={Wang, Yingqian and Wang, Longguang and Wu, Gaochang and Yang, Jungang and An, Wei and Yu, Jingyi and Guo, Yulan},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Disentangling Light Fields for Super-Resolution and Disparity Estimation}, 
  year={2023},
  volume={45},
  number={1},
  pages={425-443},
  doi={10.1109/TPAMI.2022.3152488}}

@ARTICLE{9495181,
  author={Bai, Yan and Liu, Jun and Lou, Yihang and Wang, Ce and Duan, Ling-Yu},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Disentangled Feature Learning Network and a Comprehensive Benchmark for Vehicle Re-Identification}, 
  year={2022},
  volume={44},
  number={10},
  pages={6854-6871},
  doi={10.1109/TPAMI.2021.3099253}}

@ARTICLE{9241434,
  author={Shen, Yujun and Yang, Ceyuan and Tang, Xiaoou and Zhou, Bolei},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={InterFaceGAN: Interpreting the Disentangled Face Representation Learned by GANs}, 
  year={2022},
  volume={44},
  number={4},
  pages={2004-2018},
  doi={10.1109/TPAMI.2020.3034267}}

@ARTICLE{9200697,
  author={Simonelli, Andrea and Bulò, Samuel Rota and Porzi, Lorenzo and Antequera, Manuel López and Kontschieder, Peter},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Disentangling Monocular 3D Object Detection: From Single to Multi-Class Recognition}, 
  year={2022},
  volume={44},
  number={3},
  pages={1219-1231},
  doi={10.1109/TPAMI.2020.3025077}}

@ARTICLE{9585547,
  author={Eom, Chanho and Lee, Wonkyung and Lee, Geon and Ham, Bumsub},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Disentangled Representations for Short-Term and Long-Term Person Re-Identification}, 
  year={2022},
  volume={44},
  number={12},
  pages={8975-8991},
  doi={10.1109/TPAMI.2021.3122444}}

@article{wang2024omnidrive,
  title={Omnidrive: A holistic llm-agent framework for autonomous driving with 3d perception, reasoning and planning},
  author={Wang, Shihao and Yu, Zhiding and Jiang, Xiaohui and Lan, Shiyi and Shi, Min and Chang, Nadine and Kautz, Jan and Li, Ying and Alvarez, Jose M},
  journal={arXiv preprint arXiv:2405.01533},
  year={2024}
}

@inproceedings{zhong2024memorybank,
  title={Memorybank: Enhancing large language models with long-term memory},
  author={Zhong, Wanjun and Guo, Lianghong and Gao, Qiqi and Ye, He and Wang, Yanlin},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19724--19731},
  year={2024}
}

@article{packer2023memgpt,
  title={MemGPT: Towards LLMs as Operating Systems.},
  author={Packer, Charles and Fang, Vivian and Patil, Shishir\_G and Lin, Kevin and Wooders, Sarah and Gonzalez, Joseph\_E},
  year={2023},
  publisher={arXiv}
}

@article{hu2023chatdb,
  title={Chatdb: Augmenting llms with databases as their symbolic memory},
  author={Hu, Chenxu and Fu, Jie and Du, Chenzhuang and Luo, Simian and Zhao, Junbo and Zhao, Hang},
  journal={arXiv preprint arXiv:2306.03901},
  year={2023}
}

@article{lu2023memochat,
  title={Memochat: Tuning llms to use memos for consistent long-range open-domain conversation},
  author={Lu, Junru and An, Siyu and Lin, Mingbao and Pergola, Gabriele and He, Yulan and Yin, Di and Sun, Xing and Wu, Yunsheng},
  journal={arXiv preprint arXiv:2308.08239},
  year={2023}
}

@article{li2023metaagents,
  title={Metaagents: Simulating interactions of human behaviors for llm-based task-oriented coordination via collaborative generative agents},
  author={Li, Yuan and Zhang, Yixuan and Sun, Lichao},
  journal={arXiv preprint arXiv:2310.06500},
  year={2023}
}

@article{gao2023s3,
  title={S3: Social-network simulation system with large language model-empowered agents},
  author={Gao, Chen and Lan, Xiaochong and Lu, Zhihong and Mao, Jinzhu and Piao, Jinghua and Wang, Huandong and Jin, Depeng and Li, Yong},
  journal={arXiv preprint arXiv:2307.14984},
  year={2023}
}

@article{wang2023recmind,
  title={Recmind: Large language model powered agent for recommendation},
  author={Wang, Yancheng and Jiang, Ziyan and Chen, Zheng and Yang, Fan and Zhou, Yingxue and Cho, Eunah and Fan, Xing and Huang, Xiaojiang and Lu, Yanbin and Yang, Yingzhen},
  journal={arXiv preprint arXiv:2308.14296},
  year={2023}
}

@inproceedings{zhao2024expel,
  title={Expel: Llm agents are experiential learners},
  author={Zhao, Andrew and Huang, Daniel and Xu, Quentin and Lin, Matthieu and Liu, Yong-Jin and Huang, Gao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={17},
  pages={19632--19642},
  year={2024}
}



@article{modarressi2024memllm,
  title={Memllm: Finetuning llms to use an explicit read-write memory},
  author={Modarressi, Ali and K{\"o}ksal, Abdullatif and Imani, Ayyoob and Fayyaz, Mohsen and Sch{\"u}tze, Hinrich},
  journal={arXiv preprint arXiv:2404.11672},
  year={2024}
}

@inproceedings{chen2024driving,
  title={Driving with llms: Fusing object-level vector modality for explainable autonomous driving},
  author={Chen, Long and Sinavski, Oleg and H{\"u}nermann, Jan and Karnsund, Alice and Willmott, Andrew James and Birch, Danny and Maund, Daniel and Shotton, Jamie},
  booktitle={2024 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={14093--14100},
  year={2024},
  organization={IEEE}
}

@inproceedings{sun2024optimizing,
  title={Optimizing autonomous driving for safety: A human-centric approach with llm-enhanced rlhf},
  author={Sun, Yuan and Salami Pargoo, Navid and Jin, Peter and Ortiz, Jorge},
  booktitle={Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
  pages={76--80},
  year={2024}
}

@inproceedings{yang2024embodied,
  title={Embodied multi-modal agent trained by an llm from a parallel textworld},
  author={Yang, Yijun and Zhou, Tianyi and Li, Kanxue and Tao, Dapeng and Li, Lusong and Shen, Li and He, Xiaodong and Jiang, Jing and Shi, Yuhui},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={26275--26285},
  year={2024}
}

@article{li2024embodied,
  title={Embodied agent interface: Benchmarking llms for embodied decision making},
  author={Li, Manling and Zhao, Shiyu and Wang, Qineng and Wang, Kangrui and Zhou, Yu and Srivastava, Sanjana and Gokmen, Cem and Lee, Tony and Li, Erran Li and Zhang, Ruohan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={37},
  pages={100428--100534},
  year={2024}
}

@article{zheng2023steve,
  title={Steve-eye: Equipping llm-based embodied agents with visual perception in open worlds},
  author={Zheng, Sipeng and Liu, Jiazheng and Feng, Yicheng and Lu, Zongqing},
  journal={arXiv preprint arXiv:2310.13255},
  year={2023}
}


@inproceedings{wei2024editable,
  title={Editable scene simulation for autonomous driving via collaborative llm-agents},
  author={Wei, Yuxi and Wang, Zi and Lu, Yifan and Xu, Chenxin and Liu, Changxing and Zhao, Hao and Chen, Siheng and Wang, Yanfeng},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15077--15087},
  year={2024}
}

@inproceedings{liu2021heterogeneous,
  title={Heterogeneous risk minimization},
  author={Liu, Jiashuo and Hu, Zheyuan and Cui, Peng and Li, Bo and Shen, Zheyan},
  booktitle={International Conference on Machine Learning},
  pages={6804--6814},
  year={2021},
  organization={PMLR}
}

@article{yue2025masrouter,
  title={Masrouter: Learning to route llms for multi-agent systems},
  author={Yue, Yanwei and Zhang, Guibin and Liu, Boyang and Wan, Guancheng and Wang, Kun and Cheng, Dawei and Qi, Yiyan},
  journal={arXiv preprint arXiv:2502.11133},
  year={2025}
}

@article{wang2024battleagentbench,
  title={Battleagentbench: A benchmark for evaluating cooperation and competition capabilities of language models in multi-agent systems},
  author={Wang, Wei and Zhang, Dan and Feng, Tao and Wang, Boyan and Tang, Jie},
  journal={arXiv preprint arXiv:2408.15971},
  year={2024}
}

@article{10.1145/3604427,
author = {Li, Haoyang and Zhang, Ziwei and Wang, Xin and Zhu, Wenwu},
title = {Invariant Node Representation Learning under Distribution Shifts with Multiple Latent Environments},
year = {2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3604427},
doi = {10.1145/3604427},
abstract = {Node representation learning methods, such as graph neural networks, show promising results when testing and training graph data come from the same distribution. However, the existing approaches fail to generalize under distribution shifts when the nodes reside in multiple latent environments. How to learn invariant node representations to handle distribution shifts with multiple latent environments remains unexplored. In this paper, we propose a novel Invariant Node representation Learning (INL) approach capable of generating invariant node representations based on the invariant patterns under distribution shifts with multiple latent environments by leveraging the invariance principle. Specifically, we define invariant and variant patterns as ego-subgraphs of each node, and identify the invariant ego-subgraphs through jointly accounting for node features and graph structures. In order to infer the latent environments of nodes, we propose a contrastive modularity-based graph clustering method based on the variant patterns. We further propose an invariant learning module to learn node representations that can generalize to distribution shifts. We theoretically show that our proposed method can achieve guaranteed performance under distribution shifts. Extensive experiments on both synthetic and real-world node classification benchmarks demonstrate that our method greatly outperforms state-of-the-art baselines under distribution shifts.},
note = {Just Accepted},
journal = {ACM Transactions on Information Systems (TOIS)},
month = {jun},
keywords = {Node Representation Learning, Graph Neural Networks, Distribution Shift}
}


@article{cai2023user,
  title={User cold-start recommendation via inductive heterogeneous graph neural network},
  author={Cai, Desheng and Qian, Shengsheng and Fang, Quan and Hu, Jun and Xu, Changsheng},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={41},
  number={3},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@article{chen2020neural,
  title={Neural feature-aware recommendation with signed hypergraph convolutional network},
  author={Chen, Xu and Xiong, Kun and Zhang, Yongfeng and Xia, Long and Yin, Dawei and Huang, Jimmy Xiangji},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={39},
  number={1},
  pages={1--22},
  year={2020},
  publisher={ACM New York, NY, USA}
}

@article{huang2023position,
  title={Position-enhanced and time-aware graph convolutional network for sequential recommendations},
  author={Huang, Liwei and Ma, Yutao and Liu, Yanbo and Danny Du, Bohong and Wang, Shuliang and Li, Deyi},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={41},
  number={1},
  pages={1--32},
  year={2023},
  publisher={ACM New York, NY}
}

@article{ma2023kr,
  title={Kr-gcn: Knowledge-aware reasoning with graph convolution network for explainable recommendation},
  author={Ma, Ting and Huang, Longtao and Lu, Qianqian and Hu, Songlin},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={41},
  number={1},
  pages={1--27},
  year={2023},
  publisher={ACM New York, NY}
}

@article{yang2021hgat,
  title={HGAT: Heterogeneous graph attention networks for semi-supervised short text classification},
  author={Yang, Tianchi and Hu, Linmei and Shi, Chuan and Ji, Houye and Li, Xiaoli and Nie, Liqiang},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={39},
  number={3},
  pages={1--29},
  year={2021},
  publisher={ACM New York, NY}
}

@article{zhang2022efraudcom,
  title={efraudcom: An e-commerce fraud detection system via competitive graph neural networks},
  author={Zhang, Ge and Li, Zhao and Huang, Jiaming and Wu, Jia and Zhou, Chuan and Yang, Jian and Gao, Jianliang},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={40},
  number={3},
  pages={1--29},
  year={2022},
  publisher={ACM New York, NY}
}

@article{zitnik2018modeling,
  title={Modeling polypharmacy side effects with graph convolutional networks},
  author={Zitnik, Marinka and Agrawal, Monica and Leskovec, Jure},
  journal={Bioinformatics},
  volume={34},
  number={13},
  pages={i457--i466},
  year={2018},
  publisher={Oxford University Press}
}

@article{li2022graph,
  title={Graph representation learning in biomedicine and healthcare},
  author={Li, Michelle M and Huang, Kexin and Zitnik, Marinka},
  journal={Nature Biomedical Engineering},
  volume={6},
  number={12},
  pages={1353--1369},
  year={2022},
  publisher={Nature Publishing Group UK London}
}

@article{li2023preference,
  title={Preference-aware Graph Attention Networks for Cross-Domain Recommendations with Collaborative Knowledge Graph},
  author={Li, Yakun and Hou, Lei and Li, Juanzi},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={41},
  number={3},
  pages={1--26},
  year={2023},
  publisher={ACM New York, NY}
}

@article{xie2021graph,
  title={Graph neural collaborative topic model for citation recommendation},
  author={Xie, Qianqian and Zhu, Yutao and Huang, Jimin and Du, Pan and Nie, Jian-Yun},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={40},
  number={3},
  pages={1--30},
  year={2021},
  publisher={ACM New York, NY}
}

@article{wang2021combining,
  title={Combining graph convolutional neural networks and label propagation},
  author={Wang, Hongwei and Leskovec, Jure},
  journal={ACM Transactions on Information Systems (TOIS)},
  volume={40},
  number={4},
  pages={1--27},
  year={2021},
  publisher={ACM New York, NY}
}


@inproceedings{bi2023predicting,
  title={Predicting the silent majority on graphs: Knowledge transferable graph neural network},
  author={Bi, Wendong and Xu, Bingbing and Sun, Xiaoqian and Xu, Li and Shen, Huawei and Cheng, Xueqi},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={274--285},
  year={2023}
}

@inproceedings{wu2020dynamic,
  title={Dynamic graph convolutional networks for entity linking},
  author={Wu, Junshuang and Zhang, Richong and Mao, Yongyi and Guo, Hongyu and Soflaei, Masoumeh and Huai, Jinpeng},
  booktitle={Proceedings of The ACM Web Conference 2020},
  pages={1149--1159},
  year={2020}
}

@inproceedings{taheri2019learning,
  title={Learning to represent the evolution of dynamic graphs with recurrent models},
  author={Taheri, Aynaz and Gimpel, Kevin and Berger-Wolf, Tanya},
  booktitle={Proceedings of the ACM Web Conference 2019},
  pages={301--307},
  year={2019}
}

@inproceedings{bai2023hgwavenet,
  title={HGWaveNet: A Hyperbolic Graph Neural Network for Temporal Link Prediction},
  author={Bai, Qijie and Nie, Changli and Zhang, Haiwei and Zhao, Dongming and Yuan, Xiaojie},
  booktitle={Proceedings of the ACM Web Conference 2023},
  pages={523--532},
  year={2023}
}

@inproceedings{liu2022confidence,
  title={Confidence may cheat: Self-training on graph neural networks under distribution shift},
  author={Liu, Hongrui and Hu, Binbin and Wang, Xiao and Shi, Chuan and Zhang, Zhiqiang and Zhou, Jun},
  booktitle={Proceedings of the ACM Web Conference 2022},
  pages={1248--1258},
  year={2022}
}

@inproceedings{tang2023dynamic,
  title={Dynamic Graph Evolution Learning for Recommendation},
  author={Tang, Haoran and Wu, Shiqing and Xu, Guandong and Li, Qing},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={1589--1598},
  year={2023}
}

@inproceedings{fu2021sdg,
  title={Sdg: A simplified and dynamic graph neural network},
  author={Fu, Dongqi and He, Jingrui},
  booktitle={Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2273--2277},
  year={2021}
}

@inproceedings{wang2022disenctr,
  title={DisenCTR: Dynamic graph-based disentangled representation for click-through rate prediction},
  author={Wang, Yifan and Qin, Yifang and Sun, Fang and Zhang, Bo and Hou, Xuyang and Hu, Ke and Cheng, Jia and Lei, Jun and Zhang, Ming},
  booktitle={Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={2314--2318},
  year={2022}
}

@inproceedings{zhao2023time,
  title={Time-interval Aware Share Recommendation via Bi-directional Continuous Time Dynamic Graphs},
  author={Zhao, Ziwei and Zhu, Xi and Xu, Tong and Lizhiyu, Aakas and Yu, Yu and Li, Xueying and Yin, Zikai and Chen, Enhong},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={822--831},
  year={2023}
}

@inproceedings{yang2023generic,
  title={A Generic Learning Framework for Sequential Recommendation with Distribution Shifts},
  author={Yang, Zhengyi and He, Xiangnan and Zhang, Jizhi and Wu, Jiancan and Xin, Xin and Chen, Jiawei and Wang, Xiang},
  booktitle={Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year={2023}
}

@inproceedings{gao2023alleviating,
  title={Alleviating structural distribution shift in graph anomaly detection},
  author={Gao, Yuan and Wang, Xiang and He, Xiangnan and Liu, Zhenguang and Feng, Huamin and Zhang, Yongdong},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={357--365},
  year={2023}
}

@inproceedings{liu2023good,
  title={Good-d: On unsupervised graph out-of-distribution detection},
  author={Liu, Yixin and Ding, Kaize and Liu, Huan and Pan, Shirui},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={339--347},
  year={2023}
}

@inproceedings{yang2023interpretable,
  title={Interpretable Research Interest Shift Detection with Temporal Heterogeneous Graphs},
  author={Yang, Qiang and Ma, Changsheng and Zhang, Qiannan and Gao, Xin and Zhang, Chuxu and Zhang, Xiangliang},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={321--329},
  year={2023}
}

@inproceedings{wang2023tutorial,
  title={A Tutorial on Domain Generalization},
  author={Wang, Jindong and Li, Haoliang and Pan, Sinno and Xie, Xing},
  booktitle={Proceedings of the Sixteenth ACM International Conference on Web Search and Data Mining},
  pages={1236--1239},
  year={2023}
}

@inproceedings{chen2022learning,
  title={Learning to generalize in heterogeneous federated networks},
  author={Chen, Cen and Ye, Tiandi and Wang, Li and Gao, Ming},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={159--168},
  year={2022}
}

@inproceedings{wang2022adagcl,
  title={AdaGCL: Adaptive Subgraph Contrastive Learning to Generalize Large-scale Graph Training},
  author={Wang, Yili and Zhou, Kaixiong and Miao, Rui and Liu, Ninghao and Wang, Xin},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={2046--2055},
  year={2022}
}

@inproceedings{wang2022imbalanced,
  title={Imbalanced graph classification via graph-of-graph neural networks},
  author={Wang, Yu and Zhao, Yuying and Shah, Neil and Derr, Tyler},
  booktitle={Proceedings of the 31st ACM International Conference on Information \& Knowledge Management},
  pages={2067--2076},
  year={2022}
}

@inproceedings{wang2019heterogeneous,
  title={Heterogeneous graph attention network},
  author={Wang, Xiao and Ji, Houye and Shi, Chuan and Wang, Bai and Ye, Yanfang and Cui, Peng and Yu, Philip S},
  booktitle={The world wide web conference},
  pages={2022--2032},
  year={2019}
}

@inproceedings{wang2017community,
  title={Community preserving network embedding},
  author={Wang, Xiao and Cui, Peng and Wang, Jing and Pei, Jian and Zhu, Wenwu and Yang, Shiqiang},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={31},
  number={1},
  year={2017}
}

@article{zhou2020graph,
  title={Graph neural networks: A review of methods and applications},
  author={Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  journal={AI open},
  volume={1},
  pages={57--81},
  year={2020},
  publisher={Elsevier}
}

@article{wu2020comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Philip, S Yu},
  journal={IEEE transactions on neural networks and learning systems},
  volume={32},
  number={1},
  pages={4--24},
  year={2020},
  publisher={IEEE}
}

@article{xu2018powerful,
  title={How powerful are graph neural networks?},
  author={Xu, Keyulu and Hu, Weihua and Leskovec, Jure and Jegelka, Stefanie},
  journal={arXiv preprint arXiv:1810.00826},
  year={2018}
}

@inproceedings{zhang2023graph,
  title={Graph meets llms: Towards large graph models},
  author={Zhang, Ziwei and Li, Haoyang and Zhang, Zeyang and Qin, Yijian and Wang, Xin and Zhu, Wenwu},
  booktitle={NeurIPS 2023 Workshop: New Frontiers in Graph Learning},
  year={2023}
}

@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}


@misc{debate2-thu,
   author = {Liang, Tian and He, Zhiwei and Jiao, Wenxiang and Wang, Xing and Wang, Yan and Wang, Rui and Yang, Yujiu and Tu, Zhaopeng and Shi, Shuming},
   title = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
   pages = {arXiv:2305.19118},
   month = {May 01, 2023},
   note = {Work in progress},
   abstract = {Modern large language models (LLMs) like ChatGPT have shown remarkable performance on general language tasks but still struggle on complex reasoning tasks, which drives the research on cognitive behaviors of LLMs to explore human-like problem-solving strategies. Along this direction, one representative strategy is self-reflection, which asks an LLM to refine the solution with the feedback generated by itself iteratively. However, our study shows that such reflection-style methods suffer from the Degeneration-of-Thought (DoT) problem: once the LLM has established confidence in its solutions, it is unable to generate novel thoughts later through reflection even if its initial stance is incorrect. To address the DoT problem, we propose a Multi-Agent Debate (MAD) framework, in which multiple agents express their arguments in the state of "tit for tat" and a judge manages the debate process to obtain a final solution. Clearly, our MAD framework encourages divergent thinking in LLMs which would be helpful for tasks that require deep levels of contemplation. Experiment results on two challenging datasets, commonsense machine translation and counter-intuitive arithmetic reasoning, demonstrate the effectiveness of our MAD framework. Extensive analyses suggest that the adaptive break of debate and the modest level of "tit for tat" state are required for MAD to obtain good performance. Moreover, we find that LLMs might not be a fair judge if different LLMs are used for agents. Codes: https://github.com/Skytliang/Multi-Agents-Debate},
   keywords = {Computer Science - Computation and Language},
   year = {2023},
   type = {Electronic Article}
}

@misc{PHPrompting,
   author = {Zheng, Chuanyang and Liu, Zhengying and Xie, Enze and Li, Zhenguo and Li, Yu},
   title = {Progressive-Hint Prompting Improves Reasoning in Large Language Models},
   pages = {arXiv:2304.09797},
   month = {April 01, 2023},
   note = {Tech Report},
   abstract = {The performance of Large Language Models (LLMs) in reasoning tasks depends heavily on prompt design, with Chain-of-Thought (CoT) and self-consistency being critical methods that enhance this ability. However, these methods do not fully exploit the answers generated by the LLM to guide subsequent responses. This paper proposes a new prompting method, named Progressive-Hint Prompting (PHP), that enables automatic multiple interactions between users and LLMs by using previously generated answers as hints to progressively guide toward the correct answers. PHP is orthogonal to CoT and self-consistency, making it easy to combine with state-of-the-art techniques to further improve performance. We conducted extensive and comprehensive experiments on seven benchmarks. The results show that PHP significantly improves accuracy while remaining highly efficient. For instance, with text-davinci-003, we observed a 4.2% improvement on GSM8K with greedy decoding compared to Complex CoT, and a 46.17% reduction in sample paths with self-consistency. With GPT-4 and PHP, we achieve state-of-the-art performances on SVAMP (89.1% -> 91.9%), GSM8K (92% -> 95.5%), AQuA (76.4% -> 79.9%) and MATH (50.3% -> 53.9%).},
   keywords = {Computer Science - Computation and Language
Computer Science -
Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@inproceedings{blender,
    title = "{LLM}-Blender: Ensembling Large Language Models with Pairwise Ranking and Generative Fusion",
    author = "Jiang, Dongfu  and
      Ren, Xiang  and
      Lin, Bill Yuchen",
    booktitle = "Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    pages = "14165--14178",
    abstract = "We present LLM-Blender, an ensembling framework designed to attain consistently superior performance by leveraging the diverse strengths of multiple open-source large language models (LLMs). Our framework consists of two modules: PairRanker and GenFuser, addressing the observation that optimal LLMs for different examples can significantly vary. PairRanker employs a specialized pairwise comparison method to distinguish subtle differences between candidate outputs. It jointly encodes the input text and a pair of candidates, using cross-attention encoders to determine the superior one. Our results demonstrate that PairRanker exhibits the highest correlation with ChatGPT-based ranking. Then, GenFuser aims to merge the top-ranked candidates, generating an improved output by capitalizing on their strengths and mitigating their weaknesses. To facilitate large-scale evaluation, we introduce a benchmark dataset, MixInstruct, which is a mixture of multiple instruction datasets featuring oracle pairwise comparisons. Our LLM-Blender significantly outperform individual LLMs and baseline methods across various metrics, establishing a substantial performance gap.",
}

@book{bondy1976graph,
  title={Graph theory with applications},
  author={Bondy, John Adrian and Murty, Uppaluri Siva Ramachandra and others},
  volume={290},
  year={1976},
  publisher={Macmillan London}
}

@inproceedings{
wang2023selfconsistency,
title={Self-Consistency Improves Chain of Thought Reasoning in Language Models},
author={Xuezhi Wang and Jason Wei and Dale Schuurmans and Quoc V Le and Ed H. Chi and Sharan Narang and Aakanksha Chowdhery and Denny Zhou},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@inproceedings{spielman2008graph,
  title={Graph sparsification by effective resistances},
  author={Spielman, Daniel A and Srivastava, Nikhil},
  booktitle={Proceedings of the fortieth annual ACM symposium on Theory of computing},
  pages={563--568},
  year={2008}
}

@inproceedings{chen2021unified,
  title={A unified lottery ticket hypothesis for graph neural networks},
  author={Chen, Tianlong and Sui, Yongduo and Chen, Xuxi and Zhang, Aston and Wang, Zhangyang},
  booktitle={International conference on machine learning},
  pages={1695--1706},
  year={2021},
  organization={PMLR}
}

@inproceedings{zhang2024graph,
  title={Graph lottery ticket automated},
  author={Zhang, Guibin and Wang, Kun and Huang, Wei and Yue, Yanwei and Wang, Yang and Zimmermann, Roger and Zhou, Aojun and Cheng, Dawei and Zeng, Jin and Liang, Yuxuan},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@inproceedings{achille2018critical,
  title={Critical learning periods in deep networks},
  author={Achille, Alessandro and Rovere, Matteo and Soatto, Stefano},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@inproceedings{entezari2020all,
  title={All you need is low (rank) defending against adversarial attacks on graphs},
  author={Entezari, Negin and Al-Sayouri, Saba A and Darvishzadeh, Amirali and Papalexakis, Evangelos E},
  booktitle={Proceedings of the 13th international conference on web search and data mining},
  pages={169--177},
  year={2020}
}

@inproceedings{ennadir2024simple,
  title={A Simple and Yet Fairly Effective Defense for Graph Neural Networks},
  author={Ennadir, Sofiane and Abbahaddou, Yassine and Lutzeyer, Johannes F and Vazirgiannis, Michalis and Bostr{\"o}m, Henrik},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={19},
  pages={21063--21071},
  year={2024}
}

@inproceedings{alchihabi2023efficient,
  title={Efficient Low-Rank GNN Defense Against Structural Attacks},
  author={Alchihabi, Abdullah and En, Qing and Guo, Yuhong},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@article{you2019drawing,
  title={Drawing early-bird tickets: Towards more efficient training of deep networks},
  author={You, Haoran and Li, Chaojian and Xu, Pengfei and Fu, Yonggan and Wang, Yue and Chen, Xiaohan and Baraniuk, Richard G and Wang, Zhangyang and Lin, Yingyan},
  journal={arXiv preprint arXiv:1909.11957},
  year={2019}
}

@article{zhang2024two,
  title={Two heads are better than one: Boosting graph sparse training via semantic and topological awareness},
  author={Zhang, Guibin and Yue, Yanwei and Wang, Kun and Fang, Junfeng and Sui, Yongduo and Wang, Kai and Liang, Yuxuan and Cheng, Dawei and Pan, Shirui and Chen, Tianlong},
  journal={arXiv preprint arXiv:2402.01242},
  year={2024}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@article{li2023api,
  title={Api-bank: A comprehensive benchmark for tool-augmented llms},
  author={Li, Minghao and Zhao, Yingxiu and Yu, Bowen and Song, Feifan and Li, Hangyu and Yu, Haiyang and Li, Zhoujun and Huang, Fei and Li, Yongbin},
  journal={arXiv preprint arXiv:2304.08244},
  year={2023}
}

@article{wang2023brave,
  title={Brave the wind and the waves: Discovering robust and generalizable graph lottery tickets},
  author={Wang, Kun and Liang, Yuxuan and Li, Xinglin and Li, Guohao and Ghanem, Bernard and Zimmermann, Roger and Yi, Huahui and Zhang, Yudong and Wang, Yang and others},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2023},
  publisher={IEEE}
}

@article{chen2023demystifying,
  title={Demystifying graph sparsification algorithms in graph properties preservation},
  author={Chen, Yuhan and Ye, Haojie and Vedula, Sanketh and Bronstein, Alex and Dreslinski, Ronald and Mudge, Trevor and Talati, Nishil},
  journal={Proceedings of the VLDB Endowment},
  volume={17},
  number={3},
  pages={427--440},
  year={2023},
  publisher={VLDB Endowment}
}

@ARTICLE{augmented-lm-survey,
       author = {{Mialon}, Gr{\'e}goire and {Dess{\`\i}}, Roberto and {Lomeli}, Maria and {Nalmpantis}, Christoforos and {Pasunuru}, Ram and {Raileanu}, Roberta and {Rozi{\`e}re}, Baptiste and {Schick}, Timo and {Dwivedi-Yu}, Jane and {Celikyilmaz}, Asli and {Grave}, Edouard and {LeCun}, Yann and {Scialom}, Thomas},
        title = "{Augmented Language Models: a Survey}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2023,
        month = feb,
          eid = {arXiv:2302.07842},
        pages = {arXiv:2302.07842},
archivePrefix = {arXiv},
       eprint = {2302.07842},
 primaryClass = {cs.CL},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{audio-gpt,
   author = {Huang, Rongjie and Li, Mingze and Yang, Dongchao and Shi, Jiatong and Chang, Xuankai and Ye, Zhenhui and Wu, Yuning and Hong, Zhiqing and Huang, Jiawei and Liu, Jinglin and Ren, Yi and Zhao, Zhou and Watanabe, Shinji},
   title = {AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head},
   pages = {arXiv:2304.12995},
   month = {April 01, 2023},
   abstract = {Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \url{https://github.com/AIGC-Audio/AudioGPT}.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence
Computer Science - Sound
Electrical
Engineering and Systems Science - Audio and Speech Processing},
   year = {2023},
   type = {Electronic Article}
}

@misc{visual-gpt,
   author = {Chen, Jun and Guo, Han and Yi, Kai and Li, Boyang and Elhoseiny, Mohamed},
   title = {VisualGPT: Data-efficient Adaptation of Pretrained Language Models for Image Captioning},
   pages = {arXiv:2102.10407},
   month = {February 01, 2021},
   abstract = {The ability to quickly learn from a small quantity oftraining data widens the range of machine learning applications. In this paper, we propose a data-efficient image captioning model, VisualGPT, which leverages the linguistic knowledge from a large pretrained language model(LM). A crucial challenge is to balance between the use of visual information in the image and prior linguistic knowledge acquired from pretraining. We designed a novel self-resurrecting encoder-decoder attention mechanism to quickly adapt the pretrained LM as the language decoder ona small amount of in-domain training data. The proposed self-resurrecting activation unit produces sparse activations but has reduced susceptibility to zero gradients. We train the proposed model, VisualGPT, on 0.1%, 0.5% and 1% of MSCOCO and Conceptual Captions training data. Under these conditions, we outperform the best baseline model by up to 10.8% CIDEr on MS COCO and upto 5.4% CIDEr on Conceptual Captions. Further, Visual-GPT achieves the state-of-the-art result on IU X-ray, a medical report generation dataset. To the best of our knowledge, this is the first work that improves data efficiency of image captioning by utilizing LM pretrained on unimodal data. Our code is available at: https://github.com/Vision-CAIR/VisualGPT.},
   keywords = {Computer Science - Computer Vision and Pattern Recognition
Computer
Science - Artificial Intelligence
Computer Science - Computation and
Language
Computer Science - Multimedia},
   year = {2021},
   type = {Electronic Article}
}

@ARTICLE{neural-sequence,
       author = {{Dabagia}, Max and {Papadimitriou}, Christos H. and {Vempala}, Santosh S.},
        title = "{Computation with Sequences in the Brain}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Neural and Evolutionary Computing, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition},
         year = 2023,
        month = jun,
          eid = {arXiv:2306.03812},
        pages = {arXiv:2306.03812},
archivePrefix = {arXiv},
       eprint = {2306.03812},
 primaryClass = {cs.NE},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{khattab2023dspy,
  title={Dspy: Compiling declarative language model calls into self-improving pipelines},
  author={Khattab, Omar and Singhvi, Arnav and Maheshwari, Paridhi and Zhang, Zhiyuan and Santhanam, Keshav and Vardhamanan, Sri and Haq, Saiful and Sharma, Ashutosh and Joshi, Thomas T and Moazam, Hanna and others},
  journal={arXiv preprint arXiv:2310.03714},
  year={2023}
}

@article{RUC2024agent-memory,
  title={A survey on the memory mechanism of large language model based agents},
  author={Zhang, Zeyu and Bo, Xiaohe and Ma, Chen and Li, Rui and Chen, Xu and Dai, Quanyu and Zhu, Jieming and Dong, Zhenhua and Wen, Ji-Rong},
  journal={arXiv preprint arXiv:2404.13501},
  year={2024}
}

@article{yang2023investlm,
  title={Investlm: A large language model for investment using financial domain instruction tuning},
  author={Yang, Yi and Tang, Yixuan and Tam, Kar Yan},
  journal={arXiv preprint arXiv:2309.13064},
  year={2023}
}

@article{li2024survey-mas,
  title={A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges},
  author={Li, Xinyi and Wang, Sai and Zeng, Siqi and Wu, Yu and Yang, Yi},
  journal={Vicinagearth},
  volume={1},
  number={1},
  pages={9},
  year={2024},
  publisher={Springer}
}

@article{zhu2023ghost,
  title={Ghost in the minecraft: Generally capable agents for open-world environments via large language models with text-based knowledge and memory},
  author={Zhu, Xizhou and Chen, Yuntao and Tian, Hao and Tao, Chenxin and Su, Weijie and Yang, Chenyu and Huang, Gao and Li, Bin and Lu, Lewei and Wang, Xiaogang and others},
  journal={arXiv preprint arXiv:2305.17144},
  year={2023}
}

@article{zheng2023synapse,
  title={Synapse: Trajectory-as-exemplar prompting with memory for computer control},
  author={Zheng, Longtao and Wang, Rundong and Wang, Xinrun and An, Bo},
  journal={arXiv preprint arXiv:2306.07863},
  year={2023}
}

@article{zelikman2023self,
  title={Self-taught optimizer (stop): Recursively self-improving code generation},
  author={Zelikman, Eric and Lorch, Eliana and Mackey, Lester and Kalai, Adam Tauman},
  journal={arXiv preprint arXiv:2310.02304},
  year={2023}
}

@article{zhang2025maas,
  title={Multi-agent Architecture Search via Agentic Supernet},
  author={Zhang, Guibin and Niu, Luyang and Fang, Junfeng and Wang, Kun and Bai, Lei and Wang, Xiang},
  journal={arXiv preprint arXiv:2502.04180},
  year={2025}
}

@article{yuan2024evoagent,
  title={EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms},
  author={Yuan, Siyu and Song, Kaitao and Chen, Jiangjie and Tan, Xu and Li, Dongsheng and Yang, Deqing},
  journal={arXiv preprint arXiv:2406.14228},
  year={2024}
}

@article{hu2024adas,
  title={Automated design of agentic systems},
  author={Hu, Shengran and Lu, Cong and Clune, Jeff},
  journal={arXiv preprint arXiv:2408.08435},
  year={2024}
}

@article{shang2024agentsquare,
  title={AgentSquare: Automatic LLM Agent Search in Modular Design Space},
  author={Shang, Yu and Li, Yu and Zhao, Keyu and Ma, Likai and Liu, Jiahe and Xu, Fengli and Li, Yong},
  journal={arXiv preprint arXiv:2410.06153},
  year={2024}
}

@article{liu2024evaluating,
  title={Evaluating Language Models for Efficient Code Generation},
  author={Liu, Jiawei and Xie, Songrun and Wang, Junhao and Wei, Yuxiang and Ding, Yifeng and Zhang, Lingming},
  journal={arXiv preprint arXiv:2408.06450},
  year={2024}
}

@article{ling2017program,
  title={Program induction by rationale generation: Learning to solve and explain algebraic word problems},
  author={Ling, Wang and Yogatama, Dani and Dyer, Chris and Blunsom, Phil},
  journal={arXiv preprint arXiv:1705.04146},
  year={2017}
}

@misc{software-dev,
   author = {Qian, Chen and Cong, Xin and Yang, Cheng and Chen, Weize and Su, Yusheng and Xu, Juyuan and Liu, Zhiyuan and Sun, Maosong},
   title = {Communicative Agents for Software Development},
   pages = {arXiv:2307.07924},
   month = {July 01, 2023},
   note = {25 pages, 9 figures, 2 tables},
   abstract = {Software engineering is a domain characterized by intricate decision-making processes, often relying on nuanced intuition and consultation. Recent advancements in deep learning have started to revolutionize software engineering practices through elaborate designs implemented at various stages of software development. In this paper, we present an innovative paradigm that leverages large language models (LLMs) throughout the entire software development process, streamlining and unifying key processes through natural language communication, thereby eliminating the need for specialized models at each phase. At the core of this paradigm lies ChatDev, a virtual chat-powered software development company that mirrors the established waterfall model, meticulously dividing the development process into four distinct chronological stages: designing, coding, testing, and documenting. Each stage engages a team of agents, such as programmers, code reviewers, and test engineers, fostering collaborative dialogue and facilitating a seamless workflow. The chat chain acts as a facilitator, breaking down each stage into atomic subtasks. This enables dual roles, allowing for proposing and validating solutions through context-aware communication, leading to efficient resolution of specific subtasks. The instrumental analysis of ChatDev highlights its remarkable efficacy in software generation, enabling the completion of the entire software development process in under seven minutes at a cost of less than one dollar. It not only identifies and alleviates potential vulnerabilities but also rectifies potential hallucinations while maintaining commendable efficiency and cost-effectiveness. The potential of ChatDev unveils fresh possibilities for integrating LLMs into the realm of software development.},
   keywords = {Computer Science - Software Engineering
Computer Science -
Computation and Language
Computer Science - Multiagent Systems},
   year = {2023},
   type = {Electronic Article}
}

@misc{debate3-multi-models,
   author = {Xiong, Kai and Ding, Xiao and Cao, Yixin and Liu, Ting and Qin, Bing},
   title = {Examining the Inter-Consistency of Large Language Models: An In-depth Analysis via Debate},
   pages = {arXiv:2305.11595},
   month = {May 01, 2023},
   abstract = {Large Language Models (LLMs) have demonstrated human-like intelligence and are widely used in various applications. However, LLMs still exhibit various kinds of inconsistency problems. Existing works mainly focus on the inconsistency issues within a single LLM, while we investigate the inter-consistency among multiple LLMs, which is critical for collaborating to solve a complex task. To examine whether LLMs can collaborate to ultimately achieve a consensus for the shared goal and whether LLMs easily change their viewpoints, we introduce a Formal Debate framework (FORD) With FORD, we conduct a three-stage debate aligned with real-world scenarios: fair debate, mismatched debate, and roundtable debate. Through extensive experiments on the commonsense reasoning task, LLMs not only become more inter-consistent but also achieve higher performance. Moreover, we observe that stronger LLMs tend to dominate the debates by adhering to their perspectives, while weaker ones are more likely to change viewpoints. Additionally, we highlight the importance of a competent judge, such as GPT-4, to draw more proper conclusions. Our work contributes to understanding the inter-consistency among LLMs and lays the foundation for the development of future collaboration methods.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}


@article{chen2024compundLLM,
  title={Are more llm calls all you need? towards scaling laws of compound inference systems},
  author={Chen, Lingjiao and Davis, Jared Quincy and Hanin, Boris and Bailis, Peter and Stoica, Ion and Zaharia, Matei and Zou, James},
  journal={arXiv preprint arXiv:2403.02419},
  year={2024}
}

@article{piatti2024cooperate,
  title={Cooperate or Collapse: Emergence of Sustainability Behaviors in a Society of LLM Agents},
  author={Piatti, Giorgio and Jin, Zhijing and Kleiman-Weiner, Max and Sch{\"o}lkopf, Bernhard and Sachan, Mrinmaya and Mihalcea, Rada},
  journal={arXiv preprint arXiv:2404.16698},
  year={2024}
}

@article{zhang2006introduction,
  title={Introduction to graph theory},
  author={Zhang, Ping and Chartrand, Gary},
  journal={Tata McGraw-Hill},
  volume={2},
  pages={2--1},
  year={2006}
}

@article{ma2023laser,
  title={Laser: Llm agent with state-space exploration for web navigation},
  author={Ma, Kaixin and Zhang, Hongming and Wang, Hongwei and Pan, Xiaoman and Yu, Wenhao and Yu, Dong},
  journal={arXiv preprint arXiv:2309.08172},
  year={2023}
}


@article{bouzenia2024repairagent,
  title={Repairagent: An autonomous, llm-based agent for program repair},
  author={Bouzenia, Islem and Devanbu, Premkumar and Pradel, Michael},
  journal={arXiv preprint arXiv:2403.17134},
  year={2024}
}

@article{thorne2018fever,
  title={FEVER: a large-scale dataset for fact extraction and VERification},
  author={Thorne, James and Vlachos, Andreas and Christodoulopoulos, Christos and Mittal, Arpit},
  journal={arXiv preprint arXiv:1803.05355},
  year={2018}
}

@article{yang2018hotpotqa,
  title={HotpotQA: A dataset for diverse, explainable multi-hop question answering},
  author={Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William W and Salakhutdinov, Ruslan and Manning, Christopher D},
  journal={arXiv preprint arXiv:1809.09600},
  year={2018}
}

@article{zhou2025reso,
  title={ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for Reasoning Tasks},
  author={Zhou, Heng and Geng, Hejia and Xue, Xiangyuan and Yin, Zhenfei and Bai, Lei},
  journal={arXiv preprint arXiv:2503.02390},
  year={2025}
}

@article{zhao2025sirius,
  title={SiriuS: Self-improving Multi-agent Systems via Bootstrapped Reasoning},
  author={Zhao, Wanjia and Yuksekgonul, Mert and Wu, Shirley and Zou, James},
  journal={arXiv preprint arXiv:2502.04780},
  year={2025}
}




@article{ishibashi2024selforganize-mother,
  title={Self-organized agents: A llm multi-agent framework toward ultra large-scale code generation and optimization},
  author={Ishibashi, Yoichi and Nishimura, Yoshimasa},
  journal={arXiv preprint arXiv:2404.02183},
  year={2024}
}

@article{BOOK_1991organizational_memory,
  title={Organizational memory},
  author={Walsh, James P and Ungson, Gerardo Rivera},
  journal={Academy of management review},
  volume={16},
  number={1},
  pages={57--91},
  year={1991},
  publisher={Academy of Management Briarcliff Manor, NY 10510}
}


@article{mmlu,
  title={Measuring Massive Multitask Language Understanding},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andy Zou and Mantas Mazeika and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{hendrycks2021ethics,
  title={Aligning AI With Shared Human Values},
  author={Dan Hendrycks and Collin Burns and Steven Basart and Andrew Critch and Jerry Li and Dawn Song and Jacob Steinhardt},
  journal={Proceedings of the International Conference on Learning Representations (ICLR)},
  year={2021}
}

@article{hendrycksmath2021,
  title={Measuring Mathematical Problem Solving With the MATH Dataset},
  author={Dan Hendrycks and Collin Burns and Saurav Kadavath and Akul Arora and Steven Basart and Eric Tang and Dawn Song and Jacob Steinhardt},
  journal={NeurIPS},
  year={2021}
}

@misc{generative-agents-simulacra,
   author = {Park, Joon Sung and O'Brien, Joseph C. and Cai, Carrie J. and Ringel Morris, Meredith and Liang, Percy and Bernstein, Michael S.},
   title = {Generative Agents: Interactive Simulacra of Human Behavior},
   pages = {arXiv:2304.03442},
   month = {April 01, 2023},
   abstract = {Believable proxies of human behavior can empower interactive applications ranging from immersive environments to rehearsal spaces for interpersonal communication to prototyping tools. In this paper, we introduce generative agents--computational software agents that simulate believable human behavior. Generative agents wake up, cook breakfast, and head to work; artists paint, while authors write; they form opinions, notice each other, and initiate conversations; they remember and reflect on days past as they plan the next day. To enable generative agents, we describe an architecture that extends a large language model to store a complete record of the agent's experiences using natural language, synthesize those memories over time into higher-level reflections, and retrieve them dynamically to plan behavior. We instantiate generative agents to populate an interactive sandbox environment inspired by The Sims, where end users can interact with a small town of twenty five agents using natural language. In an evaluation, these generative agents produce believable individual and emergent social behaviors: for example, starting with only a single user-specified notion that one agent wants to throw a Valentine's Day party, the agents autonomously spread invitations to the party over the next two days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture--observation, planning, and reflection--each contribute critically to the believability of agent behavior. By fusing large language models with computational, interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.},
   keywords = {Computer Science - Human-Computer Interaction
Computer Science -
Artificial Intelligence
Computer Science - Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@article{zhang2024classroom,
  title={Simulating classroom education with llm-empowered agents},
  author={Zhang, Zheyuan and Zhang-Li, Daniel and Yu, Jifan and Gong, Linlu and Zhou, Jinchang and Liu, Zhiyuan and Hou, Lei and Li, Juanzi},
  journal={arXiv preprint arXiv:2406.19226},
  year={2024}
}

@article{zhao2023competeai,
  title={Competeai: Understanding the competition behaviors in large language model-based agents},
  author={Zhao, Qinlin and Wang, Jindong and Zhang, Yixuan and Jin, Yiqiao and Zhu, Kaijie and Chen, Hao and Xie, Xing},
  journal={arXiv preprint arXiv:2310.17512},
  year={2023}
}

@misc{multi-persona,
   author = {Wang, Zhenhailong and Mao, Shaoguang and Wu, Wenshan and Ge, Tao and Wei, Furu and Ji, Heng},
   title = {Unleashing Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration},
   pages = {arXiv:2307.05300},
   month = {July 01, 2023},
   note = {work in progress},
   abstract = {Human intelligence thrives on the concept of cognitive synergy, where collaboration and information integration among different cognitive processes yield superior outcomes compared to individual cognitive processes in isolation. Although Large Language Models (LLMs) have demonstrated promising performance as general task-solving agents, they still struggle with tasks that require intensive domain knowledge and complex reasoning. In this work, we propose Solo Performance Prompting (SPP), which transforms a single LLM into a cognitive synergist by engaging in multi-turn self-collaboration with multiple personas. A cognitive synergist refers to an intelligent agent that collaborates with multiple minds, combining their individual strengths and knowledge, to enhance problem-solving and overall performance in complex tasks. By dynamically identifying and simulating different personas based on task inputs, SPP unleashes the potential of cognitive synergy in LLMs. We have discovered that assigning multiple, fine-grained personas in LLMs elicits better problem-solving abilities compared to using a single or fixed number of personas. We evaluate SPP on three challenging tasks: Trivia Creative Writing, Codenames Collaborative, and Logic Grid Puzzle, encompassing both knowledge-intensive and reasoning-intensive types. Unlike previous works, such as Chain-of-Thought, that solely enhance the reasoning abilities in LLMs, SPP effectively elicits internal knowledge acquisition abilities, reduces hallucination, and maintains strong reasoning capabilities. Code, data, and prompts can be found at: https://github.com/MikeWangWZHL/Solo-Performance-Prompting.git.},
   keywords = {Computer Science - Artificial Intelligence
Computer Science -
Computation and Language},
   year = {2023},
   type = {Electronic Article}
}

@misc{bargaining-feedback,
   author = {Fu, Yao and Peng, Hao and Khot, Tushar and Lapata, Mirella},
   title = {Improving Language Model Negotiation with Self-Play and In-Context Learning from AI Feedback},
   pages = {arXiv:2305.10142},
   month = {May 01, 2023},
   note = {Preprint. Code at https://github.com/FranxYao/GPT-Bargaining},
   abstract = {We study whether multiple large language models (LLMs) can autonomously improve each other in a negotiation game by playing, reflecting, and criticizing. We are interested in this question because if LLMs were able to improve each other, it would imply the possibility of creating strong AI agents with minimal human intervention. We ask two LLMs to negotiate with each other, playing the roles of a buyer and a seller, respectively. They aim to reach a deal with the buyer targeting a lower price and the seller a higher one. A third language model, playing the critic, provides feedback to a player to improve the player's negotiation strategies. We let the two agents play multiple rounds, using previous negotiation history and AI feedback as in-context demonstrations to improve the model's negotiation strategy iteratively. We use different LLMs (GPT and Claude) for different roles and use the deal price as the evaluation metric. Our experiments reveal multiple intriguing findings: (1) Only a subset of the language models we consider can self-play and improve the deal price from AI feedback, weaker models either do not understand the game's rules or cannot incorporate AI feedback for further improvement. (2) Models' abilities to learn from the feedback differ when playing different roles. For example, it is harder for Claude-instant to improve as the buyer than as the seller. (3) When unrolling the game to multiple rounds, stronger agents can consistently improve their performance by meaningfully using previous experiences and iterative AI feedback, yet have a higher risk of breaking the deal. We hope our work provides insightful initial explorations of having models autonomously improve each other with game playing and AI feedback.},
   keywords = {Computer Science - Computation and Language},
   year = {2023},
   type = {Electronic Article}
}

@misc{sot,
   author = {Ning, Xuefei and Lin, Zinan and Zhou, Zixuan and Yang, Huazhong and Wang, Yu},
   title = {Skeleton-of-Thought: Large Language Models Can Do Parallel Decoding},
   pages = {arXiv:2307.15337},
   month = {July 01, 2023},
   abstract = {This work aims at decreasing the end-to-end generation latency of large language models (LLMs). One of the major causes of the high generation latency is the sequential decoding approach adopted by almost all state-of-the-art LLMs. In this work, motivated by the thinking and writing process of humans, we propose "Skeleton-of-Thought" (SoT), which guides LLMs to first generate the skeleton of the answer, and then conducts parallel API calls or batched decoding to complete the contents of each skeleton point in parallel. Not only does SoT provide considerable speed-up (up to 2.39x across 11 different LLMs), but it can also potentially improve the answer quality on several question categories in terms of diversity and relevance. SoT is an initial attempt at data-centric optimization for efficiency, and reveal the potential of pushing LLMs to think more like a human for answer quality.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}

@article{hua2023war,
  title={War and peace (waragent): Large language model-based multi-agent simulation of world wars},
  author={Hua, Wenyue and Fan, Lizhou and Li, Lingyao and Mei, Kai and Ji, Jianchao and Ge, Yingqiang and Hemphill, Libby and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2311.17227},
  year={2023}
}

@article{chen2023gamegpt,
  title={Gamegpt: Multi-agent collaborative framework for game development},
  author={Chen, Dake and Wang, Hanbin and Huo, Yunhao and Li, Yuzhao and Zhang, Haoyang},
  journal={arXiv preprint arXiv:2310.08067},
  year={2023}
}


@article{cohen2023lm,
  title={Lm vs lm: Detecting factual errors via cross examination},
  author={Cohen, Roi and Hamri, May and Geva, Mor and Globerson, Amir},
  journal={arXiv preprint arXiv:2305.13281},
  year={2023}
}

@misc{self-correction,
   author = {Pan, Liangming and Saxon, Michael and Xu, Wenda and Nathani, Deepak and Wang, Xinyi and Wang, William Yang},
   title = {Automatically Correcting Large Language Models: Surveying the landscape of diverse self-correction strategies},
   pages = {arXiv:2308.03188},
   month = {August 01, 2023},
   note = {Work in Progress},
   abstract = {Large language models (LLMs) have demonstrated remarkable performance across a wide array of NLP tasks. However, their efficacy is undermined by undesired and inconsistent behaviors, including hallucination, unfaithful reasoning, and toxic content. A promising approach to rectify these flaws is self-correction, where the LLM itself is prompted or guided to fix problems in its own output. Techniques leveraging automated feedback -- either produced by the LLM itself or some external system -- are of particular interest as they are a promising way to make LLM-based solutions more practical and deployable with minimal human feedback. This paper presents a comprehensive review of this emerging class of techniques. We analyze and taxonomize a wide array of recent work utilizing these strategies, including training-time, generation-time, and post-hoc correction. We also summarize the major applications of this strategy and conclude by discussing future directions and challenges.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}


@article{qian2024scaling,
  title={Scaling Large-Language-Model-based Multi-Agent Collaboration},
  author={Qian, Chen and Xie, Zihao and Wang, Yifei and Liu, Wei and Dang, Yufan and Du, Zhuoyun and Chen, Weize and Yang, Cheng and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2406.07155},
  year={2024}
}

@inproceedings{zhuge2024gptswarm,
  title={GPTSwarm: Language Agents as Optimizable Graphs},
  author={Zhuge, Mingchen and Wang, Wenyi and Kirsch, Louis and Faccio, Francesco and Khizbullin, Dmitrii and Schmidhuber, J{\"u}rgen},
  booktitle={Forty-first International Conference on Machine Learning},
year={2024}
}

@misc{openai2023gpt4,
      title={GPT-4 Technical Report}, 
      author={OpenAI},
      year={2023},
      eprint={2303.08774},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@ARTICLE{coalitional-game,
  author={Saad, Walid and Han, Zhu and Debbah, Merouane and Hjorungnes, Are and Basar, Tamer},
  journal={IEEE Signal Processing Magazine}, 
  title={Coalitional game theory for communication networks}, 
  year={2009},
  volume={26},
  number={5},
  pages={77-97},
}

@inproceedings{held-yang-2023-shapley,
    title = "Shapley Head Pruning: Identifying and Removing Interference in Multilingual Transformers",
    author = "Held, William  and
      Yang, Diyi",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.177",
    pages = "2416--2427",
    abstract = "Multilingual transformer-based models demonstrate remarkable zero and few-shot transfer across languages by learning and reusing language-agnostic features. However, as a fixed-size model acquires more languages, its performance across all languages degrades. Those who attribute this interference phenomenon to limited model capacity address the problem by adding additional parameters, despite evidence that transformer-based models are overparameterized. In this work, we show that it is possible to reduce interference by instead identifying and pruning language-specific attention heads. First, we use Shapley Values, a credit allocation metric from coalitional game theory, to identify attention heads that introduce interference. Then, we show that pruning such heads from a fixed model improves performance for a target language on both sentence classification and structural prediction. Finally, we provide insights on language-agnostic and language-specific attention heads using attention visualization.",
}

@INPROCEEDINGS{imp-score,
  author={Yu, Ruichi and Li, Ang and Chen, Chun-Fu and Lai, Jui-Hsin and Morariu, Vlad I. and Han, Xintong and Gao, Mingfei and Lin, Ching-Yung and Davis, Larry S.},
  booktitle={2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition}, 
  title={NISP: Pruning Networks Using Neuron Importance Score Propagation}, 
  year={2018},
  volume={},
  number={},
  pages={9194-9203}}

@misc{human-eval,
   author = {Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Ponde de Oliveira Pinto, Henrique and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and Ray, Alex and Puri, Raul and Krueger, Gretchen and Petrov, Michael and Khlaaf, Heidy and Sastry, Girish and Mishkin, Pamela and Chan, Brooke and Gray, Scott and Ryder, Nick and Pavlov, Mikhail and Power, Alethea and Kaiser, Lukasz and Bavarian, Mohammad and Winter, Clemens and Tillet, Philippe and Petroski Such, Felipe and Cummings, Dave and Plappert, Matthias and Chantzis, Fotios and Barnes, Elizabeth and Herbert-Voss, Ariel and Hebgen Guss, William and Nichol, Alex and Paino, Alex and Tezak, Nikolas and Tang, Jie and Babuschkin, Igor and Balaji, Suchir and Jain, Shantanu and Saunders, William and Hesse, Christopher and Carr, Andrew N. and Leike, Jan and Achiam, Josh and Misra, Vedant and Morikawa, Evan and Radford, Alec and Knight, Matthew and Brundage, Miles and Murati, Mira and Mayer, Katie and Welinder, Peter and McGrew, Bob and Amodei, Dario and McCandlish, Sam and Sutskever, Ilya and Zaremba, Wojciech},
   title = {Evaluating Large Language Models Trained on Code},
   pages = {arXiv:2107.03374},
   month = {July 01, 2021},
   keywords = {Computer Science - Machine Learning},
   year = {2021},
   type = {Electronic Article}
}

@ARTICLE{minecraft-agent,
       author = {{Zhu}, Xizhou and {Chen}, Yuntao and {Tian}, Hao and {Tao}, Chenxin and {Su}, Weijie and {Yang}, Chenyu and {Huang}, Gao and {Li}, Bin and {Lu}, Lewei and {Wang}, Xiaogang and {Qiao}, Yu and {Zhang}, Zhaoxiang and {Dai}, Jifeng},
        title = "{Ghost in the Minecraft: Generally Capable Agents for Open-World Environments via Large Language Models with Text-based Knowledge and Memory}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
         year = 2023,
        month = may,
          eid = {arXiv:2305.17144},
        pages = {arXiv:2305.17144},
archivePrefix = {arXiv},
       eprint = {2305.17144},
 primaryClass = {cs.AI},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{meta-gpt,
   author = {Hong, Sirui and Zheng, Xiawu and Chen, Jonathan and Cheng, Yuheng and Wang, Jinlin and Zhang, Ceyao and Wang, Zili and Yau, Steven Ka Shing and Lin, Zijuan and Zhou, Liyang and Ran, Chenyu and Xiao, Lingfeng and Wu, Chenglin},
   title = {MetaGPT: Meta Programming for Multi-Agent Collaborative Framework},
   pages = {arXiv:2308.00352},
   month = {August 01, 2023},
   abstract = {Recently, remarkable progress has been made in automated task-solving through the use of multi-agent driven by large language models (LLMs). However, existing LLM-based multi-agent works primarily focus on solving simple dialogue tasks, and complex tasks are rarely studied, mainly due to the LLM hallucination problem. This type of hallucination becomes cascading when naively chaining multiple intelligent agents, resulting in a failure to effectively address complex problems. Therefore, we introduce MetaGPT, an innovative framework that incorporates efficient human workflows as a meta programming approach into LLM-based multi-agent collaboration. Specifically, MetaGPT encodes Standardized Operating Procedures (SOPs) into prompts to enhance structured coordination. Subsequently, it mandates modular outputs, empowering agents with domain expertise comparable to human professionals, to validate outputs and minimize compounded errors. In this way, MetaGPT leverages the assembly line paradigm to assign diverse roles to various agents, thereby establishing a framework that can effectively and cohesively deconstruct complex multi-agent collaborative problems. Our experiments on collaborative software engineering benchmarks demonstrate that MetaGPT generates more coherent and correct solutions compared to existing chat-based multi-agent systems. This highlights the potential of integrating human domain knowledge into multi-agent systems, thereby creating new opportunities to tackle complex real-world challenges. The GitHub repository of this project is publicly available on:https://github.com/geekan/MetaGPT.},
   keywords = {Computer Science - Artificial Intelligence
Computer Science -
Multiagent Systems},
   year = {2023},
   type = {Electronic Article}
}

@misc{self-debug,
   author = {Olausson, Theo X. and Priya Inala, Jeevana and Wang, Chenglong and Gao, Jianfeng and Solar-Lezama, Armando},
   title = {Demystifying GPT Self-Repair for Code Generation},
   pages = {arXiv:2306.09896},
   month = {June 01, 2023},
   abstract = {Large Language Models (LLMs) have shown remarkable aptitude in code generation but still struggle on challenging programming tasks. Self-repair -- in which the model debugs and fixes mistakes in its own code -- has recently become a popular way to boost performance in these settings. However, only very limited studies on how and when self-repair works effectively exist in the literature, and one might wonder to what extent a model is really capable of providing accurate feedback on why the code is wrong when that code was generated by the same model. In this paper, we analyze GPT-3.5 and GPT-4's ability to perform self-repair on APPS, a challenging dataset consisting of diverse coding challenges. To do so, we first establish a new evaluation strategy dubbed pass@t that measures the pass rate of the tasks against the total number of tokens sampled from the model, enabling a fair comparison to purely sampling-based approaches. With this evaluation strategy, we find that the effectiveness of self-repair is only seen in GPT-4. We also observe that self-repair is bottlenecked by the feedback stage; using GPT-4 to give feedback on the programs generated by GPT-3.5 and using expert human programmers to give feedback on the programs generated by GPT-4, we unlock significant performance gains.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence
Computer Science - Programming Languages
Computer Science - Software Engineering},
   year = {2023},
   type = {Electronic Article}
}

@article{zhang2024g-designer,
  title={G-designer: Architecting multi-agent communication topologies via graph neural networks},
  author={Zhang, Guibin and Yue, Yanwei and Sun, Xiangguo and Wan, Guancheng and Yu, Miao and Fang, Junfeng and Wang, Kun and Chen, Tianlong and Cheng, Dawei},
  journal={arXiv preprint arXiv:2410.11782},
  year={2024}
}

@inproceedings{
chen2023codet,
title={CodeT:  Code Generation with Generated Tests},
author={Bei Chen and Fengji Zhang and Anh Nguyen and Daoguang Zan and Zeqi Lin and Jian-Guang Lou and Weizhu Chen},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=ktrw68Cmu9c}
}

@ARTICLE{self-evaluation-decode,
       author = {{Xie}, Yuxi and {Kawaguchi}, Kenji and {Zhao}, Yiran and {Zhao}, Xu and {Kan}, Min-Yen and {He}, Junxian and {Xie}, Qizhe},
        title = "{Decomposition Enhances Reasoning via Self-Evaluation Guided Decoding}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2023,
        month = apr,
          eid = {arXiv:2305.00633},
        pages = {arXiv:2305.00633},
archivePrefix = {arXiv},
       eprint = {2305.00633},
 primaryClass = {cs.CL},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{llm-overconfident,
       author = {{Xiong}, Miao and {Hu}, Zhiyuan and {Lu}, Xinyang and {Li}, Yifei and {Fu}, Jie and {He}, Junxian and {Hooi}, Bryan},
        title = "{Can LLMs Express Their Uncertainty? An Empirical Evaluation of Confidence Elicitation in LLMs}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2023,
        month = jun,
          eid = {arXiv:2306.13063},
        pages = {arXiv:2306.13063},
archivePrefix = {arXiv},
       eprint = {2306.13063},
 primaryClass = {cs.CL},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@misc{llm-as-a-judge,
   author = {Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric. P and Zhang, Hao and Gonzalez, Joseph E. and Stoica, Ion},
   title = {Judging LLM-as-a-judge with MT-Bench and Chatbot Arena},
   pages = {arXiv:2306.05685},
   month = {June 01, 2023},
   abstract = {Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, such as position and verbosity biases and limited reasoning ability, and propose solutions to migrate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80\% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA/Vicuna. We will publicly release 80 MT-bench questions, 3K expert votes, and 30K conversations with human preferences from Chatbot Arena.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}

@misc{sliding-window,
   author = {Qin, Zhen and Jagerman, Rolf and Hui, Kai and Zhuang, Honglei and Wu, Junru and Shen, Jiaming and Liu, Tianqi and Liu, Jialu and Metzler, Donald and Wang, Xuanhui and Bendersky, Michael},
   title = {Large Language Models are Effective Text Rankers with Pairwise Ranking Prompting},
   pages = {arXiv:2306.17563},
   month = {June 01, 2023},
   note = {12 pages, 3 figures},
   abstract = {Ranking documents using Large Language Models (LLMs) by directly feeding the query and candidate documents into the prompt is an interesting and practical problem. However, there has been limited success so far, as researchers have found it difficult to outperform fine-tuned baseline rankers on benchmark datasets. We analyze pointwise and listwise ranking prompts used by existing methods and argue that off-the-shelf LLMs do not fully understand these ranking formulations, possibly due to the nature of how LLMs are trained. In this paper, we propose to significantly reduce the burden on LLMs by using a new technique called Pairwise Ranking Prompting (PRP). Our results are the first in the literature to achieve state-of-the-art ranking performance on standard benchmarks using moderate-sized open-sourced LLMs. On TREC-DL2020, PRP based on the Flan-UL2 model with 20B parameters outperforms the previous best approach in the literature, which is based on the blackbox commercial GPT-4 that has 50x (estimated) model size, by over 5% at NDCG@1. On TREC-DL2019, PRP is only inferior to the GPT-4 solution on the NDCG@5 and NDCG@10 metrics, while outperforming other existing solutions, such as InstructGPT which has 175B parameters, by over 10% for nearly all ranking metrics. Furthermore, we propose several variants of PRP to improve efficiency and show that it is possible to achieve competitive results even with linear complexity. We also discuss other benefits of PRP, such as supporting both generation and scoring LLM APIs, as well as being insensitive to input ordering.},
   keywords = {Computer Science - Information Retrieval
Computer Science -
Computation and Language
Computer Science - Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@inproceedings{SHAP,
author = {Lundberg, Scott M. and Lee, Su-In},
title = {A Unified Approach to Interpreting Model Predictions},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {4768–4777},
numpages = {10},
location = {Long Beach, California, USA},
series = {NIPS'17}
}

@Article{shapley-origin,
  author={Stan Lipovetsky and Michael Conklin},
  title={{Analysis of regression in game theory approach}},
  journal={Applied Stochastic Models in Business and Industry},
  year=2001,
  volume={17},
  number={4},
  pages={319-330},
  month={October},
  keywords={},
  abstract={Working with multiple regression analysis a researcher usually wants to know a comparative importance of predictors in the model. However, the analysis can be made difficult because of multicollinearity among regressors, which produces biased coefficients and negative inputs to multiple determination from presum ably useful regressors. To solve this problem we apply a tool from the co‐operative games theory, the Shapley Value imputation. We demonstrate the theoretical and practical advantages of the Shapley Value and show that it provides consistent results in the presence of multicollinearity. Copyright © 2001 John Wiley \& Sons, Ltd.},
  url={https://ideas.repec.org/a/wly/apsmbi/v17y2001i4p319-330.html}
}

@misc{got,
   author = {Besta, Maciej and Blach, Nils and Kubicek, Ales and Gerstenberger, Robert and Gianinazzi, Lukas and Gajda, Joanna and Lehmann, Tomasz and Podstawski, Michal and Niewiadomski, Hubert and Nyczyk, Piotr and Hoefler, Torsten},
   title = {Graph of Thoughts: Solving Elaborate Problems with Large Language Models},
   pages = {arXiv:2308.09687},
   month = {August 01, 2023},
   abstract = {We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-ofThought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence
Computer Science - Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@misc{agent-bench,
   author = {Liu, Xiao and Yu, Hao and Zhang, Hanchen and Xu, Yifan and Lei, Xuanyu and Lai, Hanyu and Gu, Yu and Ding, Hangliang and Men, Kaiwen and Yang, Kejuan and Zhang, Shudan and Deng, Xiang and Zeng, Aohan and Du, Zhengxiao and Zhang, Chenhui and Shen, Sheng and Zhang, Tianjun and Su, Yu and Sun, Huan and Huang, Minlie and Dong, Yuxiao and Tang, Jie},
   title = {AgentBench: Evaluating LLMs as Agents},
   pages = {arXiv:2308.03688},
   month = {August 01, 2023},
   note = {38 pages},
   abstract = {Large Language Models (LLMs) are becoming increasingly smart and autonomous, targeting real-world pragmatic missions beyond traditional NLP tasks. As a result, there has been an urgent need to evaluate LLMs as agents on challenging tasks in interactive environments. We present AgentBench, a multi-dimensional evolving benchmark that currently consists of 8 distinct environments to assess LLM-as-Agent's reasoning and decision-making abilities in a multi-turn open-ended generation setting. Our extensive test over 25 LLMs (including APIs and open-sourced models) shows that, while top commercial LLMs present a strong ability of acting as agents in complex environments, there is a significant disparity in performance between them and open-sourced competitors. It also serves as a component of an ongoing project with wider coverage and deeper consideration towards systematic LLM evaluation. Datasets, environments, and an integrated evaluation package for AgentBench are released at https://github.com/THUDM/AgentBench},
   keywords = {Computer Science - Artificial Intelligence
Computer Science -
Computation and Language
Computer Science - Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@misc{cot,
   author = {Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Ichter, Brian and Xia, Fei and Chi, Ed and Le, Quoc and Zhou, Denny},
   title = {Chain-of-Thought Prompting Elicits Reasoning in Large Language Models},
   journal = {arXiv:2201.11903},
   month = {January 01, 2022},
   year = {2022}
}

@article{kim2014convolutional,
  title={Convolutional neural networks for sentence classification},
  author={Kim, Yoon},
  journal={arXiv:1408.5882},
  year={2014}
}

@inproceedings{nair2010rectified,
  title={Rectified linear units improve restricted boltzmann machines},
  author={Nair, Vinod and Hinton, Geoffrey E},
  booktitle={Proceedings of the 27th international conference on machine learning (ICML-10)},
  pages={807--814},
  year={2010}
}

@article{hendrycks2016gaussian,
  title={Gaussian error linear units (gelus)},
  author={Hendrycks, Dan and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1606.08415},
  year={2016}
}

@inproceedings{listmle,
author = {Xia, Fen and Liu, Tie-Yan and Wang, Jue and Zhang, Wensheng and Li, Hang},
title = {Listwise Approach to Learning to Rank: Theory and Algorithm},
year = {2008},
isbn = {9781605582054},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This paper aims to conduct a study on the listwise approach to learning to rank. The listwise approach learns a ranking function by taking individual lists as instances and minimizing a loss function defined on the predicted list and the ground-truth list. Existing work on the approach mainly focused on the development of new algorithms; methods such as RankCosine and ListNet have been proposed and good performances by them have been observed. Unfortunately, the underlying theory was not sufficiently studied so far. To amend the problem, this paper proposes conducting theoretical analysis of learning to rank algorithms through investigations on the properties of the loss functions, including consistency, soundness, continuity, differentiability, convexity, and efficiency. A sufficient condition on consistency for ranking is given, which seems to be the first such result obtained in related research. The paper then conducts analysis on three loss functions: likelihood loss, cosine loss, and cross entropy loss. The latter two were used in RankCosine and ListNet. The use of the likelihood loss leads to the development of a new listwise method called ListMLE, whose loss function offers better properties, and also leads to better experimental results.},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
pages = {1192–1199},
numpages = {8},
location = {Helsinki, Finland},
series = {ICML '08}
}

@misc{autogpt,
  author = {Toran Bruce Richards and et al.},
  title = {Auto-GPT: An Autonomous GPT-4 Experiment},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/Significant-Gravitas/Auto-GPT}}
}

@misc{autogen,
   author = {Wu, Qingyun and Bansal, Gagan and Zhang, Jieyu and Wu, Yiran and Zhang, Shaokun and Zhu, Erkang and Li, Beibin and Jiang, Li and Zhang, Xiaoyun and Wang, Chi},
   title = {AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework},
   journal = {arXiv:2308.08155},
   month = {August 01, 2023},
   year = {2023}
}

@inproceedings{
yao2023react,
title={ReAct: Synergizing Reasoning and Acting in Language Models},
author={Shunyu Yao and Jeffrey Zhao and Dian Yu and Nan Du and Izhak Shafran and Karthik R Narasimhan and Yuan Cao},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023}
}

@ARTICLE{voyager,
       author = {{Wang}, Guanzhi and {Xie}, Yuqi and {Jiang}, Yunfan and {Mandlekar}, Ajay and {Xiao}, Chaowei and {Zhu}, Yuke and {Fan}, Linxi and {Anandkumar}, Anima},
        title = "{Voyager: An Open-Ended Embodied Agent with Large Language Models}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
         year = 2023,
        month = may,
          eid = {arXiv:2305.16291},
        pages = {arXiv:2305.16291},
archivePrefix = {arXiv},
       eprint = {2305.16291}
}

@misc{jin2023surrealdriver,
      title={SurrealDriver: Designing Generative Driver Agent Simulation Framework in Urban Contexts based on Large Language Model}, 
      author={Ye Jin and Xiaoxi Shen and Huiling Peng and Xiaoan Liu and Jingli Qin and Jiayang Li and Jintao Xie and Peizhong Gao and Guyue Zhou and Jiangtao Gong},
      year={2023},
      eprint={2309.13193},
      archivePrefix={arXiv}
}

@article{human-team-optimization,
author = {Lykourentzou, Ioanna and Vinella, Federica Lucia and Ahmed, Faez and Papastathis, Costas and Papangelis, Konstantinos and Khan, Vassilis-Javed and Masthoff, Judith},
title = {Self-Organization in Online Collaborative Work Settings},
year = {2022},
issue_date = {July-September 2022},
publisher = {Sage Publications, Inc.},
address = {USA},
volume = {1},
number = {1},
abstract = {As the volume and complexity of distributed online work increases, collaboration among people who have never worked together in the past is becoming increasingly necessary. Recent research has proposed algorithms to maximize the performance of online collaborations by grouping workers in a top-down fashion and according to a set of predefined decision criteria. This approach often means that workers have little say in the collaboration formation process. Depriving users of control over whom they will work with can stifle creativity and initiative-taking, increase psychological discomfort, and, overall, result in less-than-optimal collaboration results—especially when the task concerned is open-ended, creative, and complex. In this work, we propose an alternative model, called Self-Organizing Pairs (SOPs), which relies on the crowd of online workers themselves to organize into effective work dyads. Supported but not guided by an algorithm, SOPs are a new human-centered computational structure, which enables participants to control, correct, and guide the output of their collaboration as a collective. Experimental results, comparing SOPs to two benchmarks that do not allow user agency, and on an iterative task of fictional story writing, reveal that participants in the SOPs condition produce creative outcomes of higher quality, and report higher satisfaction with their collaboration. Finally, we find that similarly to machine learning-based self-organization, human SOPs exhibit emergent collective properties, including the presence of an objective function and the tendency to form more distinct clusters of compatible collaborators.},
journal = {Collective Intelligence},
month = {sep},
numpages = {35},
keywords = {self-organization, Online collaborative work, macrotask, distributed work, complex work}
}

@misc{babyagi,
  author = {Yohei Nakajima},
  title = {BabyAGI},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/yoheinakajima/babyagi}}
}

@misc{agentgpt,
  author = {Reworkd},
  title = {AgentGPT},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/reworkd/AgentGPT}}
}

@article{zhang2023astools,
  title={Exploring collaboration mechanisms for llm agents: A social psychology view},
  author={Zhang, Jintian and Xu, Xin and Deng, Shumin},
  journal={arXiv preprint arXiv:2310.02124},
  year={2023}
}

@article{pesce2023learning,
  title={Learning multi-agent coordination through connectivity-driven communication},
  author={Pesce, Emanuele and Montana, Giovanni},
  journal={Machine Learning},
  volume={112},
  number={2},
  pages={483--514},
  year={2023},
  publisher={Springer}
}

@inproceedings{liu2022temporal,
  title={Temporal dynamic weighted graph convolution for multi-agent reinforcement learning},
  author={Liu, Yuntao and Dou, Yong and Li, Yuan and Xu, Xinhai and Liu, Donghong},
  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},
  volume={44},
  number={44},
  year={2022}
}

@article{hu2024magraph,
  title={Learning multi-agent communication from graph modeling perspective},
  author={Hu, Shengchao and Shen, Li and Zhang, Ya and Tao, Dacheng},
  journal={arXiv preprint arXiv:2405.08550},
  year={2024}
}

@misc{bolaa,
   author = {Liu, Zhiwei and Yao, Weiran and Zhang, Jianguo and Xue, Le and Heinecke, Shelby and Murthy, Rithesh and Feng, Yihao and Chen, Zeyuan and Niebles, Juan Carlos and Arpit, Devansh and Xu, Ran and Mui, Phil and Wang, Huan and Xiong, Caiming and Savarese, Silvio},
   title = {BOLAA: Benchmarking and Orchestrating LLM-augmented Autonomous Agents},
   pages = {arXiv:2308.05960},
   month = {August 01, 2023},
   note = {Preprint},
   abstract = {The massive successes of large language models (LLMs) encourage the emerging exploration of LLM-augmented Autonomous Agents (LAAs). An LAA is able to generate actions with its core LLM and interact with environments, which facilitates the ability to resolve complex tasks by conditioning on past interactions such as observations and actions. Since the investigation of LAA is still very recent, limited explorations are available. Therefore, we provide a comprehensive comparison of LAA in terms of both agent architectures and LLM backbones. Additionally, we propose a new strategy to orchestrate multiple LAAs such that each labor LAA focuses on one type of action, \textit{i.e.} BOLAA, where a controller manages the communication among multiple agents. We conduct simulations on both decision-making and multi-step reasoning environments, which comprehensively justify the capacity of LAAs. Our performance results provide quantitative suggestions for designing LAA architectures and the optimal choice of LLMs, as well as the compatibility of both. We release our implementation code of LAAs to the public at \url{https://github.com/salesforce/BOLAA}.},
   keywords = {Computer Science - Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}

@misc{cumulative-cr,
   author = {Zhang, Yifan and Yang, Jingqin and Yuan, Yang and Chi-Chih Yao, Andrew},
   title = {Cumulative Reasoning with Large Language Models},
   pages = {arXiv:2308.04371},
   month = {August 01, 2023},
   abstract = {While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94%, which signifies a substantial enhancement of 20% over the previous state-of-the-art method (code is available at https://github.com/iiis-ai/cumulative-reasoning).},
   keywords = {Computer Science - Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}

@misc{tptu,
   author = {Ruan, Jingqing and Chen, Yihong and Zhang, Bin and Xu, Zhiwei and Bao, Tianpeng and Du, Guoqing and Shi, Shiwei and Mao, Hangyu and Zeng, Xingyu and Zhao, Rui},
   title = {TPTU: Task Planning and Tool Usage of Large Language Model-based AI Agents},
   pages = {arXiv:2308.03427},
   month = {August 01, 2023},
   abstract = {With recent advancements in natural language processing, Large Language Models (LLMs) have emerged as powerful tools for various real-world applications. Despite their prowess, the intrinsic generative abilities of LLMs may prove insufficient for handling complex tasks which necessitate a combination of task planning and the usage of external tools. In this paper, we first propose a structured framework tailored for LLM-based AI Agents and discuss the crucial capabilities necessary for tackling intricate problems. Within this framework, we design two distinct types of agents (i.e., one-step agent and sequential agent) to execute the inference process. Subsequently, we instantiate the framework using various LLMs and evaluate their Task Planning and Tool Usage (TPTU) abilities on typical tasks. By highlighting key findings and challenges, our goal is to provide a helpful resource for researchers and practitioners to leverage the power of LLMs in their AI applications. Our study emphasizes the substantial potential of these models, while also identifying areas that need more investigation and improvement.},
   keywords = {Computer Science - Artificial Intelligence},
   year = {2023},
   type = {Electronic Article}
}

@article{lu2023chameleon,
  title={Chameleon: Plug-and-Play Compositional Reasoning with Large Language Models},
  author={Lu, Pan and Peng, Baolin and Cheng, Hao and Galley, Michel and Chang, Kai-Wei and Wu, Ying Nian and Zhu, Song-Chun and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2304.09842},
  year={2023}
}

@misc{deep-network,
   author = {Sordoni, Alessandro and Yuan, Xingdi and Côté, Marc-Alexandre and Pereira, Matheus and Trischler, Adam and Xiao, Ziang and Hosseini, Arian and Niedtner, Friederike and Le Roux, Nicolas},
   title = {Deep Language Networks: Joint Prompt Training of Stacked LLMs using Variational Inference},
   pages = {arXiv:2306.12509},
   month = {June 01, 2023},
   keywords = {Computer Science - Computation and Language
Computer Science -
Machine Learning},
   year = {2023},
   type = {Electronic Article}
}

@misc{chen2023agentverse,
      title={AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents}, 
      author={Weize Chen and Yusheng Su and Jingwei Zuo and Cheng Yang and Chenfei Yuan and Chen Qian and Chi-Min Chan and Yujia Qin and Yaxi Lu and Ruobing Xie and Zhiyuan Liu and Maosong Sun and Jie Zhou},
      year={2023},
      eprint={2308.10848},
      archivePrefix={arXiv}
}

@article{rasal2024llm,
  title={Llm harmony: Multi-agent communication for problem solving},
  author={Rasal, Sumedh},
  journal={arXiv preprint arXiv:2401.01312},
  year={2024}
}

@misc{madaan2023selfrefine,
    title={Self-Refine: Iterative Refinement with Self-Feedback}, 
    author={Aman Madaan and Niket Tandon and Prakhar Gupta and Skyler Hallinan and Luyu Gao and Sarah Wiegreffe and Uri Alon and Nouha Dziri and Shrimai Prabhumoye and Yiming Yang and Sean Welleck and Bodhisattwa Prasad Majumder and Shashank Gupta and Amir Yazdanbakhsh and Peter Clark},
    year={2023},
    eprint={2303.17651},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{aggarwal2023adaptive-consistency,
      title={Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs}, 
      author={Pranjal Aggarwal and Aman Madaan and Yiming Yang and Mausam},
      year={2023},
      eprint={2305.11860},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{tot,
   author = {Yao, Shunyu and Yu, Dian and Zhao, Jeffrey and Shafran, Izhak and Griffiths, Thomas L. and Cao, Yuan and Narasimhan, Karthik},
   title = {Tree of Thoughts: Deliberate Problem Solving with Large Language Models},
   journal = {arXiv:2305.10601},
   month = {May 01, 2023},
   year = {2023}
}

@ARTICLE{embodied,
       author = {{Zhang}, Hongxin and {Du}, Weihua and {Shan}, Jiaming and {Zhou}, Qinhong and {Du}, Yilun and {Tenenbaum}, Joshua B. and {Shu}, Tianmin and {Gan}, Chuang},
        title = "{Building Cooperative Embodied Agents Modularly with Large Language Models}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Recognition},
         year = 2023,
        month = jul,
          eid = {arXiv:2307.02485},
        pages = {arXiv:2307.02485},
archivePrefix = {arXiv},
       eprint = {2307.02485},
 primaryClass = {cs.AI},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{chateval,
       author = {{Chan}, Chi-Min and {Chen}, Weize and {Su}, Yusheng and {Yu}, Jianxuan and {Xue}, Wei and {Zhang}, Shanghang and {Fu}, Jie and {Liu}, Zhiyuan},
        title = "{ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Computation and Language},
         year = 2023,
        month = aug,
       eprint = {2308.07201}
}

@ARTICLE{llm-dba,
       author = {{Zhou}, Xuanhe and {Li}, Guoliang and {Liu}, Zhiyuan},
        title = "{LLM As DBA}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Databases, Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Machine Learning},
         year = 2023,
        month = aug,
          eid = {arXiv:2308.05481},
        pages = {arXiv:2308.05481},
archivePrefix = {arXiv},
       eprint = {2308.05481},
 primaryClass = {cs.DB},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{gpt-iot,
       author = {{Nascimento}, Nathalia and {Alencar}, Paulo and {Cowan}, Donald},
        title = "{GPT-in-the-Loop: Adaptive Decision-Making for Multiagent Systems}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Multiagent Systems, Computer Science - Artificial Intelligence, Computer Science - Neural and Evolutionary Computing, Computer Science - Software Engineering},
         year = 2023,
        month = aug,
          eid = {arXiv:2308.10435},
        pages = {arXiv:2308.10435},
archivePrefix = {arXiv},
       eprint = {2308.10435},
 primaryClass = {cs.MA},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{ma2024agentboard,
  title={Agentboard: An analytical evaluation board of multi-turn llm agents},
  author={Ma, Chang and Zhang, Junlei and Zhu, Zhihao and Yang, Cheng and Yang, Yujiu and Jin, Yaohui and Lan, Zhenzhong and Kong, Lingpeng and He, Junxian},
  journal={arXiv preprint arXiv:2401.13178},
  year={2024}
}

@inproceedings{post-2018-sacrebleu,
  title = "A Call for Clarity in Reporting {BLEU} Scores",
  author = "Post, Matt",
  booktitle = "Proceedings of the Third Conference on Machine Translation: Research Papers",
  month = oct,
  year = "2018",
  address = "Belgium, Brussels",
  publisher = "Association for Computational Linguistics",
  url = "https://www.aclweb.org/anthology/W18-6319",
  pages = "186--191",
}

@article{wang2022scienceworld,
  title={Scienceworld: Is your agent smarter than a 5th grader?},
  author={Wang, Ruoyao and Jansen, Peter and C{\^o}t{\'e}, Marc-Alexandre and Ammanabrolu, Prithviraj},
  journal={arXiv preprint arXiv:2203.07540},
  year={2022}
}

@article{Ren2020CodeBLEUAM,
  title={CodeBLEU: a Method for Automatic Evaluation of Code Synthesis},
  author={Shuo Ren and Daya Guo and Shuai Lu and Long Zhou and Shujie Liu and Duyu Tang and M. Zhou and Ambrosio Blanco and Shuai Ma},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.10297},
}

@article{shridhar2020alfworld,
  title={Alfworld: Aligning text and embodied environments for interactive learning},
  author={Shridhar, Mohit and Yuan, Xingdi and C{\^o}t{\'e}, Marc-Alexandre and Bisk, Yonatan and Trischler, Adam and Hausknecht, Matthew},
  journal={arXiv preprint arXiv:2010.03768},
  year={2020}
}

@inproceedings{trueskill,
 author = {Herbrich, Ralf and Minka, Tom and Graepel, Thore},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {B. Sch\"{o}lkopf and J. Platt and T. Hoffman},
 pages = {},
 publisher = {MIT Press},
 title = {TrueSkill\texttrademark : A Bayesian Skill Rating System},
 url = {https://proceedings.neurips.cc/paper_files/paper/2006/file/f44ee263952e65b3610b8ba51229d1f9-Paper.pdf},
 volume = {19},
 year = {2006}
}

@ARTICLE{self-collab-codegen,
       author = {{Dong}, Yihong and {Jiang}, Xue and {Jin}, Zhi and {Li}, Ge},
        title = "{Self-collaboration Code Generation via ChatGPT}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Software Engineering},
         year = 2023,
        month = apr,
          eid = {arXiv:2304.07590},
        pages = {arXiv:2304.07590},
archivePrefix = {arXiv},
       eprint = {2304.07590},
 primaryClass = {cs.SE},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{human-collaboration,
  title={Advancing the Science of Collaborative Problem Solving},
  author={Arthur C. Graesser and Stephen M. Fiore and Samuel Greiff and Jessica Andrews-Todd and Peter W. Foltz and Friedrich W. Hesse},
  journal={Psychological Science in the Public Interest},
  year={2018},
  volume={19},
  pages={59 - 92},
}

@ARTICLE{multi-agent,
  author={Dorri, Ali and Kanhere, Salil S. and Jurdak, Raja},
  journal={IEEE Access}, 
  title={Multi-Agent Systems: A Survey}, 
  year={2018},
  volume={6},
  number={},
  pages={28573-28593}}

@misc{chatllm-network,
   author = {Hao, Rui and Hu, Linmei and Qi, Weijian and Wu, Qingliu and Zhang, Yirui and Nie, Liqiang},
   title = {ChatLLM Network: More brains, More intelligence},
   pages = {arXiv:2304.12998},
   month = {April 01, 2023},
   abstract = {Dialogue-based language models mark a huge milestone in the field of artificial intelligence, by their impressive ability to interact with users, as well as a series of challenging tasks prompted by customized instructions. However, the prevalent large-scale dialogue-based language models like ChatGPT still have room for improvement, such as unstable responses to questions and the inability to think cooperatively like humans. Considering the ability of dialogue-based language models in conversation and their inherent randomness in thinking, we propose ChatLLM network that allows multiple dialogue-based language models to interact, provide feedback, and think together. We design the network of ChatLLMs based on ChatGPT. Specifically, individual instances of ChatGPT may possess distinct perspectives towards the same problem, and by consolidating these diverse viewpoints via a separate ChatGPT, the ChatLLM network system can conduct decision-making more objectively and comprehensively. In addition, a language-based feedback mechanism comparable to backpropagation is devised to update the ChatGPTs within the network. Experiments on two datasets demonstrate that our network attains significant improvements in problem-solving, leading to observable progress amongst each member.},
   keywords = {Computer Science - Artificial Intelligence
Computer Science -
Computation and Language},
   year = {2023},
   type = {Electronic Article}
}

@INPROCEEDINGS{human-team-building,
  author={Liu, Qing and Luo, Tie and Tang, Ruiming and Bressan, Stéphane},
  booktitle={2015 IEEE International Conference on Communications (ICC)}, 
  title={An efficient and truthful pricing mechanism for team formation in crowdsourcing markets}, 
  year={2015},
  volume={},
  number={},
  pages={567-572}}

@article{zhang2023exploring,
  title={Exploring collaboration mechanisms for llm agents: A social psychology view},
  author={Zhang, Jintian and Xu, Xin and Deng, Shumin},
  journal={arXiv preprint arXiv:2310.02124},
  year={2023}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib"). 

-----Surveys-----
@article{arXiv2023_Survey-LLM,
  author       = {Wayne Xin Zhao and
                  Kun Zhou and
                  Junyi Li and
                  Tianyi Tang and
                  Xiaolei Wang and
                  Yupeng Hou and
                  Yingqian Min and
                  Beichen Zhang and
                  Junjie Zhang and
                  Zican Dong and
                  Yifan Du and
                  Chen Yang and
                  Yushuo Chen and
                  Zhipeng Chen and
                  Jinhao Jiang and
                  Ruiyang Ren and
                  Yifan Li and
                  Xinyu Tang and
                  Zikang Liu and
                  Peiyu Liu and
                  Jian{-}Yun Nie and
                  Ji{-}Rong Wen},
  title        = {A Survey of Large Language Models},
  journal      = {arXiv preprint},
  volume       = {abs/2303.18223},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.18223},
  doi          = {10.48550/arXiv.2303.18223}
}

@article{arXiv2023_Survey-MLLM,
  author       = {Shukang Yin and
                  Chaoyou Fu and
                  Sirui Zhao and
                  Ke Li and
                  Xing Sun and
                  Tong Xu and
                  Enhong Chen},
  title        = {A Survey on Multimodal Large Language Models},
  journal      = {arXiv preprint},
  volume       = {abs/2306.13549},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.13549},
  doi          = {10.48550/arXiv.2306.13549}
}

@article{arXiv2023_Survey-LLM-KGCR,
  author       = {Yuqi Zhu and
                  Xiaohan Wang and
                  Jing Chen and
                  Shuofei Qiao and
                  Yixin Ou and
                  Yunzhi Yao and
                  Shumin Deng and
                  Huajun Chen and
                  Ningyu Zhang},
  title        = {LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities},
  journal      = {CoRR},
  volume       = {abs/2305.13168},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.13168},
  doi          = {10.48550/arXiv.2305.13168}
}

@article{arXiv2024_Survey-LLM-Psychology-Applications,
  author       = {Luoma Ke and 
                  Song Tong and 
                  Peng Chen and 
                  Kaiping Peng},
  title        ={Exploring the Frontiers of LLMs in Psychological Applications: A Comprehensive Review}, 
  journal      = {CoRR},
  volume       = {abs/2401.01519},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.01519}
}

@article{FCS2024_Survey-Agent,
  author       = {Lei Wang and
                  Chen Ma and
                  Xueyang Feng and
                  Zeyu Zhang and
                  Hao Yang and
                  Jingsen Zhang and
                  Zhiyuan Chen and
                  Jiakai Tang and
                  Xu Chen and
                  Yankai Lin and
                  Wayne Xin Zhao and
                  Zhewei Wei and
                  Ji{-}Rong Wen},
  title        = {A Survey on Large Language Model based Autonomous Agents},
  journal      = {Front. Comput. Sci.},
  volume       = {18},
  year         = {2024}
}
arXiv2023_Survey-Agent

@article{arXiv2023_Survey-Agent_2,
  author       = {Zhiheng Xi and
                  Wenxiang Chen and
                  Xin Guo and
                  Wei He and
                  Yiwen Ding and
                  Boyang Hong and
                  Ming Zhang and
                  Junzhe Wang and
                  Senjie Jin and
                  Enyu Zhou and
                  Rui Zheng and
                  Xiaoran Fan and
                  Xiao Wang and
                  Limao Xiong and
                  Yuhao Zhou and
                  Weiran Wang and
                  Changhao Jiang and
                  Yicheng Zou and
                  Xiangyang Liu and
                  Zhangyue Yin and
                  Shihan Dou and
                  Rongxiang Weng and
                  Wensen Cheng and
                  Qi Zhang and
                  Wenjuan Qin and
                  Yongyan Zheng and
                  Xipeng Qiu and
                  Xuanjing Huan and
                  Tao Gui},
  title        = {The Rise and Potential of Large Language Model Based Agents: {A} Survey},
  journal      = {arxiv preprint},
  volume       = {abs/2309.07864},
  year         = {2023}
}

@article{arXiv2023_Survey-Agent_3,
  author       = {Chen Gao and 
                  Xiaochong Lan and 
                  Nian Li and 
                  Yuan Yuan and 
                  Jingtao Ding and 
                  Zhilun Zhou and 
                  Fengli Xu and 
                  Yong Li},
  title        = {Large Language Models Empowered Agent-based Modeling and Simulation: A Survey and Perspectives},
  journal      = {CoRR},
  volume       = {abs/2312.11970},
  year         = {2023}
}

@article{arXiv2024_Survey-Agent_4,
  author       = {Yuheng Cheng and 
                  Ceyao Zhang and 
                  Zhengwen Zhang and 
                  Xiangrui Meng and 
                  Sirui Hong and 
                  Wenhao Li and 
                  Zihao Wang and 
                  Zekai Wang and 
                  Feng Yin and 
                  Junhua Zhao and 
                  Xiuqiang He},
  title        = {Exploring Large Language Model based Intelligent Agents: Definitions, Methods, and Prospects},
  journal      = {CoRR},
  volume       = {abs/2401.03428},
  year         = {2024}
}

@article{arXiv2024_Survey-Agents-CompExp,
  author       = {Qun Ma and 
                  Xiao Xue and 
                  Deyu Zhou and 
                  Xiangning Yu and 
                  Donghua Liu and 
                  Xuwen Zhang and 
                  Zihan Zhao and 
                  Yifan Shen and 
                  Peilin Ji and 
                  Juanjuan Li and 
                  Gang Wang and 
                  Wanpeng Ma},
  title        = {Computational Experiments Meet Large Language Model Based Agents: A Survey and Perspective},
  journal      = {CoRR},
  volume       = {abs/2402.00262},
  year         = {2024}
}

@article{arXiv2024_Survey-MultiAgent,
  author       = {Taicheng Guo and 
                  Xiuying Chen and 
                  Yaqi Wang and 
                  Ruidi Chang and 
                  Shichao Pei and 
                  Nitesh V. Chawla and 
                  Olaf Wiest and 
                  Xiangliang Zhang},
  title        = {Large Language Model based Multi-Agents: A Survey of Progress and Challenges},
  journal      = {CoRR},
  volume       = {abs/2402.01680},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.01680}
}

@article{arXiv2024_Survey-MultiAgent_2,
  author       = {Pouya Pezeshkpour and 
                  Eser Kandogan and 
                  Nikita Bhutani and 
                  Sajjadur Rahman and 
                  Tom Mitchell and 
                  Estevam Hruschka},
  title        = {Reasoning Capacity in Multi-Agent Systems: Limitations, Challenges and Human-Centered Solutions},
  journal      = {CoRR},
  volume       = {abs/2402.01108},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.01108}
}

@article{arXiv2024_Survey-MultiAgent-System,
  author       = {Hung Du and 
                  Srikanth Thudumu and 
                  Rajesh Vasa and 
                  Kon Mouzakis},
  title        = {A Survey on Context-Aware Multi-Agent Systems: Techniques, Challenges and Future Directions},
  journal      = {CoRR},
  volume       = {abs/2402.01968},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.01968}
}

@article{arXiv2024_Survey-MultiAgent-System_2,
  author       = {Shanshan Han and 
                  Qifan Zhang and 
                  Yuhang Yao and 
                  Weizhao Jin and 
                  Zhaozhuo Xu and 
                  Chaoyang He},
  title        = {LLM Multi-Agent Systems: Challenges and Open Problems},
  journal      = {CoRR},
  volume       = {abs/2402.03578},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.03578}
}

@article{J2024_Survey-AI-SocialScience,
  author       = {Ruoxi Xu and 
                  Yingfei Sun and 
                  Mengjie Ren and 
                  Shiguang Guo and 
                  Ruotong Pan and 
                  Hongyu Lin and 
                  Le Sun and 
                  Xianpei Han},
  title        = {AI for social science and social science of AI: A Survey},
  journal      = {Information Processing \& Management},
  volume       = {61},
  number       = {3},
  pages        = {103665},
  year         = {2024},
  issn         = {0306-4573},
  url          = {https://www.sciencedirect.com/science/article/pii/S0306457324000256},
  doi          = {https://doi.org/10.1016/j.ipm.2024.103665}
}
arXiv2024_Survey-AI-SocialScience

@article{arXiv2023_Survey-MultiAgentCooperation,
  author       = {Yali Du and
                  Joel Z. Leibo and
                  Usman Islam and
                  Richard Willis and
                  Peter Sunehag},
  title        = {A Review of Cooperation in Multi-agent Learning},
  journal      = {CoRR},
  volume       = {abs/2312.05162},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2312.05162},
  doi          = {10.48550/ARXIV.2312.05162}
}

@article{arXiv2024_Survey-AgentAI_MMInteraction,
  author       = {Zane Durante and 
                  Qiuyuan Huang and 
                  Naoki Wake and 
                  Ran Gong and 
                  Jae Sung Park and 
                  Bidipta Sarkar and 
                  Rohan Taori and 
                  Yusuke Noda and 
                  Demetri Terzopoulos and 
                  Yejin Choi and 
                  Katsushi Ikeuchi and 
                  Hoi Vo and 
                  Li Fei-Fei and 
                  Jianfeng Gao},
  title        = {Agent AI: Surveying the Horizons of Multimodal Interaction},
  journal      = {CoRR},
  volume       = {abs/2401.03568},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.03568}
}

@article{arXiv2024_Survey-CooperativeAgent-RL,
  author       = {Jiechuan Jiang and 
                  Kefan Su and 
                  Zongqing Lu},
  title        = {Fully Decentralized Cooperative Multi-Agent Reinforcement Learning: A Survey},
  journal      = {CoRR},
  volume       = {abs/2401.04934},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.04934}
}

@inproceedings{ICLR2024_Sycophancy-LLM,
  author       = {Mrinank Sharma and
                  Meg Tong and
                  Tomasz Korbak and
                  David Duvenaud and
                  Amanda Askell and
                  Samuel R. Bowman and
                  Newton Cheng and
                  Esin Durmus and
                  Zac Hatfield{-}Dodds and
                  Scott R. Johnston and
                  Shauna Kravec and
                  Timothy Maxwell and
                  Sam McCandlish and
                  Kamal Ndousse and
                  Oliver Rausch and
                  Nicholas Schiefer and
                  Da Yan and
                  Miranda Zhang and
                  Ethan Perez},
  title        = {Towards Understanding Sycophancy in Language Models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=tvhaxkMKAn}
}
arXiv2023_Sycophancy-LLM

@article{J2008_Survey-MultiAgent-Reinforce,
  author       = {Lucian Busoniu and
                  Robert Babuska and
                  Bart De Schutter},
  title        = {A Comprehensive Survey of Multiagent Reinforcement Learning},
  journal      = {{IEEE} Trans. Syst. Man Cybern. Part {C}},
  volume       = {38},
  number       = {2},
  pages        = {156--172},
  year         = {2008},
  url          = {https://doi.org/10.1109/TSMCC.2007.913919},
  doi          = {10.1109/TSMCC.2007.913919}
}

@article{arXiv2023_Survey-MultiAgent-Reinforce,
  author       = {Dom Huh and 
                  Prasant Mohapatra},
  title        = {Multi-agent Reinforcement Learning: A Comprehensive Survey}, 
  journal      = {arxiv preprint},
  volume       = {abs/2312.10256},
  year         = {2023},
  url          = {https://arxiv.org/abs/2312.10256}
}

@article{arXiv2023_Survey-Hallucination_LFM,
  author       = {Vipula Rawte and
                  Amit P. Sheth and
                  Amitava Das},
  title        = {A Survey of Hallucination in Large Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2309.05922},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.05922},
  doi          = {10.48550/arXiv.2309.05922}
}

@article{J2023_Survey-Hallucination_NLG,
  author       = {Ziwei Ji and
                  Nayeon Lee and
                  Rita Frieske and
                  Tiezheng Yu and
                  Dan Su and
                  Yan Xu and
                  Etsuko Ishii and
                  Yejin Bang and
                  Andrea Madotto and
                  Pascale Fung},
  title        = {Survey of Hallucination in Natural Language Generation},
  journal      = {{ACM} Comput. Surv.},
  volume       = {55},
  number       = {12},
  pages        = {248:1--248:38},
  year         = {2023},
  url          = {https://doi.org/10.1145/3571730},
  doi          = {10.1145/3571730}
}

@article{arXiv2023_Survey-Hallucination_LLM,
  author       = {Yue Zhang and
                  Yafu Li and
                  Leyang Cui and
                  Deng Cai and
                  Lemao Liu and
                  Tingchen Fu and
                  Xinting Huang and
                  Enbo Zhao and
                  Yu Zhang and
                  Yulong Chen and
                  Longyue Wang and
                  Anh Tuan Luu and
                  Wei Bi and
                  Freda Shi and
                  Shuming Shi},
  title        = {Siren's Song in the {AI} Ocean: {A} Survey on Hallucination in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.01219},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.01219},
  doi          = {10.48550/ARXIV.2309.01219}
}

@article{arXiv2024_Survey-Hallucination,
  author       = {Junliang Luo and 
                  Tianyu Li and 
                  Di Wu and 
                  Michael Jenkin and 
                  Steve Liu and 
                  Gregory Dudek},
  title        = {Hallucination Detection and Hallucination Mitigation: An Investigation},
  journal      = {CoRR},
  volume       = {abs/2401.08358},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.08358}
}

@article{arXiv2024_Analysis-Hallucination,
  author       = {Ziwei Xu and 
                  Sanjay Jain and 
                  Mohan Kankanhalli},
  title        = {Hallucination is Inevitable: An Innate Limitation of Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.11817},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.11817}
}


-----Multi-Agent-----
@inproceedings{1995_MultiAgent-System,
  author       = {Gerhard Wei{\ss}},
  title        = {Adaptation and Learning in Multi-Agent Systems: Some Remarks and a Bibliography},
  booktitle    = {Adaption and Learning in Multi-Agent Systems},
  series       = {Lecture Notes in Computer Science},
  volume       = {1042},
  pages        = {1--21},
  publisher    = {Springer},
  year         = {1995},
  url          = {https://doi.org/10.1007/3-540-60923-7\_16},
  doi          = {10.1007/3-540-60923-7\_16}
}

@article{J2000_MultiAgent-System,
  author       = {Peter Stone and
                  Manuela M. Veloso},
  title        = {Multiagent Systems: {A} Survey from a Machine Learning Perspective},
  journal      = {Auton. Robots},
  volume       = {8},
  number       = {3},
  pages        = {345--383},
  publisher    = {Springer},
  year         = {2000},
  url          = {https://doi.org/10.1023/A:1008942012299},
  doi          = {10.1023/A:1008942012299}
}

@book{Book2006_MultiAgent-System,
  author       = {Jos\'{e} M. Vidal},
  title        = {Fundamentals of Multiagent Systems: Using NetLogo Models},
  publisher    = {Unpublished},
  year         = {2006},
  url          = {http://www.multiagent.com/fmas},
  note         = {\url{http://www.multiagent.com}},
  cluster      = {10994802165800486817}
}

@book{Book2009_MultiAgent-System,
  author       = {Michael J. Wooldridge},
  title        = {An Introduction to MultiAgent Systems, Second Edition},
  publisher    = {Wiley},
  url          = {https://www.cs.ox.ac.uk/people/michael.wooldridge/pubs/imas/IMAS2e.html},
  year         = {2009},
  isbn         = {978-0-470-51946-2}
}

@article{arXiv2024_Formal-LLM,
  author       = {Zelong Li and 
                  Wenyue Hua and 
                  Hao Wang and 
                  He Zhu and 
                  Yongfeng Zhang},
  title        = {Formal-LLM: Integrating Formal Language and Natural Language for Controllable LLM-based Agents},
  journal      = {CoRR},
  volume       = {abs/2402.00798},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.00798}
}

@article{arXiv2023_Agents,
  author       = {Wangchunshu Zhou and
                  Yuchen Eleanor Jiang and
                  Long Li and
                  Jialong Wu and
                  Tiannan Wang and
                  Shi Qiu and
                  Jintian Zhang and
                  Jing Chen and
                  Ruipu Wu and
                  Shuai Wang and
                  Shiding Zhu and
                  Jiyu Chen and
                  Wentao Zhang and
                  Ningyu Zhang and
                  Huajun Chen and
                  Peng Cui and
                  Mrinmaya Sachan},
  title        = {Agents: An Open-source Framework for Autonomous Language Agents},
  journal      = {CoRR},
  volume       = {abs/2309.07870},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.07870},
  doi          = {10.48550/arXiv.2309.07870}
}

@article{arXiv2023_OpenAgents,
  author       = {Tianbao Xie and
                  Fan Zhou and
                  Zhoujun Cheng and
                  Peng Shi and
                  Luoxuan Weng and
                  Yitao Liu and
                  Toh Jing Hua and
                  Junning Zhao and
                  Qian Liu and
                  Che Liu and
                  Leo Z. Liu and
                  Yiheng Xu and
                  Hongjin Su and
                  Dongchan Shin and
                  Caiming Xiong and
                  Tao Yu},
  title        = {OpenAgents: An Open Platform for Language Agents in the Wild},
  journal      = {CoRR},
  volume       = {abs/2310.10634},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.10634},
  doi          = {10.48550/ARXIV.2310.10634}
}

@article{arXiv2023_AutoAgents,
  author       = {Guangyao Chen and
                  Siwei Dong and
                  Yu Shu and
                  Ge Zhang and
                  Jaward Sesay and
                  B{\"{o}}rje F. Karlsson and
                  Jie Fu and
                  Yemin Shi},
  title        = {AutoAgents: {A} Framework for Automatic Agent Generation},
  journal      = {CoRR},
  volume       = {abs/2309.17288},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.17288},
  doi          = {10.48550/ARXIV.2309.17288}
}

@article{arXiv2023_CGMI,
  author       = {Jinxin Shi and
                  Jiabao Zhao and
                  Yilei Wang and
                  Xingjiao Wu and
                  Jiawen Li and
                  Liang He},
  title        = {{CGMI:} Configurable General Multi-Agent Interaction Framework},
  journal      = {CoRR},
  volume       = {abs/2308.12503},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.12503},
  doi          = {10.48550/ARXIV.2308.12503}
}

@article{arXiv2023_Believability-Agents,
  author       = {Yang Xiao and 
                  Yi Cheng and 
                  Jinlan Fu and 
                  Jiashuo Wang and 
                  Wenjie Li and 
                  Pengfei Liu},
  title        = {How Far Are We from Believable AI Agents? A Framework for Evaluating the Believability of Human Behavior Simulation},
  journal      = {CoRR},
  volume       = {abs/2312.17115},
  year         = {2023},
  url          = {https://arxiv.org/abs/2312.17115}
}

@article{arXiv2023_MAgIC,
  author       = {Lin Xu and
                  Zhiyuan Hu and
                  Daquan Zhou and
                  Hongyu Ren and
                  Zhen Dong and
                  Kurt Keutzer and
                  See{-}Kiong Ng and
                  Jiashi Feng},
  title        = {MAgIC: Investigation of Large Language Model Powered Multi-Agent in Cognition, Adaptability, Rationality and Collaboration},
  journal      = {CoRR},
  volume       = {abs/2311.08562},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2311.08562},
  doi          = {10.48550/ARXIV.2311.08562}
}

@article{arXiv2024_AgentBoard,
  author       = {Chang Ma and 
                  Junlei Zhang and 
                  Zhihao Zhu and 
                  Cheng Yang and 
                  Yujiu Yang and 
                  Yaohui Jin and 
                  Zhenzhong Lan and 
                  Lingpeng Kong and 
                  Junxian He},
  title        = {AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents},
  journal      = {CoRR},
  volume       = {abs/2401.13178},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.13178}
}

@article{arXiv2024_Evaluate-Agents,
  author       = {Lize Alberts and 
                  Geoff Keeling and 
                  Amanda McCroskery},
  title        = {What makes for a 'good' social actor? Using respect as a lens to evaluate interactions with language agents},
  journal      = {CoRR},
  volume       = {abs/2401.09082},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.09082}
}

---Multi-Agent Collaboration---
@article{arXiv2023_InterAct,
  author       = {Po{-}Lin Chen and
                  Cheng{-}Shang Chang},
  title        = {InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent},
  journal      = {CoRR},
  volume       = {abs/2308.01552},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.01552},
  doi          = {10.48550/ARXIV.2308.01552}
}

@article{arXiv2023_Multi-Agent-Collaboration_Intelligent,
  author       = {Yashar Talebirad and
                  Amirhossein Nadiri},
  title        = {Multi-Agent Collaboration: Harnessing the Power of Intelligent {LLM} Agents},
  journal      = {CoRR},
  volume       = {abs/2306.03314},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.03314},
  doi          = {10.48550/ARXIV.2306.03314}
}

@inproceedings{UIST2023_Agent-Simulate-Interaction,
  author       = {Joon Sung Park and
                  Joseph C. O'Brien and
                  Carrie Jun Cai and
                  Meredith Ringel Morris and
                  Percy Liang and
                  Michael S. Bernstein},
  title        = {Generative Agents: Interactive Simulacra of Human Behavior},
  booktitle    = {{UIST}},
  pages        = {2:1--2:22},
  publisher    = {{ACM}},
  year         = {2023}
}


@inproceedings{AAAI2024_CooperativeAgents_ProAgent,
  author       = {Ceyao Zhang and
                  Kaijie Yang and
                  Siyi Hu and
                  Zihao Wang and
                  Guanghe Li and
                  Yihang Sun and
                  Cheng Zhang and
                  Zhaowei Zhang and
                  Anji Liu and
                  Song{-}Chun Zhu and
                  Xiaojun Chang and
                  Junge Zhang and
                  Feng Yin and
                  Yitao Liang and
                  Yaodong Yang},
  title        = {ProAgent: Building Proactive Cooperative Agents with Large Language
                  Models},
  booktitle    = {{AAAI}},
  pages        = {17591--17599},
  publisher    = {{AAAI} Press},
  year         = {2024},
  url          = {https://doi.org/10.1609/aaai.v38i16.29710},
  doi          = {10.1609/AAAI.V38I16.29710}
}

@article{sun2023corex,
  title={Corex: Pushing the boundaries of complex reasoning through multi-model collaboration},
  author={Sun, Qiushi and Yin, Zhangyue and Li, Xiang and Wu, Zhiyong and Qiu, Xipeng and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2310.00280},
  year={2023}
}

@article{chen2024comm,
  title={CoMM: Collaborative multi-agent, multi-reasoning-path prompting for complex problem solving},
  author={Chen, Pei and Han, Boran and Zhang, Shuai},
  journal={arXiv preprint arXiv:2404.17729},
  year={2024}
}

@inproceedings{ICLR2024_MultiAgent_AgentVerse,
  author       = {Weize Chen and
                  Yusheng Su and
                  Jingwei Zuo and
                  Cheng Yang and
                  Chenfei Yuan and
                  Chen Qian and
                  Chi{-}Min Chan and
                  Yujia Qin and
                  Yaxi Lu and
                  Ruobing Xie and
                  Zhiyuan Liu and
                  Maosong Sun and
                  Jie Zhou},
  title        = {AgentVerse: Facilitating Multi-Agent Collaboration and Exploring Emergent Behaviors in Agents},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=EHg5GDnyq1}
}

@article{arXiv2023_Dynamic-LLM-Agent,
  author       = {Zijun Liu and
                  Yanzhe Zhang and
                  Peng Li and
                  Yang Liu and
                  Diyi Yang},
  title        = {Dynamic LLM-Agent Network: An LLM-agent Collaboration Framework with Agent Team Optimization},
  journal      = {CoRR},
  volume       = {abs/2310.02170},
  year         = {2023}
}

@inproceedings{EMNLP2023-Demo_CollaborativeLLMs,
  author       = {Kai Lv and
                  Shuo Zhang and
                  Tianle Gu and
                  Shuhao Xing and
                  Jiawei Hong and
                  Keyu Chen and
                  Xiaoran Liu and
                  Yuqing Yang and
                  Honglin Guo and
                  Tengxiao Liu and
                  Yu Sun and
                  Qipeng Guo and
                  Hang Yan and
                  Xipeng Qiu},
  title        = {CoLLiE: Collaborative Training of Large Language Models in an Efficient Way},
  booktitle    = {{EMNLP} (Demos)},
  pages        = {527--542},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://aclanthology.org/2023.emnlp-demo.48}
}

@article{J2024_MechAgents-MultiAgentCollaborations,
  author       = {Bo Ni and
                  Markus J. Buehler},
  title        = {MechAgents: Large language model multi-agent collaborations can solve mechanics problems, generate new data, and integrate knowledge},
  journal      = {Extreme Mechanics Letters},
  volume     = {67},
  pages      = {102131},
  year       = {2024},
  issn       = {2352-4316},
  url        = {https://www.sciencedirect.com/science/article/pii/S2352431624000117},
  doi        = {https://doi.org/10.1016/j.eml.2024.102131}
}
arXiv2023_MechAgents-MultiAgentCollaborations

@article{arXiv2023_MultiAgent-Coordination-Eval,
  author       = {Saaket Agashe and
                  Yue Fan and
                  Xin Eric Wang},
  title        = {Evaluating Multi-Agent Coordination Abilities in Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2310.03903},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.03903},
  doi          = {10.48550/ARXIV.2310.03903}
}

@inproceedings{ICLR2024_Agent-Interactive-Eval,
  author       = {Xuhui Zhou and
                  Hao Zhu and
                  Leena Mathur and
                  Ruohong Zhang and
                  Haofei Yu and
                  Zhengyang Qi and
                  Louis{-}Philippe Morency and
                  Yonatan Bisk and
                  Daniel Fried and
                  Graham Neubig and
                  Maarten Sap},
  title        = {{SOTOPIA:} Interactive Evaluation for Social Intelligence in Language Agents},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=mM7VurbA4r}
}
arXiv2023_Agent-Interactive-Eval

@inproceedings{AAMAS2024_AgentInteraction-Quantifying,
  author       = {Yuxin Chen and
                  Chen Tang and
                  Ran Tian and
                  Chenran Li and
                  Jinning Li and
                  Masayoshi Tomizuka and
                  Wei Zhan},
  title        = {Quantifying Agent Interaction in Multi-agent Reinforcement Learning for Cost-efficient Generalization},
  booktitle    = {{AAMAS}},
  pages        = {2201--2203},
  publisher    = {{ACM}},
  year         = {2024},
  url          = {https://dl.acm.org/doi/10.5555/3635637.3663107},
  doi          = {10.5555/3635637.3663107}
}
arXiv2023_AgentInteraction-Quantifying

@article{arXiv2023_LLM-Deliberation,
  author       = {Sahar Abdelnabi and
                  Amr Gomaa and
                  Sarath Sivaprasad and
                  Lea Sch{\"{o}}nherr and
                  Mario Fritz},
  title        = {LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games},
  journal      = {CoRR},
  volume       = {abs/2309.17234},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.17234},
  doi          = {10.48550/ARXIV.2309.17234}
}

@article{arXiv2023_MultiAgent-Cooperation,
  author       = {Rafael Pina and
                  Varuna De Silva and
                  Corentin Artaud},
  title        = {Discovering Causality for Efficient Cooperation in Multi-Agent Environments},
  journal      = {CoRR},
  volume       = {abs/2306.11846},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.11846},
  doi          = {10.48550/ARXIV.2306.11846}
}

@article{arXiv2023_MultiAgent-Algorithms,
  author       = {Lin Yang and
                  Xuchuang Wang and
                  Mohammad Hajiesmaili and
                  Lijun Zhang and
                  John C. S. Lui and
                  Don Towsley},
  title        = {Cooperative Multi-agent Bandits: Distributed Algorithms with Optimal Individual Regret and Constant Communication Costs},
  journal      = {CoRR},
  volume       = {abs/2308.04314},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.04314},
  doi          = {10.48550/ARXIV.2308.04314}
}


-----Debate and Reflection-----
@book{Book1971_Rhetoric,
  author       = {Perelman, Chaim},
  title        = {The new rhetoric},
  publisher    = {Springer},
  year         = {1971},
  url          = {https://link.springer.com/chapter/10.1007/978-94-010-1713-8_8}
}

@book{Book2005_Society-Dissent,
  author       = {Cass R Sunstein},
  title        = {Why societies need dissent},
  publisher    = {Harvard University Press},
  year         = {2005},
  url          = {https://doi.org/10.4159/9780674267657}
}

@article{J2009_DecisionMaking,
  author       = {Leila Amgoud and
                  Henri Prade},
  title        = {Using arguments for making and explaining decisions},
  journal      = {Artif. Intell.},
  volume       = {173},
  number       = {3-4},
  pages        = {413--436},
  publisher    = {Elsevier},
  year         = {2009},
  url          = {https://doi.org/10.1016/j.artint.2008.11.006},
  doi          = {10.1016/j.artint.2008.11.006} 
}

@article{arXiv2023_MultiAgent-Debate,
  author       = {Yilun Du and
                  Shuang Li and
                  Antonio Torralba and
                  Joshua B. Tenenbaum and
                  Igor Mordatch},
  title        = {Improving Factuality and Reasoning in Language Models through Multiagent Debate},
  journal      = {CoRR},
  volume       = {abs/2305.14325},
  year         = {2023}
}

@article{yan2024depending,
  title={Depending on yourself when you should: Mentoring LLM with RL agents to become the master in cybersecurity games},
  author={Yan, Yikuan and Zhang, Yaolun and Huang, Keman},
  journal={arXiv preprint arXiv:2403.17674},
  year={2024}
}

@inproceedings{holt2024l2mac,
  title={L2MAC: Large Language Model Automatic Computer for Extensive Code Generation},
  author={Holt, Samuel and Luyten, Max Ruiz and van der Schaar, Mihaela},
  booktitle={The Twelfth International Conference on Learning Representations},
year={2024}
}

@article{zhou2023large,
  title={Large language model as a policy teacher for training reinforcement learning agents},
  author={Zhou, Zihao and Hu, Bin and Zhao, Chenyang and Zhang, Pu and Liu, Bin},
  journal={arXiv preprint arXiv:2311.13373},
  year={2023}
}

@article{arXiv2023_MultiAgent-Debate_2,
  author       = {Tian Liang and
                  Zhiwei He and
                  Wenxiang Jiao and
                  Xing Wang and
                  Yan Wang and
                  Rui Wang and
                  Yujiu Yang and
                  Zhaopeng Tu and
                  Shuming Shi},
  title        = {Encouraging Divergent Thinking in Large Language Models through Multi-Agent Debate},
  journal      = {CoRR},
  volume       = {abs/2305.19118},
  year         = {2023}
}

@inproceedings{ICLR2024_Multiagent-Debate-Embeddings,
  author       = {Chau Pham and
                  Boyi Liu and
                  Yingxiang Yang and
                  Zhengyu Chen and
                  Tianyi Liu and
                  Jianbo Yuan and
                  Bryan A. Plummer and
                  Zhaoran Wang and
                  Hongxia Yang},
  title        = {Let Models Speak Ciphers: Multiagent Debate through Embeddings},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=sehRvaIPQQ}
}
arXiv2023_Multiagent-Debate-Embeddings

@inproceedings{ICLR2024_Multiagent-Debate-Eval,
  author       = {Chi{-}Min Chan and
                  Weize Chen and
                  Yusheng Su and
                  Jianxuan Yu and
                  Wei Xue and
                  Shanghang Zhang and
                  Jie Fu and
                  Zhiyuan Liu},
  title        = {ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=FQepisCUWu}
}
arXiv2023_Multiagent-Debate-Eval

@article{J1985_Reflection,
  author       = {R. J. Bogumil},
  title        = {The reflective practitioner: How professionals think in action},
  journal      = {Proc. {IEEE}},
  volume       = {73},
  number       = {4},
  pages        = {845--846},
  year         = {1985},
  url          = {https://doi.org/10.1109/PROC.1985.13210},
  doi          = {10.1109/PROC.1985.13210}
}

@book{Book2010_Reflection,
  author       = {Bolton, Gillie},
  title        = {Reflective practice: Writing and professional development},
  publisher    = {Sage publications},
  year         = {2010},
  url          = {https://uk.sagepub.com/en-gb/eur/reflective-practice/book252252}
}

@article{zelikman2023parsel,
  title={Parsel: Algorithmic Reasoning with Language Models by Composing Decompositions},
  author={Zelikman, Eric and Huang, Qian and Poesia, Gabriel and Goodman, Noah and Haber, Nick},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={31466--31523},
  year={2023}
}

@article{huang2024anpl,
  title={ANPL: towards natural programming with interactive decomposition},
  author={Huang, Di and Nan, Ziyuan and Hu, Xing and Jin, Pengwei and Peng, Shaohui and Wen, Yuanbo and Zhang, Rui and Du, Zidong and Guo, Qi and Pu, Yewen and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

% reflection-1 3 prompt
@article{reflexion,
  author       = {Noah Shinn and
                  Beck Labash and
                  Ashwin Gopinath},
  title        = {Reflexion: an autonomous agent with dynamic memory and self-reflection},
  journal      = {arXiv preprint},
  volume       = {abs/2303.11366},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.11366},
  doi          = {10.48550/arXiv.2303.11366}
}

% reflection-2 reinforcement
arXiv2023_Self-Refine
@inproceedings{NeurIPS2023_Self-Refine,
  author       = {Aman Madaan and
                  Niket Tandon and
                  Prakhar Gupta and
                  Skyler Hallinan and
                  Luyu Gao and
                  Sarah Wiegreffe and
                  Uri Alon and
                  Nouha Dziri and
                  Shrimai Prabhumoye and
                  Yiming Yang and
                  Shashank Gupta and
                  Bodhisattwa Prasad Majumder and
                  Katherine Hermann and
                  Sean Welleck and
                  Amir Yazdanbakhsh and
                  Peter Clark},
  title        = {Self-Refine: Iterative Refinement with Self-Feedback},
  booktitle    = {NeurIPS},
  year         = {2023},
  url          = {http://papers.nips.cc/paper\_files/paper/2023/hash/91edff07232fb1b55a505a9e9f6c0ff3-Abstract-Conference.html}
}

@article{J2003_Reflection-ContinuingEducation,
  author       = {Mezirow, Jack},
  title        = {How critical reflection triggers transformative learning},
  journal      = {Adult and Continuing Education: Teaching, learning and research},
  volume       = {4},
  pages        = {199},
  publisher    = {Taylor \& Francis},
  year         = {2003},
  url          = {https://www.colorado.edu/plc/sites/default/files/attached-files/how_critical_reflection_triggers_transfo.pdf}
}

@article{arXiv2024_Self-Contrast,
  author       = {Wenqi Zhang and 
                  Yongliang Shen and 
                  Linjuan Wu and 
                  Qiuying Peng and 
                  Jun Wang and 
                  Yueting Zhuang and 
                  Weiming Lu},
  title        = {Self-Contrast: Better Reflection Through Inconsistent Solving Perspectives}, 
  journal      = {CoRR},
  volume       = {abs/2401.02009},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.02009}
}


-----Interactive NLP-----
@article{arXiv2023_InteractiveNLP,
  author       = {Zekun Wang and
                  Ge Zhang and
                  Kexin Yang and
                  Ning Shi and
                  Wangchunshu Zhou and
                  Shaochun Hao and
                  Guangzheng Xiong and
                  Yizhi Li and
                  Mong Yuan Sim and
                  Xiuying Chen and
                  Qingqing Zhu and
                  Zhenzhu Yang and
                  Adam Nik and
                  Qi Liu and
                  Chenghua Lin and
                  Shi Wang and
                  Ruibo Liu and
                  Wenhu Chen and
                  Ke Xu and
                  Dayiheng Liu and
                  Yike Guo and
                  Jie Fu},
  title        = {Interactive Natural Language Processing},
  journal      = {CoRR},
  volume       = {abs/2305.13246},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.13246},
  doi          = {10.48550/arXiv.2305.13246}
}

@inproceedings{J2023_InteractiveNLP,
  author       = {Guanhua Zhang and
                  Matteo Bortoletto and
                  Zhiming Hu and
                  Lei Shi and
                  Mihai B{\^{a}}ce and
                  Andreas Bulling},
  title        = {Exploring Natural Language Processing Methods for Interactive Behaviour Modelling},
  booktitle    = {{INTERACT} {(3)}},
  series       = {Lecture Notes in Computer Science},
  volume       = {14144},
  pages        = {3--26},
  publisher    = {Springer},
  year         = {2023},
  url          = {https://doi.org/10.1007/978-3-031-42286-7\_1},
  doi          = {10.1007/978-3-031-42286-7\_1}
}


-----Human-AI Simulation-----
@article{NMI2023_Human-Like-AI,
  author       = {Edgar A. Du{\'{e}}{\~{n}}ez{-}Guzm{\'{a}}n and
                  Suzanne Sadedin and
                  Jane X. Wang and
                  Kevin R. McKee and
                  Joel Z. Leibo},
  title        = {A social path to human-like artificial intelligence},
  journal      = {Nat. Mac. Intell.},
  volume       = {5},
  number       = {11},
  pages        = {1181--1188},
  year         = {2023},
  url          = {https://doi.org/10.1038/s42256-023-00754-x},
  doi          = {10.1038/S42256-023-00754-X}
}

@inproceedings{ICLR2024_LLM-Simulate-Society,
  author       = {Ruibo Liu and
                  Ruixin Yang and
                  Chenyan Jia and
                  Ge Zhang and
                  Denny Zhou and
                  Andrew M. Dai and
                  Diyi Yang and
                  Soroush Vosoughi},
  title        = {Training Socially Aligned Language Models in Simulated Human Society},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=NddKiWtdUm}
}
arXiv2023_LLM-Simulate-Society

@article{arXiv2023_LLMAgents-Simulate-Society_S3,
  author       = {Chen Gao and
                  Xiaochong Lan and
                  Zhihong Lu and
                  Jinzhu Mao and
                  Jinghua Piao and
                  Huandong Wang and
                  Depeng Jin and
                  Yong Li},
  title        = {S\({}^{\mbox{3}}\): Social-network Simulation System with Large Language Model-Empowered Agents},
  journal      = {CoRR},
  volume       = {abs/2307.14984},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.14984},
  doi          = {10.48550/ARXIV.2307.14984}
}

@inproceedings{UIST2022_SocialSimulacra,
  author       = {Joon Sung Park and
                  Lindsay Popowski and
                  Carrie J. Cai and
                  Meredith Ringel Morris and
                  Percy Liang and
                  Michael S. Bernstein},
  title        = {Social Simulacra: Creating Populated Prototypes for Social Computing Systems},
  booktitle    = {{UIST}},
  pages        = {74:1--74:18},
  publisher    = {{ACM}},
  year         = {2022},
  url          = {https://doi.org/10.1145/3526113.3545616},
  doi          = {10.1145/3526113.3545616}
}

@article{arXiv2024_AgentAlignment-SocialNorms,
  author       = {Shimin Li and 
                  Tianxiang Sun and 
                  Xipeng Qiu},
  title        = {Agent Alignment in Evolving Social Norms},
  journal      = {CoRR},
  volume       = {abs/2401.04620},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.04620}
}

@inproceedings{NAACL2022-Findings_Align-GLMs,
  author       = {Ruibo Liu and
                  Ge Zhang and
                  Xinyu Feng and
                  Soroush Vosoughi},
  title        = {Aligning Generative Language Models with Human Values},
  booktitle    = {{NAACL-HLT} (Findings)},
  pages        = {241--252},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.findings-naacl.18},
  doi          = {10.18653/V1/2022.FINDINGS-NAACL.18}
}

@inproceedings{NeurIPS2022_Re-Align,
  author       = {Ruibo Liu and
                  Chenyan Jia and
                  Ge Zhang and
                  Ziyu Zhuang and
                  Tony X. Liu and
                  Soroush Vosoughi},
  title        = {Second Thoughts are Best: Learning to Re-Align With Human Values from Text Edits},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/01c4593d60a020fed5607944330106b1-Abstract-Conference.html}
}

@article{arXiv2023_Align-Chatbot,
  author       = {Chunpu Xu and 
                  Steffi Chern and 
                  Ethan Chern and 
                  Ge Zhang and 
                  Zekun Wang and 
                  Ruibo Liu and 
                  Jing Li and 
                  Jie Fu and 
                  Pengfei Liu},
  title        = {Align on the Fly: Adapting Chatbot Behavior to Established Norms},
  journal      = {CoRR},
  volume       = {abs/2312.15907},
  year         = {2023},
  url          = {https://arxiv.org/abs/2312.15907}
}

@article{arXiv2023_Human-AI_Collaboration,
  author       = {Andrew Fuchs and
                  Andrea Passarella and
                  Marco Conti},
  title        = {Optimizing delegation between human and {AI} collaborative agents},
  journal      = {CoRR},
  volume       = {abs/2309.14718},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.14718},
  doi          = {10.48550/ARXIV.2309.14718}
}

@inproceedings{ICLR2024_Human-Agent-Collaboration,
  author       = {Yiming Gao and
                  Feiyu Liu and
                  Liang Wang and
                  Zhenjie Lian and
                  Dehua Zheng and
                  Weixuan Wang and
                  Wenjin Yang and
                  Siqin Li and
                  Xianliang Wang and
                  Wenhui Chen and
                  Jing Dai and
                  Qiang Fu and
                  Wei Yang and
                  Lanxiao Huang and
                  Wei Liu},
  title        = {Enhancing Human Experience in Human-Agent Collaboration: A Human-Centered Modeling Approach Based on Positive Human Gain},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=BqEvdOS1Hs}
}

@article{arXiv2024_Human-Agent-Collaboration,
  author       = {Xueyang Feng and 
                  Zhi-Yuan Chen and 
                  Yujia Qin and 
                  Yankai Lin and 
                  Xu Chen and 
                  Zhiyuan Liu and 
                  Ji-Rong Wen},
  title        = {Large Language Model-based Human-Agent Collaboration for Complex Task Solving},
  journal      = {CoRR},
  volume       = {abs/2402.12914},
  year         = {2024},
  url          = {https://arxiv.org/abs/2402.12914}
}

@article{TEVC2023_MultiAgent-Collaboration-SocialRoles,
  author       = {Yaqing Hou and 
                  Mingyang Sun and 
                  Yifeng Zeng and 
                  Yew-Soon Ong and 
                  Yaochu Jin and 
                  Hongwei Ge and 
                  Qiang Zhang},
  journal      = {IEEE Transactions on Evolutionary Computation}, 
  title        = {A Multi-agent Cooperative Learning System with Evolution of Social Roles}, 
  volume       = {},
  number       = {},
  pages        = {1-1},
  year         = {2023},
  url          = {https://ieeexplore.ieee.org/document/10104101},
  doi          = {10.1109/TEVC.2023.3268076}
}

@inproceedings{EMNLP2023-Findings_LEGO,
  author       = {Zhitao He and
                  Pengfei Cao and
                  Yubo Chen and
                  Kang Liu and
                  Ruopeng Li and
                  Mengshu Sun and
                  Jun Zhao},
  title        = {{LEGO:} {A} Multi-agent Collaborative Framework with Role-playing and Iterative Feedback for Causality Explanation Generation},
  booktitle    = {{EMNLP} (Findings)},
  pages        = {9142--9163},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://aclanthology.org/2023.findings-emnlp.613}
}

@article{Nature2023_Role-Play-LLM,
  author       = {Murray Shanahan and
                  Kyle McDonell and
                  Laria Reynolds},
  title        = {Role play with large language models},
  journal      = {Nat.},
  volume       = {623},
  number       = {7987},
  pages        = {493--498},
  year         = {2023},
  url          = {https://doi.org/10.1038/s41586-023-06647-8},
  doi          = {10.1038/S41586-023-06647-8}
}

@article{arXiv2023_PlayGames-LLM,
  author       = {Elif Akata and
                  Lion Schulz and
                  Julian Coda{-}Forno and
                  Seong Joon Oh and
                  Matthias Bethge and
                  Eric Schulz},
  title        = {Playing repeated games with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2305.16867},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.16867},
  doi          = {10.48550/arXiv.2305.16867}
}

@article{arXiv2023_Agent-Simulate-OpinionDynamics,
  author       = {Yun{-}Shiuan Chuang and
                  Agam Goyal and
                  Nikunj Harlalka and
                  Siddharth Suresh and
                  Robert Hawkins and
                  Sijia Yang and
                  Dhavan Shah and
                  Junjie Hu and
                  Timothy T. Rogers},
  title        = {Simulating Opinion Dynamics with Networks of LLM-based Agents},
  journal      = {CoRR},
  volume       = {abs/2311.09618},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2311.09618},
  doi          = {10.48550/ARXIV.2311.09618}
}

@article{arXiv2023_Agent-Simulate-OpinionDynamics_Survey,
  author       = {Yun{-}Shiuan Chuang and
                  Timothy T. Rogers},
  title        = {Computational Agent-based Models in Opinion Dynamics: {A} Survey on Social Simulations and Empirical Studies},
  journal      = {CoRR},
  volume       = {abs/2306.03446},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.03446},
  doi          = {10.48550/ARXIV.2306.03446}
}

@article{arXiv2024_AI-Human-Creative,
  author       = {Haonan Wang and 
                  James Zou and 
                  Michael Mozer and 
                  Anirudh Goyal and 
                  Alex Lamb and 
                  Linjun Zhang and 
                  Weijie J Su and 
                  Zhun Deng and 
                  Michael Qizhe Xie and 
                  Hannah Brown and 
                  Kenji Kawaguchi},
  title        = {Can AI Be as Creative as Humans?},
  journal      = {CoRR},
  volume       = {abs/2401.01623},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.01623}
}

@article{arXiv2023_LLM-Simulator,
  author       = {Chuyi Kong and
                  Yaxin Fan and
                  Xiang Wan and
                  Feng Jiang and
                  Benyou Wang},
  title        = {Large Language Model as a User Simulator},
  journal      = {CoRR},
  volume       = {abs/2308.11534},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.11534},
  doi          = {10.48550/ARXIV.2308.11534}
}

@article{arXiv2023_MetaAgents,
  author       = {Yuan Li and
                  Yixuan Zhang and
                  Lichao Sun},
  title        = {MetaAgents: Simulating Interactions of Human Behaviors for LLM-based Task-oriented Coordination via Collaborative Generative Agents},
  journal      = {CoRR},
  volume       = {abs/2310.06500},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.06500},
  doi          = {10.48550/ARXIV.2310.06500}
}

@misc{meyer2021entspann,
  title={Entspann dich, Deutschland! TK-Stressstudie 2021},
  author={Meyer, B and Zill, A and Dilba, D and Voermans, S},
  year={2021},
  publisher={Hamburg: Techniker Krankenkasse}
}

@article{wang2024tokeneconomy,
  title={Reasoning in Token Economies: Budget-Aware Evaluation of LLM Reasoning Strategies},
  author={Wang, Junlin and Jain, Siddhartha and Zhang, Dejiao and Ray, Baishakhi and Kumar, Varun and Athiwaratkun, Ben},
  journal={arXiv preprint arXiv:2406.06461},
  year={2024}
}

@article{PNAS2024_TuringTest_Chatbots-Humans,
  author       = {Qiaozhu Mei and
                  Yutong Xie and
                  Walter Yuan and
                  Matthew O. Jackson},
  title        = {A Turing test of whether AI chatbots are behaviorally similar to humans},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {121},
  number       = {9},
  pages        = {e2313925121},
  year         = {2024},
  url          = {https://doi.org/10.1073/pnas.2313925121},
  doi          = {10.1073/pnas.2313925121}
}
arXiv2023_TuringTest_Chatbots-Humans

@article{arXiv2024_BehavioralSimulation,
  author       = {Cheng Wang and 
                  Chuwen Wang and 
                  Yu Zhao and 
                  Shirong Zeng and 
                  Wang Zhang and 
                  Ronghui Ning},
  title        = {Behavioral Simulation: Exploring A Possible Next Paradigm for Science},
  journal      = {CoRR},
  volume       = {abs/2401.09851},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.09851}
}

@article{arXiv2023_Agent-BehaviorExplanation,
  author       = {Xijia Zhang and
                  Yue Guo and
                  Simon Stepputtis and
                  Katia P. Sycara and
                  Joseph Campbell},
  title        = {Understanding Your Agent: Leveraging Large Language Models for Behavior Explanation},
  journal      = {CoRR},
  volume       = {abs/2311.18062},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2311.18062},
  doi          = {10.48550/ARXIV.2311.18062}
}

@article{arXiv2023_Agent-BehaviorExplaining,
  author       = {Xijia Zhang and
                  Yue Guo and
                  Simon Stepputtis and
                  Katia P. Sycara and
                  Joseph Campbell},
  title        = {Explaining Agent Behavior with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2309.10346},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.10346},
  doi          = {10.48550/ARXIV.2309.10346}
}

@article{arXiv2023_Agents-High-Level-Behavior,
  author       = {Maxwell Crouse and
                  Ibrahim Abdelaziz and
                  Kinjal Basu and
                  Soham Dan and
                  Sadhana Kumaravel and
                  Achille Fokoue and
                  Pavan Kapanipathi and
                  Luis A. Lastras},
  title        = {Formally Specifying the High-Level Behavior of LLM-Based Agents},
  journal      = {CoRR},
  volume       = {abs/2310.08535},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.08535},
  doi          = {10.48550/ARXIV.2310.08535}
}

@article{arXiv2024_Agents-Simulate-Trust,
  author       = {Chengxing Xie and
                  Canyu Chen and
                  Feiran Jia and
                  Ziyu Ye and
                  Kai Shu and
                  Adel Bibi and
                  Ziniu Hu and
                  Philip H. S. Torr and
                  Bernard Ghanem and
                  Guohao Li},
  title        = {Can Large Language Model Agents Simulate Human Trust Behaviors?},
  journal      = {CoRR},
  volume       = {abs/2402.04559},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2402.04559},
  doi          = {10.48550/ARXIV.2402.04559}
}

@article{arXiv2024_Reward-Socially-RL-Agent,
  author       = {Zhaoyue Wang},
  title        = {Towards Socially and Morally Aware RL agent: Reward Design With LLM},
  journal      = {CoRR},
  volume       = {abs/2401.12459},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.12459}
}

@inproceedings{ICLR2024_LLM-Simulate-CognitiveModel,
  author       = {Marcel Binz and
                  Eric Schulz},
  title        = {Turning large language models into cognitive models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=eiC4BKypf1}
}
arXiv2023_LLM-Simulate-CognitiveModel

@article{arXiv2023_Agent-Cognitive,
  author       = {Theodore R. Sumers and
                  Shunyu Yao and
                  Karthik Narasimhan and
                  Thomas L. Griffiths},
  title        = {Cognitive Architectures for Language Agents},
  journal      = {CoRR},
  volume       = {abs/2309.02427},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.02427},
  doi          = {10.48550/ARXIV.2309.02427}
}
TMLR

@article{J2024_Interactions-Cognitive-LLMs,
  author       = {Youzhi Qu and 
                  Penghui Du and 
                  Wenxin Che and 
                  Chen Wei and 
                  Chi Zhang and 
                  Wanli Ouyang and 
                  Yatao Bian and 
                  Feiyang Xu and 
                  Bin Hu and 
                  Kai Du and 
                  Haiyan Wu and 
                  Jia Liu and 
                  Quanying Liu},
  title        = {Promoting interactions between cognitive science and large language models},
  journal      = {The Innovation},
  pages        = {100579},
  issn         = {2666-6758},
  year         = {2024},
  url          = {https://www.sciencedirect.com/science/article/pii/S2666675824000171},
  doi          = {https://doi.org/10.1016/j.xinn.2024.100579}
}

@article{arXiv2024_Multi-Agent_Conversation_CognitiveBias,
  author       = {Yu He Ke and 
                  Rui Yang and 
                  Sui An Lie and 
                  Taylor Xin Yi Lim and 
                  Hairil Rizal Abdullah and 
                  Daniel Shu Wei Ting and 
                  Nan Liu},
  title        = {Enhancing Diagnostic Accuracy through Multi-Agent Conversations: Using Large Language Models to Mitigate Cognitive Bias},
  journal      = {CoRR},
  volume       = {abs/2401.14589},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.14589}
}

@article{arXiv2023_AI-Agent,
  author       = {Sungwoo Lee and
                  Younghyun Oh and
                  Hyunhoe An and
                  Hyebhin Yoon and
                  Karl J. Friston and
                  Seok Jun Hong and
                  Choong{-}Wan Woo},
  title        = {Life-inspired Interoceptive Artificial Intelligence for Autonomous and Adaptive Agents},
  journal      = {CoRR},
  volume       = {abs/2309.05999},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.05999},
  doi          = {10.48550/ARXIV.2309.05999}
}

@article{arXiv2024_Agent-Preference,
  author       = {Zihong He and 
                  Changwang Zhang},
  title        = {AFSPP: Agent Framework for Shaping Preference and Personality with Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.02870},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.02870}
}

@article{PANS2022_Agent-Cooperation-Competition,
  author       = {Euel Elliott and 
                  L. Douglas Kiel},
  title        = {Exploring cooperation and competition using agent-based modeling},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {99},
  number       = {suppl\_3},
  pages        = {7193-7194},
  year         = {2002},
  url          = {https://www.pnas.org/doi/abs/10.1073/pnas.102079099},
  doi          = {10.1073/pnas.102079099}
}

@article{arXiv2023_LyfeAgents,
  author       = {Zhao Kaiya and
                  Michelangelo Naim and
                  Jovana Kondic and
                  Manuel Cortes and
                  Jiaxin Ge and
                  Shuying Luo and
                  Guangyu Robert Yang and
                  Andrew Ahn},
  title        = {Lyfe Agents: Generative agents for low-cost real-time social interactions},
  journal      = {CoRR},
  volume       = {abs/2310.02172},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.02172},
  doi          = {10.48550/ARXIV.2310.02172}
}

@inproceedings{ICLR2023_Reasoning-Simulation,
  author       = {Ruibo Liu and
                  Jason Wei and
                  Shixiang Shane Gu and
                  Te{-}Yen Wu and
                  Soroush Vosoughi and
                  Claire Cui and
                  Denny Zhou and
                  Andrew M. Dai},
  title        = {Mind's Eye: Grounded Language Model Reasoning through Simulation},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=4rXMRuoJlai}
}

@article{arXiv2024_Human-AI-Interaction_Gesture,
  author       = {Philipp Wicke},
  title        = {Probing Language Models' Gesture Understanding for Enhanced Human-AI Interaction},
  journal      = {CoRR},
  volume       = {abs/2401.17858},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.17858}
}

@article{arXiv2023_Human-like-Agents,
  author       = {Thuy{-}Ngoc Nguyen and
                  Chase McDonald and
                  Cleotilde Gonzalez},
  title        = {Credit Assignment: Challenges and Opportunities in Developing Human-like {AI} Agents},
  journal      = {CoRR},
  volume       = {abs/2307.08171},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.08171},
  doi          = {10.48550/ARXIV.2307.08171}
}

@article{arXiv2024_Human-Centered-LM,
  author       = {Nikita Soni and 
                  Niranjan Balasubramanian and 
                  H. Andrew Schwartz and 
                  Dirk Hovy},
  title        = {Comparing Human-Centered Language Modeling: Is it Better to Model Groups, Individual Traits, or Both?},
  journal      = {CoRR},
  volume       = {abs/2401.12492},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.12492}
}

-----Theory-----
@book{Book1973_Theory_NLP,
  author       = {Alfred V. Aho and
                  Jeffrey D. Ullman},
  title        = {The theory of parsing, translation, and compiling. 2: Compiling},
  publisher    = {Prentice-Hall},
  year         = {1973},
  url          = {https://www.worldcat.org/oclc/310805948},
  isbn         = {0139145648}
}

@incollection{2018_Theory,
  author       = {Mezirow, Jack},
  title        = {Transformative learning theory},
  booktitle    = {Contemporary theories of learning},
  pages        = {114--128},
  year         = {2018},
  publisher    = {Routledge},
  url          = {https://www.wichita.edu/services/mrc/OIR/Pedagogy/Theories/transformative.php}
}

---Byzantine Consensus Theory---
@inproceedings{USENIX1999_Theory-FaultTolerance,
  author       = {Miguel Castro and
                  Barbara Liskov},
  title        = {Practical Byzantine Fault Tolerance},
  booktitle    = {{OSDI}},
  pages        = {173--186},
  publisher    = {{USENIX} Association},
  year         = {1999},
  url          = {https://dl.acm.org/citation.cfm?id=296824}
}

---Collaborative Learning---
@incollection{Book2013_InfoProcess-Collaboration,
  author       = {Noreen M Webb},
  title        = {Information processing approaches to collaborative learning},
  booktitle    = {The international handbook of collaborative learning},
  publisher    = {Routledge},
  pages        = {19--40},
  year         = {2013},
  url          = {https://psycnet.apa.org/record/2013-13644-001}
}

---Personality----
@book{Book1999_Personality,
  author       = {Friedman, Howard S and 
                  Schustack, Miriam W},
  title        = {Personality: Classic theories and modern research},
  publisher    = {Allyn and Bacon Boston, MA},
  year         = {1999},
  url          = {https://books.google.com/books/about/Personality.html?id=ziTvDAAAQBAJ}
}

@article{J2008_Overconfidence,
  author       = {Moore, Don A and Healy, Paul J},
  title        = {The trouble with overconfidence.},
  journal      = {Psychological review},
  volume       = {115},
  number       = {2},
  pages        = {502},
  publisher    = {American Psychological Association},
  year         = {2008},
  url          = {https://healy.econ.ohio-state.edu/papers/Moore_Healy-TroubleWithOverconfidence_WP.pdf}
}

@book{Book1985_MedievalPoliticalTheology,
  author       = {Ernst H. Kantorowicz},
  title        = {The King's Two Bodies: A Study in Medieval Political Theology},
  publisher    = {Princeton University Press},
  ISBN         = {9780691169231},
  urldate      = {2023-06-21},
  year         = {1985},
  url          = {http://www.jstor.org/stable/j.ctvcszz1c}
}


-----Social Psychology View-----
@article{J2009_SocialPsychology,
  author       = {Johnson, David W and Johnson, Roger T},
  title        = {An educational psychology success story: Social interdependence theory and cooperative learning},
  journal      = {Educational researcher},
  volume       = {38},
  number       = {5},
  pages        = {365--379},
  publisher    = {Sage Publications},
  year         = {2009},
  url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=72585feb1200d53a81d4fb3e64862d69317b72c3}
}

@article{1982_SocialPsychology,
  author       = {Tajfel, Henri},
  title        = {Social psychology of intergroup relations},
  journal      = {Annual review of psychology},
  volume       = {33},
  number       = {1},
  publisher    = {Annual Reviews 4139 El Camino Way, PO Box 10139, Palo Alto, CA 94303-0139, USA},
  pages        = {1--39},
  year         = {1982},
  url          = {https://www.annualreviews.org/doi/abs/10.1146/annurev.ps.33.020182.000245?journalCode=psych}
}

@incollection{2004_SocialPsychology,
  author       = {Tajfel, Henri and 
                 Turner, John C},
  title        = {The social identity theory of intergroup behavior},
  booktitle    = {Political psychology},
  pages        = {276--293},
  year         = {2004},
  publisher    = {Psychology Press},
  url          = {https://psycnet.apa.org/record/2004-13697-016}
}

---Society of Mind---
@book{Book1988_SoM,
  author       = {Minsky, Marvin},
  title        = {Society of mind},
  year         = {1988},
  publisher    = {Simon and Schuster},
  url          = {https://www.simonandschuster.com/books/Society-Of-Mind/Marvin-Minsky/9780671657130}
}

@article{J2003_SoM,
  author       = {Push Singh},
  title        = {Examining the Society of Mind},
  journal      = {Comput. Artif. Intell.},
  volume       = {22},
  number       = {6},
  pages        = {521--543},
  year         = {2003},
  url          = {http://www.cai.sk/ojs/index.php/cai/article/view/467}
}

@article{hu2024evomac,
  title={Self-evolving multi-agent collaboration networks for software development},
  author={Hu, Yue and Cai, Yuzhu and Du, Yaxin and Zhu, Xinyu and Liu, Xiangrui and Yu, Zijie and Hou, Yuchen and Tang, Shuo and Chen, Siheng},
  journal={arXiv preprint arXiv:2410.16946},
  year={2024}
}

@inproceedings{NeurIPS2023_Agent-SoM,
  author       = {Guohao Li and
                  Hasan Hammoud and
                  Hani Itani and
                  Dmitrii Khizbullin and
                  Bernard Ghanem},
  title        = {{CAMEL:} Communicative Agents for "Mind" Exploration of Large Language Model Society},
  booktitle    = {NeurIPS},
  year         = {2023}
}
arXiv2023_Agent-SoM

@article{arXiv2023_SoM-NL,
  author       = {Mingchen Zhuge and
                  Haozhe Liu and
                  Francesco Faccio and
                  Dylan R. Ashley and
                  R{\'{o}}bert Csord{\'{a}}s and
                  Anand Gopalakrishnan and
                  Abdullah Hamdi and
                  Hasan Abed Al Kader Hammoud and
                  Vincent Herrmann and
                  Kazuki Irie and
                  Louis Kirsch and
                  Bing Li and
                  Guohao Li and
                  Shuming Liu and
                  Jinjie Mai and
                  Piotr Piekos and
                  Aditya Ramesh and
                  Imanol Schlag and
                  Weimin Shi and
                  Aleksandar Stanic and
                  Wenyi Wang and
                  Yuhui Wang and
                  Mengmeng Xu and
                  Deng{-}Ping Fan and
                  Bernard Ghanem and
                  J{\"{u}}rgen Schmidhuber},
  title        = {Mindstorms in Natural Language-Based Societies of Mind},
  journal      = {CoRR},
  volume       = {abs/2305.17066},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.17066},
  doi          = {10.48550/arXiv.2305.17066}
}
DBLP:journals/corr/abs-2305-17066


---Theory Of Mind---
@article{J2002_TheoryOfMind,
  author       = {Siegal, Michael and 
                  Varley, Rosemary},
  title        = {Neural systems involved in 'theory of mind'},
  journal      = {Nature Reviews Neuroscience},
  volume       = {3},
  number       = {6},
  pages        = {463--471},
  publisher    = {Nature Publishing Group UK London},
  year         = {2002},
  url          = {https://www.nature.com/articles/nrn844},
  doi          = {10.1038/nrn844}
}

@article{J2004_TheoryOfMind,
  author       = {Leslie, Alan M and 
                  Friedman, Ori and 
                  German, Tim P},
  title        = {Core mechanisms in ‘theory of mind’},
  journal      = {Trends in cognitive sciences},
  volume       = {8},
  number       = {12},
  pages        = {528--533},
  issn         = {1364-6613},
  publisher    = {Elsevier},
  year         = {2004},
  url          = {https://www.sciencedirect.com/science/article/pii/S1364661304002608},
  doi          = {https://doi.org/10.1016/j.tics.2004.10.001}
}

@inproceedings{EMNLP2022_TheoryOfMind,
  author       = {Maarten Sap and
                  Ronan Le Bras and
                  Daniel Fried and
                  Yejin Choi},
  title        = {Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs},
  booktitle    = {{EMNLP}},
  pages        = {3762--3780},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.emnlp-main.248},
  doi          = {10.18653/V1/2022.EMNLP-MAIN.248}
}

@inproceedings{EMNLP2023_TheoryOfMind-Agents,
  author       = {Huao Li and
                  Yu Quan Chong and
                  Simon Stepputtis and
                  Joseph Campbell and
                  Dana T. Hughes and
                  Charles Lewis and
                  Katia P. Sycara},
  title        = {Theory of Mind for Multi-Agent Collaboration via Large Language Models},
  booktitle    = {{EMNLP}},
  pages        = {180--192},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://aclanthology.org/2023.emnlp-main.13}
}

@inproceedings{EACL2024_TheoryOfMind,
  author       = {Natalie Shapira and
                  Mosh Levy and
                  Seyed Hossein Alavi and
                  Xuhui Zhou and
                  Yejin Choi and
                  Yoav Goldberg and
                  Maarten Sap and
                  Vered Shwartz},
  title        = {Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models},
  booktitle    = {{EACL} {(1)}},
  pages        = {2257--2273},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://aclanthology.org/2024.eacl-long.138}
}
arXiv2023_TheoryOfMind

@article{arXiv2023_TheoryOfMind-Agents,
  author       = {Pei Zhou and
                  Aman Madaan and
                  Srividya Pranavi Potharaju and
                  Aditya Gupta and
                  Kevin R. McKee and
                  Ari Holtzman and
                  Jay Pujara and
                  Xiang Ren and
                  Swaroop Mishra and
                  Aida Nematzadeh and
                  Shyam Upadhyay and
                  Manaal Faruqui},
  title        = {How FaR Are Large Language Models From Agents with Theory-of-Mind?},
  journal      = {CoRR},
  volume       = {abs/2310.03051},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.03051},
  doi          = {10.48550/ARXIV.2310.03051}
}

@article{arXiv2023_TheoryofMind-Game,
  author       = {Jiaxian Guo and
                  Bo Yang and
                  Paul Yoo and
                  Bill Yuchen Lin and
                  Yusuke Iwasawa and
                  Yutaka Matsuo},
  title        = {Suspicion-Agent: Playing Imperfect Information Games with Theory of Mind Aware {GPT-4}},
  journal      = {CoRR},
  volume       = {abs/2309.17277},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.17277},
  doi          = {10.48550/ARXIV.2309.17277}
}

---Group---
@article{Science2010_HumanDynamics,
  author       = {Anita Williams Woolley and 
                  Christopher F. Chabris and 
                  Alex Pentland and 
                  Nada Hashmi and 
                  Thomas W. Malone},
  title        = {Evidence for a Collective Intelligence Factor in the Performance of Human Groups},
  journal      = {Science},
  volume       = {330},
  number       = {6004},
  pages        = {686-688},
  year         = {2010},
  doi          = {10.1126/science.1193147},
  url          = {https://www.science.org/doi/abs/10.1126/science.1193147}
}

@misc{1968_GroupDynamics,
  author       = {Dorwin Cartwright and 
                  Alvin Zander},
  title        = {Group dynamics},
  publisher    = {Harper+ Row},
  year         = {1968},
  url          = {https://psycnet.apa.org/record/1968-12031-000}
}

@article{J2018_GroupDynamics,
  author       = {Wilfred R Bion},
  title        = {Group dynamics: A re-view},
  journal      = {New directions in psychoanalysis},
  pages        = {440--477},
  publisher    = {Routledge},
  year         = {2018},
  url          = {https://www.taylorfrancis.com/chapters/edit/10.4324/9780429477546-19/group-dynamics-re-view-bion}
}

@book{Book2014_GroupDynamics,
  author       = {Donelson R Forsyth},
  title        = {Group dynamics},
  publisher    = {Wadsworth Cengage Learning},
  year         = {2014},
  url          = {https://scholarship.richmond.edu/bookshelf/5/}
}

@book{Book2018_GroupDynamics,
  author       = {Donelson R Forsyth},
  title        = {Group dynamics},
  publisher    = {Cengage Learning},
  year         = {2018},
  url          = {https://books.google.com.sg/books?id=vg9EDwAAQBAJ&newbks=0&source=newbks_fb&redir_esc=y}
}

@article{J1987_GroupDynamics,
  author       = {Clayton P Alderfer},
  title        = {An intergroup perspective on group dynamics},
  journal      = {Handbook of organizational behavior},
  volume       = {190},
  pages        = {222},
  year         = {1987},
  url          = {https://apps.dtic.mil/sti/citations/ADA135582}
}

@inproceedings{yin2023exchange,
  title={Exchange-of-thought: Enhancing large language model capabilities through cross-model communication},
  author={Yin, Zhangyue and Sun, Qiushi and Chang, Cheng and Guo, Qipeng and Dai, Junqi and Huang, Xuan-Jing and Qiu, Xipeng},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={15135--15153},
  year={2023}
}

@inproceedings{chen2024benchmarking,
  title={Benchmarking large language models in retrieval-augmented generation},
  author={Chen, Jiawei and Lin, Hongyu and Han, Xianpei and Sun, Le},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={38},
  number={16},
  pages={17754--17762},
  year={2024}
}

@article{zhuang2023toolchain,
  title={Toolchain*: Efficient action space navigation in large language models with a* search},
  author={Zhuang, Yuchen and Chen, Xiang and Yu, Tong and Mitra, Saayan and Bursztyn, Victor and Rossi, Ryan A and Sarkhel, Somdeb and Zhang, Chao},
  journal={arXiv preprint arXiv:2310.13227},
  year={2023}
}

@article{shen2024smallllms,
  title={Small llms are weak tool learners: A multi-llm agent},
  author={Shen, Weizhou and Li, Chenliang and Chen, Hongzhan and Yan, Ming and Quan, Xiaojun and Chen, Hehong and Zhang, Ji and Huang, Fei},
  journal={arXiv preprint arXiv:2401.07324},
  year={2024}
}

@article{J1998_SmallGroupDynamics-Discussions,
  author       = {David Wyatt Seal and 
                  Laura M Bogart and 
                  Anke A Ehrhardt},
  title        = {Small group dynamics: The utility of focus group discussions as a research method},
  journal      = {Group Dynamics: Theory, Research, and Practice},
  volume       = {2},
  number       = {4},
  pages        = {253},
  publisher    = {Educational Publishing Foundation},
  year         = {1998},
  url          = {https://doi.org/10.1037/1089-2699.2.4.253}
}

@book{Book1972_Groupthink,
  author       = {Janis, Irving L},
  title        = {Victims of Groupthink: A psychological study of foreign-policy decisions and fiascoes.},
  publisher    = {Houghton Mifflin},
  year         = {1972},
  url          = {https://psycnet.apa.org/record/1975-29417-000}
}

@article{J2015_Group,
  author       = {Iyengar, Shanto and Westwood, Sean J},
  title        = {Fear and loathing across party lines: New evidence on group polarization},
  journal      = {American journal of political science},
  volume       = {59},
  number       = {3},
  pages        = {690--707},
  publisher    = {Wiley Online Library},
  year         = {2015},
  url          = {https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=f8248c39c3daff874fb0f6f5abc667ebcdfee024}
}

@article{J2003_Intergroup-Intragroup_Culture,
  author       = {Masaki Yuki},
  title        = {Intergroup Comparison versus Intragroup Relationships: A Cross-Cultural Examination of Social Identity Theory in North American and East Asian Cultural Contexts},
  journal      = {Social Psychology Quarterly},
  issn         = {01902725},
  number       = {2},
  pages        = {166--183},
  volume       = {66},
  publisher    = {[Sage Publications, Inc., American Sociological Association]},
  urldate      = {2024-01-16},
  year         = {2003},
  url          = {http://www.jstor.org/stable/1519846}
}

@article{J1995_IntragroupConflict,
  author       = {Karen A Jehn},
  title        = {A multimethod examination of the benefits and detriments of intragroup conflict},
  journal      = {Administrative science quarterly},
  publisher    = {JSTOR},
  pages        = {256--282},
  year         = {1995},
  url          = {https://www.jstor.org/stable/2393638},
  doi          = {10.2307/2393638}
}

@article{J2003_SmartGroups,
  author       = {Brigid Barron},
  title        = {When Smart Groups Fail},
  journal      = {Journal of the Learning Sciences},
  volume       = {12},
  number       = {3},
  pages        = {307--359},
  publisher    = {Routledge},
  year         = {2003},
  url          = {https://doi.org/10.1207/S15327809JLS1203_1},
  doi          = {10.1207/S15327809JLS1203\_1}
}

---Intelligence---
@book{Book2005_CrowdWisdom,
  author       = {Surowiecki, James},
  title        = {The Wisdom of Crowds},
  isbn         = {0385721706},
  publisher    = {Anchor},
  year         = {2005},
  url          = {https://books.google.com.sg/books/about/The_Wisdom_of_Crowds.html?id=hHUsHOHqVzEC&redir_esc=y}
}

@article{J1996_Intelligence,
  author       = {Neisser, Ulric and 
                  Boodoo, Gwyneth and 
                  Bouchard Jr, Thomas J and 
                  Boykin, A Wade and 
                  Brody, Nathan and 
                  Ceci, Stephen J and 
                  Halpern, Diane F and 
                  Loehlin, John C and 
                  Perloff, Robert and 
                  Sternberg, Robert J and 
                  others},
  title        = {Intelligence: knowns and unknowns.},
  journal      = {American psychologist},
  volume       = {51},
  number       = {2},
  pages        = {77},
  publisher    = {American Psychological Association},
  year         = {1996},
  url          = {https://psycnet.apa.org/record/1996-02655-001}
}

@article{1961_Intelligence,
  author       = {Spearman, Charles},
  title        = {"General Intelligence" Objectively Determined and Measured.},
  publisher    = {Appleton-Century-Crofts},
  year         = {1961},
  url          = {https://psycnet.apa.org/record/1926-00296-001}
}

---Conformity---
@article{J2004_Conformity,
  author       = {Robert B. Cialdini
                  and Noah J. Goldstein},
  title        = {Social Influence: Compliance and Conformity},
  journal      = {Annual Review of Psychology},
  volume       = {55},
  number       = {1},
  pages        = {591-621},
  note         = {PMID: 14744228},
  year         = {2004},
  url          = {https://doi.org/10.1146/annurev.psych.55.090902.142015},
  doi          = {10.1146/annurev.psych.55.090902.142015}
}

@article{J1969_Conformity,
  author       = {Vernon L. Allen and John M. Levine},
  title        = {Consensus and conformity},
  journal      = {Journal of Experimental Social Psychology},
  volume       = {5},
  number       = {4},
  pages        = {389-399},
  issn         = {0022-1031},
  year         = {1969},
  url          = {https://www.sciencedirect.com/science/article/pii/0022103169900328},
  doi          = {https://doi.org/10.1016/0022-1031(69)90032-8}
}

@book{Book2011_Negotiation,
  author       = {Fisher, Roger and 
                  Ury, William L and 
                  Patton, Bruce},
  title        = {Getting to yes: Negotiating agreement without giving in},
  publisher    = {Penguin},
  year         = {2011},
  url          = {https://www.pon.harvard.edu/shop/getting-to-yes-negotiating-agreement-without-giving-in/}
}

@article{J2015_Conformity,
  author       = {Julie C Coultas
                  and Edwin JC van Leeuwen},
  title        = {Conformity: Definitions, types, and evolutionary grounding},
  journal      = {Evolutionary perspectives on social psychology},
  publisher    = {Springer},
  pages        = {189--202},
  year         = {2015},
  url          = {https://link.springer.com/chapter/10.1007/978-3-319-12697-5\_15}
}

---Consensus---
@article{J1967_Consensus-Sociological,
  author       = {Scheff, Thomas J},
  title        = {Toward a sociological model of consensus},
  journal      = {American Sociological Review},
  pages        = {32--46},
  publisher    = {JSTOR},
  year         = {1967},
  url          = {https://doi.org/10.2307/2091716},
  doi          = {10.2307/2091716}
}

@article{J1974_ConsensusReaching,
  author       = {Morris H. Degroot},
  title        = {Reaching a Consensus},
  journal      = {Journal of the American Statistical Association},
  volume       = {69},
  number       = {345},
  pages        = {118-121},
  publisher    = {Taylor & Francis},
  year         = {1974},
  url          = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1974.10480137},
  doi          = {10.1080/01621459.1974.10480137}
}

@article{J2018_Emergence-Consensus,
  author       = {Baronchelli, Andrea},
  title        = {The emergence of consensus: a primer},
  journal      = {Royal Society open science},
  volume       = {5},
  number       = {2},
  pages        = {172189},
  publisher    = {The Royal Society Publishing},
  year         = {2018},
  url          = {http://doi.org/10.1098/rsos.172189},
  doi          = {10.1098/rsos.172189}
}

---Social---
@article{arXiv2023_Agent-SocialChoiceTheory,
  author       = {Marc Lanctot and
                  Kate Larson and
                  Yoram Bachrach and
                  Luke Marris and
                  Zun Li and
                  Avishkar Bhoopchand and
                  Thomas W. Anthony and
                  Brian Tanner and
                  Anna Koop},
  title        = {Evaluating Agents using Social Choice Theory},
  journal      = {CoRR},
  volume       = {abs/2312.03121},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2312.03121},
  doi          = {10.48550/ARXIV.2312.03121}
}

@article{J2000_Agent-SocialScience,
  author       = {Nigel Gilbert and 
                  Pietro Terna},
  title        = {How to build and use agent-based models in social science},
  journal      = {Mind \& Society},
  volume       = {1},
  pages        = {57--72},
  publisher    = {Springer},
  year         = {2000},
  url          = {https://link.springer.com/article/10.1007/BF02512229}
}

@book{Book2012_Agent-SocialScience,
  author       = {Joshua M Epstein},
  title        = {Generative social science: Studies in agent-based computational modeling},
  publisher    = {Princeton University Press},
  year         = {2012},
  url          = {https://press.princeton.edu/books/ebook/9781400842872/generative-social-science}
}

@book{Book2023_Agent-SocialDynamics-Culture,
  author       = {Paul Smaldino},
  title        = {Modeling social behavior: Mathematical and agent-based models of social dynamics and cultural evolution},
  publisher    = {Princeton University Press},
  year         = {2023},
  url          = {https://press.princeton.edu/books/paperback/9780691224145/modeling-social-behavior}
}

@article{J2017_SocialInfluence_OpinionDynamics,
  author       = {Andreas Flache and
                  Michael M{\"{a}}s and
                  Thomas Feliciani and
                  Edmund Chattoe{-}Brown and
                  Guillaume Deffuant and
                  Sylvie Huet and
                  Jan Lorenz},
  title        = {Models of Social Influence: Towards the Next Frontiers},
  journal      = {J. Artif. Soc. Soc. Simul.},
  volume       = {20},
  number       = {4},
  year         = {2017},
  url          = {https://doi.org/10.18564/jasss.3521},
  doi          = {10.18564/JASSS.3521}
}

@article{J2021_SocietalDynamics_OpinionDynamics,
  author       = {Jan Lorenz and 
                  Martin Neumann 
                  and Tobias Schr{\"o}der},
  title        = {Individual attitude change and societal dynamics: Computational experiments with psychological theories.},
  journal      = {Psychological Review},
  volume       = {128},
  number       = {4},
  pages        = {623},
  publisher    = {American Psychological Association},
  year         = {2021},
  url          = {https://doi.org/10.1037/rev0000291}
}

---Psychology---
@article{PNAS2023_CognitivePsychology_LLM,
  author       = {Marcel Binz and 
                  Eric Schulz},
  title        = {Using cognitive psychology to understand GPT-3},
  journal      = {Proceedings of the National Academy of Sciences},
  volume       = {120},
  number       = {6},
  pages        = {e2218523120},
  year         = {2023},
  url          = {https://www.pnas.org/doi/abs/10.1073/pnas.2218523120},
  doi          = {10.1073/pnas.2218523120}
}

@article{arXiv2023_MachinePsychology,
  author       = {Thilo Hagendorff},
  title        = {Machine Psychology: Investigating Emergent Capabilities and Behavior in Large Language Models Using Psychological Methods},
  journal      = {CoRR},
  volume       = {abs/2303.13988},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2303.13988},
  doi          = {10.48550/ARXIV.2303.13988}
}

@article{J2023_LLM-Psychology,
  author       = {Dorottya Demszky and 
                  Diyi Yang and 
                  David S. Yeager and 
                  Christopher J. Bryan and 
                  Margarett Clapper and 
                  Susannah Chandhok and  
                  Johannes C. Eichstaedt and  
                  Cameron Hecht and  
                  Jeremy Jamieson and  
                  Meghann Johnson and  
                  Michaela Jones and 
                  Danielle Krettek-Cobb and 
                  Leslie Lai and 
                  Nirel JonesMitchell and  
                  Desmond C. Ong and  
                  Carol S. Dweck and  
                  James J. Gross and 
                  James W. Pennebaker},
    title      = {Using large language models in psychology},
    journal    = {Nature Reviews Psychology},
    year       = {2023},
    month      = {Nov},
    day        = {01},
    volume     = {2},
    number     = {11},
    pages      = {688-701},
    issn       = {2731-0574},
    url        = {https://doi.org/10.1038/s44159-023-00241-5},
    doi        = {10.1038/s44159-023-00241-5}
}

@inproceedings{NAACL2024-Findings_PsychometricLLM,
  author       = {Tatsuki Kuribayashi and
                  Yohei Oseki and
                  Timothy Baldwin},
  title        = {Psychometric Predictive Power of Large Language Models},
  booktitle    = {{NAACL} (Findings)},
  pages        = {},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://doi.org/10.48550/arXiv.2311.07484}
}
arXiv2023_PsychometricLLM

@article{arXiv2024_Multi-Agent_PsySafe,
  author       = {Zaibin Zhang and 
                  Yongting Zhang and 
                  Lijun Li and 
                  Hongzhi Gao and 
                  Lijun Wang and 
                  Huchuan Lu and 
                  Feng Zhao and 
                  Yu Qiao and 
                  Jing Shao},
  title        = {PsySafe: A Comprehensive Framework for Psychological-based Attack, Defense, and Evaluation of Multi-agent System Safety},
  journal      = {CoRR},
  volume       = {abs/2401.11880},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.11880}
}

---Democracy---
@book{Book2006_DemocracyModel,
  author       = {David Held},
  title        = {Models of democracy},
  publisher    = {Polity},
  year         = {2006},
  url          = {https://www.sup.org/books/title/?id=10597}
}

@book{Book2006_Deliberative-Democracy,
  author       = {Diana C Mutz},
  title        = {Hearing the other side: Deliberative versus participatory democracy},
  publisher    = {Cambridge University Press},
  year         = {2006},
  url          = {https://www.cambridge.org/core/books/hearing-the-other-side/7CB061238546313D287668FF8EFE2EF7}
}

---other related---
@article{arXiv2023_SocialPsychology-Vehicles,
  author       = {Xiao Li and
                  Kaiwen Liu and
                  H. Eric Tseng and
                  Anouck Girard and
                  Ilya V. Kolmanovsky},
  title        = {Interaction-Aware Decision-Making for Autonomous Vehicles in Forced Merging Scenario Leveraging Social Psychology Factors},
  journal      = {CoRR},
  volume       = {abs/2309.14497},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.14497},
  doi          = {10.48550/ARXIV.2309.14497}
}

@book{Book2019_CriticalThinking,
  author       = {Paul, Richard and Elder, Linda},
  title        = {The miniature guide to critical thinking concepts and tools},
  publisher    = {Rowman \& Littlefield}, 
  year         = {2019},
  url          = {https://www.criticalthinking.org/files/Concepts_Tools.pdf}
}

@book{Book1994_Framework,
  author       = {Popper, Karl Raimund},
  title        = {The myth of the framework: In defence of science and rationality},
  publisher    = {Psychology Press},
  year         = {1994},
  url          = {http://www.math.chalmers.se/~ulfp/Review/framework.pdf}
}

@article{J2012_Circulations,
  author       = {Munro, Iain},
  title        = {The management of circulations: Biopolitical variations after Foucault},
  journal      = {International Journal of Management Reviews},
  volume       = {14},
  number       = {3},
  pages        = {345--362},
  publisher    = {Wiley Online Library},
  year         = {2012}, 
  url          = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1468-2370.2011.00320.x}
}


-----Datasets-----

@inproceedings{NeurIPS2021_Dataset-MATH,
  author       = {Dan Hendrycks and
                  Collin Burns and
                  Saurav Kadavath and
                  Akul Arora and
                  Steven Basart and
                  Eric Tang and
                  Dawn Song and
                  Jacob Steinhardt},
  title        = {Measuring Mathematical Problem Solving With the {MATH} Dataset},
  booktitle    = {NeurIPS Datasets and Benchmarks},
  year         = {2021},
  url          = {https://datasets-benchmarks-proceedings.neurips.cc/paper/2021/hash/be83ab3ecd0db773eb2dc1b0a17836a1-Abstract-round2.html}
}

@article{arXiv2022_Dataset-ChessMoveValidity,
  author       = {Aarohi Srivastava and
                  Abhinav Rastogi and
                  Abhishek Rao and
                  Abu Awal Md Shoeb and
                  Abubakar Abid and
                  Adam Fisch and
                  Adam R. Brown and
                  Adam Santoro and
                  Aditya Gupta and
                  Adri{\`{a}} Garriga{-}Alonso and
                  Agnieszka Kluska and
                  Aitor Lewkowycz and
                  Akshat Agarwal and
                  Alethea Power and
                  Alex Ray and
                  Alex Warstadt and
                  Alexander W. Kocurek and
                  Ali Safaya and
                  Ali Tazarv and
                  Alice Xiang and
                  Alicia Parrish and
                  Allen Nie and
                  Aman Hussain and
                  Amanda Askell and
                  Amanda Dsouza and
                  Ameet Rahane and
                  Anantharaman S. Iyer and
                  Anders Andreassen and
                  Andrea Santilli and
                  Andreas Stuhlm{\"{u}}ller and
                  Andrew M. Dai and
                  Andrew La and
                  Andrew K. Lampinen and
                  Andy Zou and
                  Angela Jiang and
                  Angelica Chen and
                  Anh Vuong and
                  Animesh Gupta and
                  Anna Gottardi and
                  Antonio Norelli and
                  Anu Venkatesh and
                  Arash Gholamidavoodi and
                  Arfa Tabassum and
                  Arul Menezes and
                  Arun Kirubarajan and
                  Asher Mullokandov and
                  Ashish Sabharwal and
                  Austin Herrick and
                  Avia Efrat and
                  Aykut Erdem and
                  Ayla Karakas and
                  et al.},
  title        = {Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models},
  journal      = {arXiv preprint},
  volume       = {abs/2206.04615},
  year         = {2022},
  url          = {https://doi.org/10.48550/arXiv.2206.04615},
  doi          = {10.48550/arXiv.2206.04615}
}

@article{arXiv2023_Dataset-BOLAA,
  author       = {Zhiwei Liu and
                  Weiran Yao and
                  Jianguo Zhang and
                  Le Xue and
                  Shelby Heinecke and
                  Rithesh Murthy and
                  Yihao Feng and
                  Zeyuan Chen and
                  Juan Carlos Niebles and
                  Devansh Arpit and
                  Ran Xu and
                  Phil Mui and
                  Huan Wang and
                  Caiming Xiong and
                  Silvio Savarese},
  title        = {{BOLAA:} Benchmarking and Orchestrating LLM-augmented Autonomous Agents},
  journal      = {CoRR},
  volume       = {abs/2308.05960},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2308.05960},
  doi          = {10.48550/arXiv.2308.05960}
}


-----Experiments-----
@misc{PGN,
  author       = {fsmosca},
  title        = {pgn-standard},
  publisher    = {GitHub},
  journal      = {GitHub repository},
  url          = {https://github.com/fsmosca/PGN-Standard}
}

@misc{ChatGPT-OpenAI,
  title        = {ChatGPT: Optimizing Language Models for Dialogue},
  note         = {\url{https://openai.com/blog/chatgpt/}},
  author       = {OpenAI},
  year         = {2022}
}

@inproceedings{NeurIPS2022_InstructGPT,
  author       = {Long Ouyang and
                  Jeffrey Wu and
                  Xu Jiang and
                  Diogo Almeida and
                  Carroll L. Wainwright and
                  Pamela Mishkin and
                  Chong Zhang and
                  Sandhini Agarwal and
                  Katarina Slama and
                  Alex Ray and
                  John Schulman and
                  Jacob Hilton and
                  Fraser Kelton and
                  Luke Miller and
                  Maddie Simens and
                  Amanda Askell and
                  Peter Welinder and
                  Paul F. Christiano and
                  Jan Leike and
                  Ryan Lowe},
  title        = {Training language models to follow instructions with human feedback},
  booktitle    = {NeurIPS},
  year         = {2022},
  url          = {http://papers.nips.cc/paper\_files/paper/2022/hash/b1efde53be364a73914f58805a001731-Abstract-Conference.html}
}

@article{arXiv2023_LLaMA,
  author       = {Hugo Touvron and
                  Thibaut Lavril and
                  Gautier Izacard and
                  Xavier Martinet and
                  Marie{-}Anne Lachaux and
                  Timoth{\'{e}}e Lacroix and
                  Baptiste Rozi{\`{e}}re and
                  Naman Goyal and
                  Eric Hambro and
                  Faisal Azhar and
                  Aur{\'{e}}lien Rodriguez and
                  Armand Joulin and
                  Edouard Grave and
                  Guillaume Lample},
  title        = {LLaMA: Open and Efficient Foundation Language Models},
  journal      = {CoRR},
  volume       = {abs/2302.13971},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2302.13971},
  doi          = {10.48550/ARXIV.2302.13971}
}

@article{arXiv2023_Qwen,
  author       = {Jinze Bai and
                  Shuai Bai and
                  Yunfei Chu and
                  Zeyu Cui and
                  Kai Dang and
                  Xiaodong Deng and
                  Yang Fan and
                  Wenbin Ge and
                  Yu Han and
                  Fei Huang and
                  Binyuan Hui and
                  Luo Ji and
                  Mei Li and
                  Junyang Lin and
                  Runji Lin and
                  Dayiheng Liu and
                  Gao Liu and
                  Chengqiang Lu and
                  Keming Lu and
                  Jianxin Ma and
                  Rui Men and
                  Xingzhang Ren and
                  Xuancheng Ren and
                  Chuanqi Tan and
                  Sinan Tan and
                  Jianhong Tu and
                  Peng Wang and
                  Shijie Wang and
                  Wei Wang and
                  Shengguang Wu and
                  Benfeng Xu and
                  Jin Xu and
                  An Yang and
                  Hao Yang and
                  Jian Yang and
                  Shusheng Yang and
                  Yang Yao and
                  Bowen Yu and
                  Hongyi Yuan and
                  Zheng Yuan and
                  Jianwei Zhang and
                  Xingxuan Zhang and
                  Yichang Zhang and
                  Zhenru Zhang and
                  Chang Zhou and
                  Jingren Zhou and
                  Xiaohuan Zhou and
                  Tianhang Zhu},
  title        = {Qwen Technical Report},
  journal      = {CoRR},
  volume       = {abs/2309.16609},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.16609},
  doi          = {10.48550/ARXIV.2309.16609}
}

@article{arXiv2023_Mistral,
  author       = {Albert Q. Jiang and
                  Alexandre Sablayrolles and
                  Arthur Mensch and
                  Chris Bamford and
                  Devendra Singh Chaplot and
                  Diego de Las Casas and
                  Florian Bressand and
                  Gianna Lengyel and
                  Guillaume Lample and
                  Lucile Saulnier and
                  L{\'{e}}lio Renard Lavaud and
                  Marie{-}Anne Lachaux and
                  Pierre Stock and
                  Teven Le Scao and
                  Thibaut Lavril and
                  Thomas Wang and
                  Timoth{\'{e}}e Lacroix and
                  William El Sayed},
  title        = {Mistral 7B},
  journal      = {CoRR},
  volume       = {abs/2310.06825},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.06825},
  doi          = {10.48550/ARXIV.2310.06825}
}

@article{arXiv2024_Mixtral,
  author       = {Albert Q. Jiang and 
                  Alexandre Sablayrolles and 
                  Antoine Roux and 
                  Arthur Mensch and 
                  Blanche Savary and 
                  Chris Bamford and 
                  Devendra Singh Chaplot and 
                  Diego de las Casas and 
                  Emma Bou Hanna and 
                  Florian Bressand and 
                  Gianna Lengyel and 
                  Guillaume Bour and 
                  Guillaume Lample and 
                  Lélio Renard Lavaud and 
                  Lucile Saulnier and 
                  Marie-Anne Lachaux and 
                  Pierre Stock and 
                  Sandeep Subramanian and 
                  Sophia Yang and 
                  Szymon Antoniak and 
                  Teven Le Scao and 
                  Théophile Gervet and 
                  Thibaut Lavril and 
                  Thomas Wang and 
                  Timothée Lacroix and 
                  William El Sayed},
  title        = {Mixtral of Experts},
  journal      = {CoRR},
  volume       = {abs/2401.04088},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.04088}
}

@article{J2023_Prompt-Survey,
  author    = {Pengfei Liu and
               Weizhe Yuan and
               Jinlan Fu and
               Zhengbao Jiang and
               Hiroaki Hayashi and
               Graham Neubig},
  title     = {Pre-train, Prompt, and Predict: {A} Systematic Survey of Prompting Methods in Natural Language Processing},
  volume    = {55},
  number    = {9},
  journal   = {ACM Comput. Surv.},
  numpages  = {35},
  publisher = {Association for Computing Machinery},
  issn      = {0360-0300},
  year      = {2023},
  url       = {https://doi.org/10.1145/3560815},
  doi       = {10.1145/3560815}
}

@inproceedings{WWW2022_KnowPrompt,
  author       = {Xiang Chen and
                  Ningyu Zhang and
                  Xin Xie and
                  Shumin Deng and
                  Yunzhi Yao and
                  Chuanqi Tan and
                  Fei Huang and
                  Luo Si and
                  Huajun Chen},
  title        = {KnowPrompt: Knowledge-aware Prompt-tuning with Synergistic Optimization for Relation Extraction},
  booktitle    = {{WWW}},
  pages        = {2778--2788},
  publisher    = {{ACM}},
  year         = {2022},
  url          = {https://doi.org/10.1145/3485447.3511998},
  doi          = {10.1145/3485447.3511998}
}

@inproceedings{ACL2022-Short_P-Tuning,
  author       = {Xiao Liu and
                  Kaixuan Ji and
                  Yicheng Fu and
                  Weng Tam and
                  Zhengxiao Du and
                  Zhilin Yang and
                  Jie Tang},
  title        = {P-Tuning: Prompt Tuning Can Be Comparable to Fine-tuning Across Scales and Tasks},
  booktitle    = {{ACL} {(2)}},
  pages        = {61--68},
  publisher    = {Association for Computational Linguistics},
  year         = {2022},
  url          = {https://doi.org/10.18653/v1/2022.acl-short.8},
  doi          = {10.18653/v1/2022.acl-short.8}
}

@article{arXiv2024_MoreAgents,
  author       = {Junyou Li and 
                  Qin Zhang and 
                  Yangbin Yu and 
                  Qiang Fu and 
                  Deheng Ye},
  title        = {More Agents Is All You Need},
  journal      = {CoRR},
  volume       = {abs/2402.05120},
  year         = {2024}
}

@article{reimers2019sentence,
  title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks},
  author={Reimers, N},
  journal={arXiv preprint arXiv:1908.10084},
  year={2019}
}

@article{wang2020minilm,
  title={Minilm: Deep self-attention distillation for task-agnostic compression of pre-trained transformers},
  author={Wang, Wenhui and Wei, Furu and Dong, Li and Bao, Hangbo and Yang, Nan and Zhou, Ming},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5776--5788},
  year={2020}
}

@inproceedings{shirzad2023exphormer,
  title={Exphormer: Sparse transformers for graphs},
  author={Shirzad, Hamed and Velingker, Ameya and Venkatachalam, Balaji and Sutherland, Danica J and Sinop, Ali Kemal},
  booktitle={International Conference on Machine Learning},
  pages={31613--31632},
  year={2023},
  organization={PMLR}
}

@article{zhang2025evoflow,
  title={EvoFlow: Evolving Diverse Agentic Workflows On The Fly},
  author={Zhang, Guibin and Chen, Kaijie and Wan, Guancheng and Chang, Heng and Cheng, Hong and Wang, Kun and Hu, Shuyue and Bai, Lei},
  journal={arXiv preprint arXiv:2502.07373},
  year={2025}
}


@inproceedings{tan2023virtual,
  title={Virtual node tuning for few-shot node classification},
  author={Tan, Zhen and Guo, Ruocheng and Ding, Kaize and Liu, Huan},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={2177--2188},
  year={2023}
}

@inproceedings{zhao2024causality,
  title={Causality-Inspired Spatial-Temporal Explanations for Dynamic Graph Neural Networks},
  author={Zhao, Kesen and Zhang, Liang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024}
}

@article{chen2024internet,
  title={Internet of agents: Weaving a web of heterogeneous agents for collaborative intelligence},
  author={Chen, Weize and You, Ziming and Li, Ran and Guan, Yitong and Qian, Chen and Zhao, Chenyang and Yang, Cheng and Xie, Ruobing and Liu, Zhiyuan and Sun, Maosong},
  journal={arXiv preprint arXiv:2407.07061},
  year={2024}
}

@article{rosenbluth2024distinguished,
  title={Distinguished In Uniform: Self Attention Vs. Virtual Nodes},
  author={Rosenbluth, Eran and T{\"o}nshoff, Jan and Ritzert, Martin and Kisin, Berke and Grohe, Martin},
  journal={arXiv preprint arXiv:2405.11951},
  year={2024}
}

@inproceedings{ICLR2023_Self-Consistency,
  author       = {Xuezhi Wang and
                  Jason Wei and
                  Dale Schuurmans and
                  Quoc V. Le and
                  Ed H. Chi and
                  Sharan Narang and
                  Aakanksha Chowdhery and
                  Denny Zhou},
  title        = {Self-Consistency Improves Chain of Thought Reasoning in Language Models},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2023},
  url          = {https://openreview.net/pdf?id=1PL1NIMMrw}
}

@inproceedings{ACL2023-Findings_Eval-LLM-Behavior,
  author       = {Ethan Perez and
                  Sam Ringer and
                  Kamile Lukosiute and
                  Karina Nguyen and
                  Edwin Chen and
                  Scott Heiner and
                  Craig Pettit and
                  Catherine Olsson and
                  Sandipan Kundu and
                  Saurav Kadavath and
                  Andy Jones and
                  Anna Chen and
                  Benjamin Mann and
                  Brian Israel and
                  Bryan Seethor and
                  Cameron McKinnon and
                  Christopher Olah and
                  Da Yan and
                  Daniela Amodei and
                  Dario Amodei and
                  Dawn Drain and
                  Dustin Li and
                  Eli Tran{-}Johnson and
                  Guro Khundadze and
                  Jackson Kernion and
                  James Landis and
                  Jamie Kerr and
                  Jared Mueller and
                  Jeeyoon Hyun and
                  Joshua Landau and
                  Kamal Ndousse and
                  Landon Goldberg and
                  Liane Lovitt and
                  Martin Lucas and
                  Michael Sellitto and
                  Miranda Zhang and
                  Neerav Kingsland and
                  Nelson Elhage and
                  Nicholas Joseph and
                  Noem{\'{\i}} Mercado and
                  Nova DasSarma and
                  Oliver Rausch and
                  Robin Larson and
                  Sam McCandlish and
                  Scott Johnston and
                  Shauna Kravec and
                  Sheer El Showk and
                  Tamera Lanham and
                  Timothy Telleen{-}Lawton and
                  Tom Brown and
                  Tom Henighan and
                  Tristan Hume and
                  Yuntao Bai and
                  Zac Hatfield{-}Dodds and
                  Jack Clark and
                  Samuel R. Bowman and
                  Amanda Askell and
                  Roger Grosse and
                  Danny Hernandez and
                  Deep Ganguli and
                  Evan Hubinger and
                  Nicholas Schiefer and
                  Jared Kaplan},
  title        = {Discovering Language Model Behaviors with Model-Written Evaluations},
  booktitle    = {{ACL} (Findings)},
  pages        = {13387--13434},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://doi.org/10.18653/v1/2023.findings-acl.847},
  doi          = {10.18653/V1/2023.FINDINGS-ACL.847}
}

@article{arXiv2023_Analyze-LLM-Behavior,
  author       = {Lingjiao Chen and
                  Matei Zaharia and
                  James Zou},
  title        = {How is ChatGPT's behavior changing over time?},
  journal      = {CoRR},
  volume       = {abs/2307.09009},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.09009},
  doi          = {10.48550/ARXIV.2307.09009}
}

@article{arXiv2024_AntEval,
  author       = {Yuanzhi Liang and 
                  Linchao Zhu and 
                  Yi Yang},
  title        = {AntEval: Quantitatively Evaluating Informativeness and Expressiveness of Agent Social Interactions},
  journal      = {CoRR},
  volume       = {abs/2401.06509},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.06509}
}

@inproceedings{ICLR2024_LLM-Bias-MCS,
  author       = {Chujie Zheng and
                  Hao Zhou and
                  Fandong Meng and
                  Jie Zhou and
                  Minlie Huang},
  title        = {Large Language Models Are Not Robust Multiple Choice Selectors},
  booktitle    = {{ICLR}},
  publisher    = {OpenReview.net},
  year         = {2024},
  url          = {https://openreview.net/forum?id=shr9PXz7T0}
}

-----Majority Vote-----
@article{Science2022_AlphaCode,
  author       = {Yujia Li and
                  David H. Choi and
                  Junyoung Chung and
                  Nate Kushman and
                  Julian Schrittwieser and
                  R{\'{e}}mi Leblond and
                  Tom Eccles and
                  James Keeling and
                  Felix Gimeno and
                  Agustin Dal Lago and
                  Thomas Hubert and
                  Peter Choy and
                  Cyprien de Masson d'Autume and
                  Igor Babuschkin and
                  Xinyun Chen and
                  Po{-}Sen Huang and
                  Johannes Welbl and
                  Sven Gowal and
                  Alexey Cherepanov and
                  James Molloy and
                  Daniel J. Mankowitz and
                  Esme Sutherland Robson and
                  Pushmeet Kohli and
                  Nando de Freitas and
                  Koray Kavukcuoglu and
                  Oriol Vinyals},
  title        = {Competition-level code generation with AlphaCode},
  journal      = {Science},
  volume       = {378},
  number       = {6624},
  pages        = {1092-1097},
  year         = {2022},
  url          = {https://www.science.org/doi/abs/10.1126/science.abq1158},
  doi          = {10.1126/science.abq1158}
}
arXiv2022_AlphaCode

@inproceedings{liu2023deja,
  title={Deja vu: Contextual sparsity for efficient llms at inference time},
  author={Liu, Zichang and Wang, Jue and Dao, Tri and Zhou, Tianyi and Yuan, Binhang and Song, Zhao and Shrivastava, Anshumali and Zhang, Ce and Tian, Yuandong and Re, Christopher and others},
  booktitle={International Conference on Machine Learning},
  pages={22137--22176},
  year={2023},
  organization={PMLR}
}

@article{arXiv2021_Verifier-Math,
  author       = {Karl Cobbe and
                  Vineet Kosaraju and
                  Mohammad Bavarian and
                  Mark Chen and
                  Heewoo Jun and
                  Lukasz Kaiser and
                  Matthias Plappert and
                  Jerry Tworek and
                  Jacob Hilton and
                  Reiichiro Nakano and
                  Christopher Hesse and
                  John Schulman},
  title        = {Training Verifiers to Solve Math Word Problems},
  journal      = {arXiv prepring},
  volume       = {abs/2110.14168},
  year         = {2021}
}

@article{roy2016solving,
  title={Solving general arithmetic word problems},
  author={Roy, Subhro and Roth, Dan},
  journal={arXiv preprint arXiv:1608.01413},
  year={2016}
}

@inproceedings{fu2022complexity,
  title={Complexity-based prompting for multi-step reasoning},
  author={Fu, Yao and Peng, Hao and Sabharwal, Ashish and Clark, Peter and Khot, Tushar},
  booktitle={The Eleventh International Conference on Learning Representations},
  year={2022}
}

@article{patel2021nlp,
  title={Are NLP models really able to solve simple math word problems?},
  author={Patel, Arkil and Bhattamishra, Satwik and Goyal, Navin},
  journal={arXiv preprint arXiv:2103.07191},
  year={2021}
}

@article{arXiv2023_ReConcile,
  author      = {Justin Chih-Yao Chen and 
                 Swarnadeep Saha and 
                 Mohit Bansal},
  title       = {ReConcile: Round-Table Conference Improves Reasoning via Consensus among Diverse LLMs}, 
  journal     = {arxiv preprint},
  volume      = {2309.07864}, 
  eprint      = {2309.13007},
  year        = {2023},
  url         = {https://arxiv.org/abs/2309.13007}
}

@article{arXiv2023_Multi-Agent-Consensus,
  author       = {Huaben Chen and
                  Wenkang Ji and
                  Lufeng Xu and
                  Shiyu Zhao},
  title        = {Multi-Agent Consensus Seeking via Large Language Models},
  journal      = {CoRR},
  volume       = {abs/2310.20151},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.20151},
  doi          = {10.48550/ARXIV.2310.20151}
}




-----Applications-----
@article{arXiv2023_LLMs-Simulate_SocialMedia,
  author       = {Petter T{\"{o}}rnberg and
                  Diliara Valeeva and
                  Justus Uitermark and
                  Christopher Bail},
  title        = {Simulating Social Media Using Large Language Models to Evaluate Alternative News Feed Algorithms},
  journal      = {CoRR},
  volume       = {abs/2310.05984},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.05984},
  doi          = {10.48550/ARXIV.2310.05984}
}



----Others----
@book{APA:83,
    author  = {{American Psychological Association}},
    title   = {Publications Manual},
    publisher = {American Psychological Association},
    address = {Washington, DC},
    year    = {1983}
}

@article{J1981_Alternation,
  author       = {Ashok K. Chandra and
                  Dexter Kozen and
                  Larry J. Stockmeyer},
  title        = {Alternation},
  journal      = {J. {ACM}},
  volume       = {28},
  number       = {1},
  pages        = {114--133},
  year         = {1981},
  url          = {https://doi.org/10.1145/322234.322243},
  doi          = {10.1145/322234.322243}
}

@inproceedings{ICML2007_L1Regular,
  author       = {Galen Andrew and
                  Jianfeng Gao},
  title        = {Scalable training of L\({}^{\mbox{1}}\)-regularized log-linear models},
  booktitle    = {{ICML}},
  series       = {{ACM} International Conference Proceeding Series},
  volume       = {227},
  pages        = {33--40},
  publisher    = {{ACM}},
  year         = {2007},
  url          = {https://doi.org/10.1145/1273496.1273501},
  doi          = {10.1145/1273496.1273501}
}

@book{Book1997_Algorithms-DataStruct,
  author       = {Dan Gusfield},
  title        = {Algorithms on Strings, Trees, and Sequences - Computer Science and Computational Biology},
  publisher    = {Cambridge University Press},
  year         = {1997},
  url          = {https://doi.org/10.1017/cbo9780511574931},
  doi          = {10.1017/CBO9780511574931},
  isbn         = {0-521-58519-8}
}

@article{arXiv2015_YaraParser,
  author       = {Mohammad Sadegh Rasooli and
                  Joel R. Tetreault},
  title        = {Yara Parser: {A} Fast and Accurate Dependency Parser},
  journal      = {CoRR},
  volume       = {abs/1503.06733},
  year         = {2015},
  url          = {http://arxiv.org/abs/1503.06733}
}

@article{JMLR2005_LearningStruct,
  author       = {Rie Kubota Ando and
                  Tong Zhang},
  title        = {A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data},
  journal      = {J. Mach. Learn. Res.},
  volume       = {6},
  pages        = {1817--1853},
  year         = {2005},
  url          = {http://jmlr.org/papers/v6/ando05a.html}
}

@article{J1965_FourierSeries-Comp,
  author       = {Cooley, James W. and 
                  Tukey, John W.},
  title        = {An algorithm for the machine calculation of complex {F}ourier series},
  journal      = {Mathematics of Computation},
  volume       = {19},
  number       = {90},
  pages        = {297--301},
  year         = {1965},
  url          = {https://www.ams.org/journals/mcom/1965-19-090/S0025-5718-1965-0178586-1/S0025-5718-1965-0178586-1.pdf}
}

@article{arXiv2023_Agent-DUMA,
  author       = {Xiaoyu Tian and
                  Liangyu Chen and
                  Na Liu and
                  Yaxuan Liu and
                  Wei Zou and
                  Kaijiang Chen and
                  Ming Cui},
  title        = {{DUMA:} a Dual-Mind Conversational Agent with Fast and Slow Thinking},
  journal      = {CoRR},
  volume       = {abs/2310.18075},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.18075},
  doi          = {10.48550/ARXIV.2310.18075}
}

@article{arXiv2023_AgentTuning,
  author       = {Aohan Zeng and
                  Mingdao Liu and
                  Rui Lu and
                  Bowen Wang and
                  Xiao Liu and
                  Yuxiao Dong and
                  Jie Tang},
  title        = {AgentTuning: Enabling Generalized Agent Abilities for LLMs},
  journal      = {CoRR},
  volume       = {abs/2310.12823},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.12823},
  doi          = {10.48550/ARXIV.2310.12823}
}

@article{arXiv2023_FireAct,
  author       = {Baian Chen and
                  Chang Shu and
                  Ehsan Shareghi and
                  Nigel Collier and
                  Karthik Narasimhan and
                  Shunyu Yao},
  title        = {FireAct: Toward Language Agent Fine-tuning},
  journal      = {CoRR},
  volume       = {abs/2310.05915},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.05915},
  doi          = {10.48550/ARXIV.2310.05915}
}

@article{agashe2023evaluating,
  title={Evaluating multi-agent coordination abilities in large language models},
  author={Agashe, Saaket and Fan, Yue and Wang, Xin Eric},
  journal={arXiv preprint arXiv:2310.03903},
  year={2023}
}



@inproceedings{NAACL2024_Agent-Self-Collaboration,
  author       = {Zhenhailong Wang and 
                  Shaoguang Mao and 
                  Wenshan Wu and 
                  Tao Ge and 
                  Furu Wei and 
                  Heng Ji},
  title        = {Unleashing the Emergent Cognitive Synergy in Large Language Models: A Task-Solving Agent through Multi-Persona Self-Collaboration},
  booktitle    = {{NAACL}},
  publisher    = {Association for Computational Linguistics},
  year         = {2024}
}
arXiv2024_Agent-Self-Collaboration

@article{arXiv2023_Benchmarking-Agents,
  author       = {Qian Huang and
                  Jian Vora and
                  Percy Liang and
                  Jure Leskovec},
  title        = {Benchmarking Large Language Models As {AI} Research Agents},
  journal      = {CoRR},
  volume       = {abs/2310.03302},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2310.03302},
  doi          = {10.48550/ARXIV.2310.03302}
}

@article{arXiv2023_Agents-SampleEfficiency,
  author       = {Zhihan Liu and
                  Hao Hu and
                  Shenao Zhang and
                  Hongyi Guo and
                  Shuqi Ke and
                  Boyi Liu and
                  Zhaoran Wang},
  title        = {Reason for Future, Act for Now: {A} Principled Framework for Autonomous {LLM} Agents with Provable Sample Efficiency},
  journal      = {CoRR},
  volume       = {abs/2309.17382},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2309.17382},
  doi          = {10.48550/ARXIV.2309.17382}
}

@article{arXiv2023_UnifiedAgent-FM,
  author       = {Norman Di Palo and
                  Arunkumar Byravan and
                  Leonard Hasenclever and
                  Markus Wulfmeier and
                  Nicolas Heess and
                  Martin A. Riedmiller},
  title        = {Towards {A} Unified Agent with Foundation Models},
  journal      = {CoRR},
  volume       = {abs/2307.09668},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2307.09668},
  doi          = {10.48550/ARXIV.2307.09668}
}

@article{arXiv2023_Universal-Agent,
  author       = {Anees Aslam},
  title        = {Universal Language Modelling agent},
  journal      = {CoRR},
  volume       = {abs/2306.06521},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2306.06521},
  doi          = {10.48550/ARXIV.2306.06521}
}

@article{arXiv2023_Hinder-Agents,
  author       = {Sukai Huang and
                  Nir Lipovetzky and
                  Trevor Cohn},
  title        = {A Reminder of its Brittleness: Language Reward Shaping May Hinder Learning for Instruction Following Agents},
  journal      = {CoRR},
  volume       = {abs/2305.16621},
  year         = {2023},
  url          = {https://doi.org/10.48550/arXiv.2305.16621},
  doi          = {10.48550/ARXIV.2305.16621}
}

@inproceedings{CoLLAs2023_Autotelic-Agents,
  author       = {C{\'{e}}dric Colas and
                  Laetitia Teodorescu and
                  Pierre{-}Yves Oudeyer and
                  Xingdi Yuan and
                  Marc{-}Alexandre C{\^{o}}t{\'{e}}},
  title        = {Augmenting Autotelic Agents with Large Language Models},
  booktitle    = {CoLLAs},
  series       = {Proceedings of Machine Learning Research},
  volume       = {232},
  pages        = {205--226},
  publisher    = {{PMLR}},
  year         = {2023},
  url          = {https://proceedings.mlr.press/v232/colas23a.html}
}
arXiv2023_Autotelic-Agents

@inproceedings{EMNLP2023_ConceptualStructure_LLM,
  author       = {Siddharth Suresh and
                  Kushin Mukherjee and
                  Xizheng Yu and
                  Wei{-}Chun Huang and
                  Lisa Padua and
                  Timothy T. Rogers},
  title        = {Conceptual structure coheres in human cognition but not in large language models},
  booktitle    = {{EMNLP}},
  pages        = {722--738},
  publisher    = {Association for Computational Linguistics},
  year         = {2023},
  url          = {https://aclanthology.org/2023.emnlp-main.47}
}

@article{Games2021_SocialStrategies-CooperativeBehaviour,
  author       = {Robin Watson and
                  Thomas J. H. Morgan and
                  Rachel L. Kendal and
                  Julie Van de Vyver and
                  Jeremy Kendal},
  title        = {Social Learning Strategies and Cooperative Behaviour: Evidence of Payoff Bias, but Not Prestige or Conformity, in a Social Dilemma Game},
  journal      = {Games},
  volume       = {12},
  number       = {4},
  pages        = {89},
  year         = {2021},
  url          = {https://doi.org/10.3390/g12040089},
  doi          = {10.3390/G12040089}
}

@inproceedings{ACL2024_AUTOACT-Self-Planning,
  author       = {Shuofei Qiao and 
                  Ningyu Zhang and 
                  Runnan Fang and 
                  Yujie Luo and 
                  Wangchunshu Zhou and 
                  Yuchen Eleanor Jiang and 
                  Chengfei Lv and 
                  Huajun Chen},
  title        = {AUTOACT: Automatic Agent Learning from Scratch via Self-Planning},
  booktitle    = {{ACL}},
  pages        = {},
  publisher    = {Association for Computational Linguistics},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.05268}
}
arXiv2024_AUTOACT-Self-Planning

@article{arXiv2024_Self-Rewarding-LMs,
  author       = {Weizhe Yuan and 
                  Richard Yuanzhe Pang and 
                  Kyunghyun Cho and 
                  Sainbayar Sukhbaatar and 
                  Jing Xu and 
                  Jason Weston},
  title        = {Self-Rewarding Language Models},
  journal      = {CoRR},
  volume       = {abs/2401.10020},
  year         = {2024},
  url          = {https://arxiv.org/abs/2401.10020}
}


@article{serrano2003topology,
  title={Topology of the world trade web},
  author={Serrano, Ma Angeles and Bogun{\'a}, Mari{\'a}n},
  journal={Physical Review E},
  volume={68},
  number={1},
  pages={015101},
  year={2003},
  publisher={APS}
}

@article{fagiolo2010evolution,
  title={The evolution of the world trade web: a weighted-network analysis},
  author={Fagiolo, Giorgio and Reyes, Javier and Schiavo, Stefano},
  journal={Journal of Evolutionary Economics},
  volume={20},
  pages={479--514},
  year={2010},
  publisher={Springer}
}

@article{garlaschelli2007interplay,
  title={Interplay between topology and dynamics in the World Trade Web},
  author={Garlaschelli, Diego and Di Matteo, Ticiana and Aste, Tomaso and Caldarelli, Guido and Loffredo, Maria I},
  journal={The European Physical Journal B},
  volume={57},
  pages={159--164},
  year={2007},
  publisher={Springer}
}

@inproceedings{pbft,
author = {Castro, Miguel and Liskov, Barbara},
title = {Practical Byzantine Fault Tolerance},
year = {1999},
isbn = {1880446391},
publisher = {USENIX Association},
address = {USA},
booktitle = {Proceedings of the Third Symposium on Operating Systems Design and Implementation},
pages = {173–186},
numpages = {14},
location = {New Orleans, Louisiana, USA},
series = {OSDI '99}
}


@article{farahani2013review,
  title={A review of urban transportation network design problems},
  author={Farahani, Reza Zanjirani and Miandoabchi, Elnaz and Szeto, Wai Yuen and Rashidi, Hannaneh},
  journal={European journal of operational research},
  volume={229},
  number={2},
  pages={281--302},
  year={2013},
  publisher={Elsevier}
}


@article{bell1997transportation,
  title={Transportation network analysis},
  author={Bell, Michael GH and Iida, Yasunori and others},
  year={1997},
  publisher={Wiley Online Library}
}

@inproceedings{fan2019graph,
  title={Graph neural networks for social recommendation},
  author={Fan, Wenqi and Ma, Yao and Li, Qing and He, Yuan and Zhao, Eric and Tang, Jiliang and Yin, Dawei},
  booktitle={The world wide web conference},
  pages={417--426},
  year={2019}
}

@article{belkin2006manifold,
  title={Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.},
  author={Belkin, Mikhail and Niyogi, Partha and Sindhwani, Vikas},
  journal={Journal of machine learning research},
  volume={7},
  number={11},
  year={2006}
}

@inproceedings{zhou2005learning,
  title={Learning from labeled and unlabeled data on a directed graph},
  author={Zhou, Dengyong and Huang, Jiayuan and Sch{\"o}lkopf, Bernhard},
  booktitle={Proceedings of the 22nd international conference on Machine learning},
  pages={1036--1043},
  year={2005}
}

@inproceedings{wang2019kgat,
  title={Kgat: Knowledge graph attention network for recommendation},
  author={Wang, Xiang and He, Xiangnan and Cao, Yixin and Liu, Meng and Chua, Tat-Seng},
  booktitle={Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={950--958},
  year={2019}
}

@article{nabti2017querying,
  title={Querying massive graph data: A compress and search approach},
  author={Nabti, Chemseddine and Seba, Hamida},
  journal={Future Generation Computer Systems},
  volume={74},
  pages={63--75},
  year={2017},
  publisher={Elsevier}
}

@article{ribeiro2021survey,
  title={A survey on subgraph counting: concepts, algorithms, and applications to network motifs and graphlets},
  author={Ribeiro, Pedro and Paredes, Pedro and Silva, Miguel EP and Aparicio, David and Silva, Fernando},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={2},
  pages={1--36},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{bouhenni2021survey,
  title={A survey on distributed graph pattern matching in massive graphs},
  author={Bouhenni, Sarra and Yahiaoui, Said and Nouali-Taboudjemat, Nadia and Kheddouci, Hamamache},
  journal={ACM Computing Surveys (CSUR)},
  volume={54},
  number={2},
  pages={1--35},
  year={2021},
  publisher={ACM New York, NY, USA}
}


@article{fulber2020network,
  title={Network service topology: Formalization, taxonomy and the custom specification model},
  author={Fulber-Garcia, Vinicius and Duarte Jr, Elias P and Huff, Alexandre and dos Santos, Carlos RP},
  journal={Computer Networks},
  volume={178},
  pages={107337},
  year={2020},
  publisher={Elsevier}
}

@inproceedings{arnold2020cloud,
  title={Cloud provider connectivity in the flat internet},
  author={Arnold, Todd and He, Jia and Jiang, Weifan and Calder, Matt and Cunha, Italo and Giotsas, Vasileios and Katz-Bassett, Ethan},
  booktitle={Proceedings of the ACM Internet Measurement Conference},
  pages={230--246},
  year={2020}
}

@article{fu2020topology,
  title={Topology optimization against cascading failures on wireless sensor networks using a memetic algorithm},
  author={Fu, Xiuwen and Pace, Pasquale and Aloi, Gianluca and Yang, Lin and Fortino, Giancarlo},
  journal={Computer Networks},
  volume={177},
  pages={107327},
  year={2020},
  publisher={Elsevier}
}

@article{zhu2024llms,
  title={Llms for knowledge graph construction and reasoning: Recent capabilities and future opportunities},
  author={Zhu, Yuqi and Wang, Xiaohan and Chen, Jing and Qiao, Shuofei and Ou, Yixin and Yao, Yunzhi and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
  journal={World Wide Web},
  volume={27},
  number={5},
  pages={58},
  year={2024},
  publisher={Springer}
}

@article{zhu2022multi,
  title={Multi-modal knowledge graph construction and application: A survey},
  author={Zhu, Xiangru and Li, Zhixu and Wang, Xiaodan and Jiang, Xueyao and Sun, Penglei and Wang, Xuwu and Xiao, Yanghua and Yuan, Nicholas Jing},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={36},
  number={2},
  pages={715--735},
  year={2022},
  publisher={IEEE}
}

@inproceedings{zhu2021network,
  title={Network planning with deep reinforcement learning},
  author={Zhu, Hang and Gupta, Varun and Ahuja, Satyajeet Singh and Tian, Yuandong and Zhang, Ying and Jin, Xin},
  booktitle={Proceedings of the 2021 ACM SIGCOMM 2021 Conference},
  pages={258--271},
  year={2021}
}




@inproceedings{huang2022language,
  title={Language models as zero-shot planners: Extracting actionable knowledge for embodied agents},
  author={Huang, Wenlong and Abbeel, Pieter and Pathak, Deepak and Mordatch, Igor},
  booktitle={International conference on machine learning},
  pages={9118--9147},
  year={2022},
  organization={PMLR}
}


@article{sun2023pearl,
  title={Pearl: Prompting large language models to plan and execute actions over long documents},
  author={Sun, Simeng and Liu, Yang and Wang, Shuohang and Zhu, Chenguang and Iyyer, Mohit},
  journal={arXiv preprint arXiv:2305.14564},
  year={2023}
}

@inproceedings{ruan2023tptu,
  title={Tptu: Task planning and tool usage of large language model-based ai agents},
  author={Ruan, Jingqing and Chen, Yihong and Zhang, Bin and Xu, Zhiwei and Bao, Tianpeng and Mao, Hangyu and Li, Ziyue and Zeng, Xingyu and Zhao, Rui and others},
  booktitle={NeurIPS 2023 Foundation Models for Decision Making Workshop},
  year={2023}
}

@article{sun2023self,
  title={Self-supervised hypergraph representation learning for sociological analysis},
  author={Sun, Xiangguo and Cheng, Hong and Liu, Bo and Li, Jia and Chen, Hongyang and Xu, Guandong and Yin, Hongzhi},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  volume={35},
  number={11},
  pages={11860--11871},
  year={2023},
  publisher={IEEE}
}

@article{li2023survey,
  title={A survey of graph meets large language model: Progress and future directions},
  author={Li, Yuhan and Li, Zhixun and Wang, Peisong and Li, Jia and Sun, Xiangguo and Cheng, Hong and Yu, Jeffrey Xu},
  journal={arXiv preprint arXiv:2311.12399},
  year={2023}
}

@inproceedings{sun2023all,
  title={All in One: Multi-Task Prompting for Graph Neural Networks},
  author={Sun, Xiangguo and Cheng, Hong and Li, Jia and Liu, Bo and Guan, Jihong},
  booktitle={Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={2120--2131},
  year={2023}
}

@article{shu2024llm,
  title={When llm meets hypergraph: A sociological analysis on personality via online social networks},
  author={Shu, Zhiyao and Sun, Xiangguo and Cheng, Hong},
  journal={arXiv preprint arXiv:2407.03568},
  year={2024}
}

@misc{park2023generativeagentsinteractivesimulacra,
      title={Generative Agents: Interactive Simulacra of Human Behavior}, 
      author={Joon Sung Park and Joseph C. O'Brien and Carrie J. Cai and Meredith Ringel Morris and Percy Liang and Michael S. Bernstein},
      year={2023},
      eprint={2304.03442},
      archivePrefix={arXiv},
      primaryClass={cs.HC},
      url={https://arxiv.org/abs/2304.03442}, 
}

@article{Drori_2022,
   title={A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
   volume={119},
   ISSN={1091-6490},
   url={http://dx.doi.org/10.1073/pnas.2123433119},
   DOI={10.1073/pnas.2123433119},
   number={32},
   journal={Proceedings of the National Academy of Sciences},
   publisher={Proceedings of the National Academy of Sciences},
   author={Drori, Iddo and Zhang, Sarah and Shuttleworth, Reece and Tang, Leonard and Lu, Albert and Ke, Elizabeth and Liu, Kevin and Chen, Linda and Tran, Sunny and Cheng, Newman and Wang, Roman and Singh, Nikhil and Patti, Taylor L. and Lynch, Jayson and Shporer, Avi and Verma, Nakul and Wu, Eugene and Strang, Gilbert},
   year={2022},
   month=aug }

@misc{swan2023mathagentscomputationalinfrastructure,
      title={Math Agents: Computational Infrastructure, Mathematical Embedding, and Genomics}, 
      author={Melanie Swan and Takashi Kido and Eric Roland and Renato P. dos Santos},
      year={2023},
      eprint={2307.02502},
      archivePrefix={arXiv},
      primaryClass={q-bio.OT},
      url={https://arxiv.org/abs/2307.02502}, 
}

@misc{guo2024deepseekcoderlargelanguagemodel,
      title={DeepSeek-Coder: When the Large Language Model Meets Programming -- The Rise of Code Intelligence}, 
      author={Daya Guo and Qihao Zhu and Dejian Yang and Zhenda Xie and Kai Dong and Wentao Zhang and Guanting Chen and Xiao Bi and Y. Wu and Y. K. Li and Fuli Luo and Yingfei Xiong and Wenfeng Liang},
      year={2024},
      eprint={2401.14196},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2401.14196}, 
}

@misc{yu2024metamathbootstrapmathematicalquestions,
      title={MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models}, 
      author={Longhui Yu and Weisen Jiang and Han Shi and Jincheng Yu and Zhengying Liu and Yu Zhang and James T. Kwok and Zhenguo Li and Adrian Weller and Weiyang Liu},
      year={2024},
      eprint={2309.12284},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.12284}, 
}

@misc{chen2023frugalgptuselargelanguage,
      title={FrugalGPT: How to Use Large Language Models While Reducing Cost and Improving Performance}, 
      author={Lingjiao Chen and Matei Zaharia and James Zou},
      year={2023},
      eprint={2305.05176},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2305.05176}, 
}

@misc{ding2024hybridllmcostefficientqualityaware,
      title={Hybrid LLM: Cost-Efficient and Quality-Aware Query Routing}, 
      author={Dujian Ding and Ankur Mallick and Chi Wang and Robert Sim and Subhabrata Mukherjee and Victor Ruhle and Laks V. S. Lakshmanan and Ahmed Hassan Awadallah},
      year={2024},
      eprint={2404.14618},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2404.14618}, 
}

@misc{hu2024routerbenchbenchmarkmultillmrouting,
      title={RouterBench: A Benchmark for Multi-LLM Routing System}, 
      author={Qitian Jason Hu and Jacob Bieker and Xiuyu Li and Nan Jiang and Benjamin Keigwin and Gaurav Ranganath and Kurt Keutzer and Shriyash Kaustubh Upadhyay},
      year={2024},
      eprint={2403.12031},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.12031}, 
}

@misc{shnitzer2023largelanguagemodelrouting,
      title={Large Language Model Routing with Benchmark Datasets}, 
      author={Tal Shnitzer and Anthony Ou and Mírian Silva and Kate Soule and Yuekai Sun and Justin Solomon and Neil Thompson and Mikhail Yurochkin},
      year={2023},
      eprint={2309.15789},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2309.15789}, 
}

@article{xu2025a-mem,
  title={A-mem: Agentic memory for llm agents},
  author={Xu, Wujiang and Mei, Kai and Gao, Hang and Tan, Juntao and Liang, Zujie and Zhang, Yongfeng},
  journal={arXiv preprint arXiv:2502.12110},
  year={2025}
}

@inproceedings{_akota_2024, 
   series={WSDM ’24},
   title={Fly-Swat or Cannon? Cost-Effective Language Model Choice via Meta-Modeling},
   url={http://dx.doi.org/10.1145/3616855.3635825},
   DOI={10.1145/3616855.3635825},
   booktitle={Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
   publisher={ACM},
   author={akota, Marija and Peyrard, Maxime and West, Robert},
   year={2024},
   month=mar, pages={606–615},
   collection={WSDM ’24} }

@article{chhikara2025mem0,
  title={Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory},
  author={Chhikara, Prateek and Khant, Dev and Aryan, Saket and Singh, Taranjeet and Yadav, Deshraj},
  journal={arXiv preprint arXiv:2504.19413},
  year={2025}
}

@article{salama2025meminsight,
  title={MemInsight: Autonomous Memory Augmentation for LLM Agents},
  author={Salama, Rana and Cai, Jason and Yuan, Michelle and Currey, Anna and Sunkara, Monica and Zhang, Yi and Benajiba, Yassine},
  journal={arXiv preprint arXiv:2503.21760},
  year={2025}
}

@article{tang2025chemagent,
  title={ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning},
  author={Tang, Xiangru and Hu, Tianyu and Ye, Muyang and Shao, Yanjun and Yin, Xunjian and Ouyang, Siru and Zhou, Wangchunshu and Lu, Pan and Zhang, Zhuosheng and Zhao, Yilun and others},
  journal={arXiv preprint arXiv:2501.06590},
  year={2025}
}

@misc{zhang_automatic_2022,
	title = {Automatic {Chain} of {Thought} {Prompting} in {Large} {Language} {Models}},
	url = {http://arxiv.org/abs/2210.03493},
	doi = {10.48550/arXiv.2210.03493},
	language = {en-US},
	urldate = {2024-10-23},
	publisher = {arXiv},
	author = {Zhang, Zhuosheng and Zhang, Aston and Li, Mu and Smola, Alex},
	month = oct,
	year = {2022},
	note = {arXiv:2210.03493
TLDR: An automatic CoT prompting method that samples questions with diversity and generates reasoning chains to construct demonstrations and consistently matches or exceeds the performance of the CoT paradigm that requires manual designs of demonstrations.},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, ccfInfo: CCF-None ICLR, citationNumber: 585},
	file = {Preprint PDF:/Users/lby/Zotero/storage/N9QJYHZH/Zhang 等 - 2022 - Automatic Chain of Thought Prompting in Large Language Models.pdf:application/pdf;Snapshot:/Users/lby/Zotero/storage/CR5ZTJ4D/2210.html:text/html},
}

@misc{zhang_aflow_2024,
	title = {{AFlow}: {Automating} {Agentic} {Workflow} {Generation}},
	shorttitle = {{AFlow}},
	url = {http://arxiv.org/abs/2410.10762},
	language = {en-US},
	urldate = {2024-10-26},
	publisher = {arXiv},
	author = {Zhang, Jiayi and Xiang, Jinyu and Yu, Zhaoyang and Teng, Fengwei and Chen, Xionghui and Chen, Jiaqi and Zhuge, Mingchen and Cheng, Xin and Hong, Sirui and Wang, Jinlin and Zheng, Bingnan and Liu, Bang and Luo, Yuyu and Wu, Chenglin},
	month = oct,
	year = {2024},
	note = {arXiv:2410.10762},
	keywords = {Computer Science - Computation and Language, Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Software Engineering},
	file = {Full Text PDF:/Users/lby/Zotero/storage/5BXEZMXB/Zhang 等 - 2024 - AFlow Automating Agentic Workflow Generation.pdf:application/pdf;Snapshot:/Users/lby/Zotero/storage/QHK9G5T7/2410.html:text/html},
}

@misc{ADAS,
	title = {Automated {Design} of {Agentic} {Systems}},
	url = {http://arxiv.org/abs/2408.08435},
	language = {en-US},
	urldate = {2024-10-26},
	publisher = {arXiv},
	author = {Hu, Shengran and Lu, Cong and Clune, Jeff},
	month = aug,
	year = {2024},
	note = {arXiv:2408.08435},
	keywords = {Computer Science - Artificial Intelligence},
	file = {Full Text PDF:/Users/lby/Zotero/storage/REG7MKB6/Hu 等 - 2024 - Automated Design of Agentic Systems.pdf:application/pdf;Snapshot:/Users/lby/Zotero/storage/29C8JNDY/2408.html:text/html},
}
@misc{eot,
      title={Exchange-of-Thought: Enhancing Large Language Model Capabilities through Cross-Model Communication}, 
      author={Zhangyue Yin and Qiushi Sun and Cheng Chang and Qipeng Guo and Junqi Dai and Xuanjing Huang and Xipeng Qiu},
      year={2023},
      eprint={2312.01823},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2312.01823}, 
}

@misc{dai2024costeffectiveonlinemultillmselection,
      title={Cost-Effective Online Multi-LLM Selection with Versatile Reward Models}, 
      author={Xiangxiang Dai and Jin Li and Xutong Liu and Anqi Yu and John C. S. Lui},
      year={2024},
      eprint={2405.16587},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2405.16587}, 
}
@misc{medagentslargelanguagemodels,
      title={MedAgents: Large Language Models as Collaborators for Zero-shot Medical Reasoning}, 
      author={Xiangru Tang and Anni Zou and Zhuosheng Zhang and Ziming Li and Yilun Zhao and Xingyao Zhang and Arman Cohan and Mark Gerstein},
      year={2024},
      eprint={2311.10537},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2311.10537}, 
}

@misc{ong2024routellmlearningroutellms,
      title={RouteLLM: Learning to Route LLMs with Preference Data}, 
      author={Isaac Ong and Amjad Almahairi and Vincent Wu and Wei-Lin Chiang and Tianhao Wu and Joseph E. Gonzalez and M Waleed Kadous and Ion Stoica},
      year={2024},
      eprint={2406.18665},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2406.18665}, 
}

@misc{mohammadshahi2024routoolearningroutelarge,
      title={Routoo: Learning to Route to Large Language Models Effectively}, 
      author={Alireza Mohammadshahi and Arshad Rafiq Shaikh and Majid Yazdani},
      year={2024},
      eprint={2401.13979},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2401.13979}, 
}

@misc{feng2024graphroutergraphbasedrouterllm,
      title={GraphRouter: A Graph-based Router for LLM Selections}, 
      author={Tao Feng and Yanzhen Shen and Jiaxuan You},
      year={2024},
      eprint={2410.03834},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2410.03834}, 
}

@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@inproceedings{Meta-structure_Discovery_Chen_2024, series={KDD ’24},
   title={Large Language Model-driven Meta-structure Discovery in Heterogeneous Information Network},
   url={http://dx.doi.org/10.1145/3637528.3671965},
   DOI={10.1145/3637528.3671965},
   booktitle={Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
   publisher={ACM},
   author={Chen, Lin and Xu, Fengli and Li, Nian and Han, Zhenyu and Wang, Meng and Li, Yong and Hui, Pan},
   year={2024},
   month=aug, pages={307–318},
   collection={KDD ’24} }

@misc{li2024autoflowautomatedworkflowgeneration,
      title={AutoFlow: Automated Workflow Generation for Large Language Model Agents}, 
      author={Zelong Li and Shuyuan Xu and Kai Mei and Wenyue Hua and Balaji Rama and Om Raheja and Hao Wang and He Zhu and Yongfeng Zhang},
      year={2024},
      eprint={2407.12821},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2407.12821}, 
}

@misc{abdin2024phi3technicalreporthighly,
      title={Phi-3 Technical Report: A Highly Capable Language Model Locally on Your Phone}, 
      author={Marah Abdin and Jyoti Aneja and Hany Awadalla and Ahmed Awadallah and Ammar Ahmad Awan and Nguyen Bach and Amit Bahree and Arash Bakhtiari and Jianmin Bao and Harkirat Behl and Alon Benhaim and Misha Bilenko and Johan Bjorck and Sébastien Bubeck and Martin Cai and Qin Cai and Vishrav Chaudhary and Dong Chen and Dongdong Chen and Weizhu Chen and Yen-Chun Chen and Yi-Ling Chen and Hao Cheng and Parul Chopra and Xiyang Dai and Matthew Dixon and Ronen Eldan and Victor Fragoso and Jianfeng Gao and Mei Gao and Min Gao and Amit Garg and Allie Del Giorno and Abhishek Goswami and Suriya Gunasekar and Emman Haider and Junheng Hao and Russell J. Hewett and Wenxiang Hu and Jamie Huynh and Dan Iter and Sam Ade Jacobs and Mojan Javaheripi and Xin Jin and Nikos Karampatziakis and Piero Kauffmann and Mahoud Khademi and Dongwoo Kim and Young Jin Kim and Lev Kurilenko and James R. Lee and Yin Tat Lee and Yuanzhi Li and Yunsheng Li and Chen Liang and Lars Liden and Xihui Lin and Zeqi Lin and Ce Liu and Liyuan Liu and Mengchen Liu and Weishung Liu and Xiaodong Liu and Chong Luo and Piyush Madan and Ali Mahmoudzadeh and David Majercak and Matt Mazzola and Caio César Teodoro Mendes and Arindam Mitra and Hardik Modi and Anh Nguyen and Brandon Norick and Barun Patra and Daniel Perez-Becker and Thomas Portet and Reid Pryzant and Heyang Qin and Marko Radmilac and Liliang Ren and Gustavo de Rosa and Corby Rosset and Sambudha Roy and Olatunji Ruwase and Olli Saarikivi and Amin Saied and Adil Salim and Michael Santacroce and Shital Shah and Ning Shang and Hiteshi Sharma and Yelong Shen and Swadheen Shukla and Xia Song and Masahiro Tanaka and Andrea Tupini and Praneetha Vaddamanu and Chunyu Wang and Guanhua Wang and Lijuan Wang and Shuohang Wang and Xin Wang and Yu Wang and Rachel Ward and Wen Wen and Philipp Witte and Haiping Wu and Xiaoxia Wu and Michael Wyatt and Bin Xiao and Can Xu and Jiahang Xu and Weijian Xu and Jilong Xue and Sonali Yadav and Fan Yang and Jianwei Yang and Yifan Yang and Ziyi Yang and Donghan Yu and Lu Yuan and Chenruidong Zhang and Cyril Zhang and Jianwen Zhang and Li Lyna Zhang and Yi Zhang and Yue Zhang and Yunan Zhang and Xiren Zhou},
      year={2024},
      eprint={2404.14219},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.14219}, 
}

@inproceedings{lepagnol-etal-2024-small,
    title = "Small Language Models Are Good Too: An Empirical Study of Zero-Shot Classification",
    author = "Lepagnol, Pierre  and
      Gerald, Thomas  and
      Ghannay, Sahar  and
      Servan, Christophe  and
      Rosset, Sophie",
    editor = "Calzolari, Nicoletta  and
      Kan, Min-Yen  and
      Hoste, Veronique  and
      Lenci, Alessandro  and
      Sakti, Sakriani  and
      Xue, Nianwen",
    booktitle = "Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)",
    month = may,
    year = "2024",
    address = "Torino, Italia",
    publisher = "ELRA and ICCL",
    url = "https://aclanthology.org/2024.lrec-main.1299/",
    pages = "14923--14936"
}

@misc{srivatsa2024harnessingpowermultipleminds,
      title={Harnessing the Power of Multiple Minds: Lessons Learned from LLM Routing}, 
      author={KV Aditya Srivatsa and Kaushal Kumar Maurya and Ekaterina Kochmar},
      year={2024},
      eprint={2405.00467},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2405.00467}, 
}

@inproceedings{stripelis-etal-2024-tensoropera,
    title = "{T}ensor{O}pera Router: A Multi-Model Router for Efficient {LLM} Inference",
    author = "Stripelis, Dimitris  and
      Xu, Zhaozhuo  and
      Hu, Zijian  and
      Shah, Alay Dilipbhai  and
      Jin, Han  and
      Yao, Yuhang  and
      Zhang, Jipeng  and
      Zhang, Tong  and
      Avestimehr, Salman  and
      He, Chaoyang",
    editor = "Dernoncourt, Franck  and
      Preo{\c{t}}iuc-Pietro, Daniel  and
      Shimorina, Anastasia",
    booktitle = "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing: Industry Track",
    month = nov,
    year = "2024",
    address = "Miami, Florida, US",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.emnlp-industry.34/",
    doi = "10.18653/v1/2024.emnlp-industry.34",
    pages = "452--462",
}

@article{erdogan2025plan-and-act,
  title={Plan-and-act: Improving planning of agents for long-horizon tasks},
  author={Erdogan, Lutfi Eren and Lee, Nicholas and Kim, Sehoon and Moon, Suhong and Furuta, Hiroki and Anumanchipalli, Gopala and Keutzer, Kurt and Gholami, Amir},
  journal={arXiv preprint arXiv:2503.09572},
  year={2025}
}

@misc{huang2024hardertasksneedexperts,
      title={Harder Tasks Need More Experts: Dynamic Routing in MoE Models}, 
      author={Quzhe Huang and Zhenwei An and Nan Zhuang and Mingxu Tao and Chen Zhang and Yang Jin and Kun Xu and Kun Xu and Liwei Chen and Songfang Huang and Yansong Feng},
      year={2024},
      eprint={2403.07652},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2403.07652}, 
}

@misc{aghdam2024damoedynamicexpertallocation,
      title={DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models}, 
      author={Maryam Akhavan Aghdam and Hongpeng Jin and Yanzhao Wu},
      year={2024},
      eprint={2409.06669},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2409.06669}, 
}

@misc{zhang2024cutcrapeconomicalcommunication,
      title={Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems}, 
      author={Guibin Zhang and Yanwei Yue and Zhixun Li and Sukwon Yun and Guancheng Wan and Kun Wang and Dawei Cheng and Jeffrey Xu Yu and Tianlong Chen},
      year={2024},
      eprint={2410.02506},
      archivePrefix={arXiv},
      primaryClass={cs.MA},
      url={https://arxiv.org/abs/2410.02506}, 
}

@misc{shang2024agentsquareautomaticllmagent,
      title={AgentSquare: Automatic LLM Agent Search in Modular Design Space}, 
      author={Yu Shang and Yu Li and Keyu Zhao and Likai Ma and Jiahe Liu and Fengli Xu and Yong Li},
      year={2024},
      eprint={2410.06153},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.06153}, 
}

@misc{chang2023surveyevaluationlargelanguage,
      title={A Survey on Evaluation of Large Language Models}, 
      author={Yupeng Chang and Xu Wang and Jindong Wang and Yuan Wu and Linyi Yang and Kaijie Zhu and Hao Chen and Xiaoyuan Yi and Cunxiang Wang and Yidong Wang and Wei Ye and Yue Zhang and Yi Chang and Philip S. Yu and Qiang Yang and Xing Xie},
      year={2023},
      eprint={2307.03109},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2307.03109}, 
}

@misc{minaee2024largelanguagemodelssurvey,
      title={Large Language Models: A Survey}, 
      author={Shervin Minaee and Tomas Mikolov and Narjes Nikzad and Meysam Chenaghlu and Richard Socher and Xavier Amatriain and Jianfeng Gao},
      year={2024},
      eprint={2402.06196},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2402.06196}, 
}

@misc{zingg2023detectingoptimisingteaminteractions,
      title={Detecting and Optimising Team Interactions in Software Development}, 
      author={Christian Zingg and Alexander von Gernler and Carsten Arzig and Frank Schweitzer and Christoph Gote},
      year={2023},
      eprint={2302.14609},
      archivePrefix={arXiv},
      primaryClass={cs.SE},
      url={https://arxiv.org/abs/2302.14609}, 
}

@inproceedings{morethancode, 
   series={ICSE ’20},
   title={More than Code: Contributions in Scrum Software Engineering Teams},
   url={http://dx.doi.org/10.1145/3387940.3392241},
   DOI={10.1145/3387940.3392241},
   booktitle={Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
   publisher={ACM},
   author={Ramin, Frederike and Matthies, Christoph and Teusner, Ralf},
   year={2020},
   month=jun, pages={137–140},
   collection={ICSE ’20}, 
}

@inproceedings{zhang-etal-2024-exploring,
    title = "Exploring Collaboration Mechanisms for {LLM} Agents: A Social Psychology View",
    author = "Zhang, Jintian  and
      Xu, Xin  and
      Zhang, Ningyu  and
      Liu, Ruibo  and
      Hooi, Bryan  and
      Deng, Shumin",
    editor = "Ku, Lun-Wei  and
      Martins, Andre  and
      Srikumar, Vivek",
    booktitle = "Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.acl-long.782/",
    doi = "10.18653/v1/2024.acl-long.782",
    pages = "14544--14607",
}

@misc{reimers2019sentencebertsentenceembeddingsusing,
      title={Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks}, 
      author={Nils Reimers and Iryna Gurevych},
      year={2019},
      eprint={1908.10084},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1908.10084}, 
}

@misc{mbpp,
      title={Program Synthesis with Large Language Models}, 
      author={Jacob Austin and Augustus Odena and Maxwell Nye and Maarten Bosma and Henryk Michalewski and David Dohan and Ellen Jiang and Carrie Cai and Michael Terry and Quoc Le and Charles Sutton},
      year={2021},
      eprint={2108.07732},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2108.07732}, 
}


@misc{OpenAI-gpt4o, title={GPT-4O Mini: Advancing cost-efficient intelligence}, url={https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence}, journal={GPT-4o mini: advancing cost-efficient intelligence}, author={OpenAI}, year={2024}} 

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@techreport{anthropicdd2024claude,
  author       = {Anthropic},
  title        = {Model card addendum: Claude 3.5 Haiku and upgraded Claude 3.5 Sonnet},
  institution  = {Anthropic},
  year         = {2024},
}

@misc{geminiteam2024gemini15unlockingmultimodal,
      title={Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context}, 
      author={Team, Gemini and Georgiev, Petko and Lei, Ving Ian and Burnell, Ryan and Bai, Libin and Gulati, Anmol and Tanzer, Garrett and Vincent, Damien and Pan, Zhufeng and Wang, Shibo and others},
      year={2024},
      eprint={2403.05530},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.05530}, 
}

@misc{deepseekai2024deepseekv3technicalreport,
      title={DeepSeek-V3 Technical Report}, 
      author={DeepSeek-AI and Aixin Liu and Bei Feng and Bing Xue and Bingxuan Wang and Bochao Wu and Chengda Lu and Chenggang Zhao and Chengqi Deng and Chenyu Zhang and Chong Ruan and Damai Dai and Daya Guo and Dejian Yang and Deli Chen and Dongjie Ji and Erhang Li and Fangyun Lin and Fucong Dai and Fuli Luo and Guangbo Hao and Guanting Chen and Guowei Li and H. Zhang and Han Bao and Hanwei Xu and Haocheng Wang and Haowei Zhang and Honghui Ding and Huajian Xin and Huazuo Gao and Hui Li and Hui Qu and J. L. Cai and Jian Liang and Jianzhong Guo and Jiaqi Ni and Jiashi Li and Jiawei Wang and Jin Chen and Jingchang Chen and Jingyang Yuan and Junjie Qiu and Junlong Li and Junxiao Song and Kai Dong and Kai Hu and Kaige Gao and Kang Guan and Kexin Huang and Kuai Yu and Lean Wang and Lecong Zhang and Lei Xu and Leyi Xia and Liang Zhao and Litong Wang and Liyue Zhang and Meng Li and Miaojun Wang and Mingchuan Zhang and Minghua Zhang and Minghui Tang and Mingming Li and Ning Tian and Panpan Huang and Peiyi Wang and Peng Zhang and Qiancheng Wang and Qihao Zhu and Qinyu Chen and Qiushi Du and R. J. Chen and R. L. Jin and Ruiqi Ge and Ruisong Zhang and Ruizhe Pan and Runji Wang and Runxin Xu and Ruoyu Zhang and Ruyi Chen and S. S. Li and Shanghao Lu and Shangyan Zhou and Shanhuang Chen and Shaoqing Wu and Shengfeng Ye and Shengfeng Ye and Shirong Ma and Shiyu Wang and Shuang Zhou and Shuiping Yu and Shunfeng Zhou and Shuting Pan and T. Wang and Tao Yun and Tian Pei and Tianyu Sun and W. L. Xiao and Wangding Zeng and Wanjia Zhao and Wei An and Wen Liu and Wenfeng Liang and Wenjun Gao and Wenqin Yu and Wentao Zhang and X. Q. Li and Xiangyue Jin and Xianzu Wang and Xiao Bi and Xiaodong Liu and Xiaohan Wang and Xiaojin Shen and Xiaokang Chen and Xiaokang Zhang and Xiaosha Chen and Xiaotao Nie and Xiaowen Sun and Xiaoxiang Wang and Xin Cheng and Xin Liu and Xin Xie and Xingchao Liu and Xingkai Yu and Xinnan Song and Xinxia Shan and Xinyi Zhou and Xinyu Yang and Xinyuan Li and Xuecheng Su and Xuheng Lin and Y. K. Li and Y. Q. Wang and Y. X. Wei and Y. X. Zhu and Yang Zhang and Yanhong Xu and Yanhong Xu and Yanping Huang and Yao Li and Yao Zhao and Yaofeng Sun and Yaohui Li and Yaohui Wang and Yi Yu and Yi Zheng and Yichao Zhang and Yifan Shi and Yiliang Xiong and Ying He and Ying Tang and Yishi Piao and Yisong Wang and Yixuan Tan and Yiyang Ma and Yiyuan Liu and Yongqiang Guo and Yu Wu and Yuan Ou and Yuchen Zhu and Yuduan Wang and Yue Gong and Yuheng Zou and Yujia He and Yukun Zha and Yunfan Xiong and Yunxian Ma and Yuting Yan and Yuxiang Luo and Yuxiang You and Yuxuan Liu and Yuyang Zhou and Z. F. Wu and Z. Z. Ren and Zehui Ren and Zhangli Sha and Zhe Fu and Zhean Xu and Zhen Huang and Zhen Zhang and Zhenda Xie and Zhengyan Zhang and Zhewen Hao and Zhibin Gou and Zhicheng Ma and Zhigang Yan and Zhihong Shao and Zhipeng Xu and Zhiyu Wu and Zhongyu Zhang and Zhuoshu Li and Zihui Gu and Zijia Zhu and Zijun Liu and Zilin Li and Ziwei Xie and Ziyang Song and Ziyi Gao and Zizheng Pan},
      year={2024},
      eprint={2412.19437},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2412.19437}, 
}

@article{
humangroup,
author = {Anita Williams Woolley  and Christopher F. Chabris  and Alex Pentland  and Nada Hashmi  and Thomas W. Malone },
title = {Evidence for a Collective Intelligence Factor in the Performance of Human Groups},
journal = {Science},
volume = {330},
number = {6004},
pages = {686-688},
year = {2010},
doi = {10.1126/science.1193147},
URL = {https://www.science.org/doi/abs/10.1126/science.1193147},
eprint = {https://www.science.org/doi/pdf/10.1126/science.1193147},}

@inbook{humanorganization,
author = {Phillips, Katherine and O'Reilly, Charles},
year = {1998},
month = {01},
pages = {77-140},
title = {Demography and Diversity in Organizations: A Review of 40 Years of Research},
volume = {20},
journal = {Research in Organizational Behavior}
}

@misc{barandoni2024automatingcustomerneedsanalysis,
      title={Automating Customer Needs Analysis: A Comparative Study of Large Language Models in the Travel Industry}, 
      author={Simone Barandoni and Filippo Chiarello and Lorenzo Cascone and Emiliano Marrale and Salvatore Puccio},
      year={2024},
      eprint={2404.17975},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2404.17975}, 
}
